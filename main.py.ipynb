{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en') #loading English\n",
    "\n",
    "\n",
    "#opening csv\n",
    "myfile = open('/home/user/Complaint/MakeComplaint/data.csv').read()\n",
    "data=nlp(myfile)\n",
    "\n",
    "#df=pd.DataFrame(data=data)\n",
    "#df=nlp(df)\n",
    "#print(df)\n",
    "print(type(data))\n",
    "for token in data[:8]:\n",
    "    print(token.text)\n",
    "#fetching the headers\n",
    "\n",
    "#for colname in frames:\n",
    "    #print(colname.columns)\n",
    "    \n",
    "    \n",
    "    \n",
    "#keys = ['Water Authority','KSEB','KSRTC','PWD','Environment and climate change','MVD']\n",
    "#df=pd.concat(frames,keys=keys)\n",
    "#df\n",
    "\n",
    "\n",
    "\n",
    "#print(doc_file)\n",
    "\n",
    "#tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "#tokens=tokenizer.tokenize(text)\n",
    "#print(\"Tree\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "dataset['Departments'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.Departments.value_counts().plot(kind='pie', \n",
    "                                  figsize=(8,6), \n",
    "                                  fontsize=13, \n",
    "                                  autopct='%1.1f%%', \n",
    "                                  wedgeprops={'linewidth': 5}\n",
    "                                  )\n",
    "plt.axis('off')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['water', 'supply', 'connection', 'water', 'pipeline', 'connection', 'amma', 'gardens', 'residential', 'area', 'erattakalangu', 'malayinkeezhu']\n",
      "['scarcity', 'water', 'day', 'time', 'scarcity', 'water', 'area', 'vanchiyooron', 'day', 'time', 'creates', 'great', 'trouble', 'people', 'getting', 'ready', 'work', 'schools', 'office', 'etc']\n",
      "['water', 'scarcity', 'huge', 'scarcity', 'water', 'remote', 'areas', 'people', 'walk', 'large', 'distancesstanding', 'queue', 'fetch', 'water', 'problem', 'exiss', 'hilly', 'areas', 'idukki', 'district', 'kerala', 'si', 'humbly', 'request', 'take', 'necessary', 'actions', 'tackle', 'problem', 'near', 'future']\n",
      "['water', 'scarcity', 'frequent', 'scarcity', 'water', 'morning']\n",
      "['water', 'supply', 'available', 'houses', 'area', 'water', 'supply', 'available', 'therepeople', 'get', 'water', 'needs', 'therefore', 'request', 'concerning', 'authorities', 'look', 'matter', 'seriously', 'take', 'necessary', 'steps', 'solving', 'problem', 'water', 'supply', 'may', 'kindly', 'made', 'daily', 'locality', 'people', 'may', 'get', 'rid', 'problem', 'water', 'supply']\n",
      "['stealing', 'water', 'sealed', 'pipes', 'stayed', 'hotel', 'kovalam', 'beach', 'called', 'palm', 'grove', 'second', 'beach', 'road', 'kovalam', 'near', 'kovalam', 'bus', 'stand', 'came', 'know', 'hotel', 'water', 'connection', 'without', 'water', 'supplybecause', 'authority', 'sealed', 'pipe', 'big', 'dues', 'bill', 'stealing', 'water', 'sealed', 'pipe', 'last', 'year', 'huge', 'capacity', 'water', 'storage', 'building', 'approx', 'ilters', 'capacity', 'stayed', 'hotel', 'nights', 'staff', 'told', 'things', 'regarding', 'please', 'take', 'immediate', 'action', 'fix', 'small', 'lengthy', 'pipe', 'two', 'side', 'thread', 'connector', 'connected', 'sealed', 'pipewhich', 'also', 'caped', 'glue', 'closed', 'thread', 'cap', 'usually', 'water', 'supply', 'hardly', 'days', 'per', 'week', 'day', 'steal', 'water', 'fill', 'liters', 'appox', 'filled', 'use', 'week', 'please', 'take', 'necessary', 'action']\n",
      "['water', 'leakage', 'water', 'leakage', 'locality', 'still', 'unrepairedit', 'causes', 'water', 'shortage', 'areas']\n",
      "['smelling', 'water', 'water', 'flowing', 'pipe', 'foul', 'smell', 'therefore', 'unfits', 'drinking', 'cooking', 'purposes']\n",
      "['water', 'theft', 'amount', 'unauthorised', 'connection', 'water', 'mains', 'cause', 'huge', 'bills', 'authorised', 'consumer']\n",
      "['leaking', 'pipes', 'public', 'pipes', 'public', 'pipe', 'triivandrum', 'city', 'leaking', 'thus', 'leads', 'water', 'shortage']\n",
      "['water', 'leakage', 'summer', 'season', 'drinking', 'water', 'pipe', 'near', 'puthoor', 'junction', 'broken', 'water', 'flowing', 'days', 'please', 'take', 'necessary', 'action']\n",
      "['water', 'related', 'complaint', 'shortage', 'drinking', 'water']\n",
      "['water', 'scarcity', 'scarcity', 'drinking', 'water', 'summer']\n",
      "['water', 'leakage', 'leakage', 'water', 'mg', 'road']\n",
      "['water', 'enough', 'please', 'setup', 'enough', 'water', 'resource', 'rural', 'areas']\n",
      "['water', 'coming', 'edathua', 'residing', 'edathua', 'panchayat', 'kuttanad', 'taluk', 'staying', 'rented', 'house', 'water', 'connection', 'meter', 'water', 'getting', 'waterour', 'house', 'consumer', 'number', 'eda', 'neighbouring', 'houseconsumer', 'noeda', 'also', 'getting', 'water', 'well', 'also', 'waterwe', 'facing', 'great', 'difficulties', 'daytoday', 'needs', 'kindly', 'request', 'take', 'necessary', 'action']\n",
      "['non', 'availability', 'drinking', 'water', 'totally', 'residing', 'attuparambil', 'eravipuram', 'kollam', 'locality', 'facing', 'severe', 'problem', 'growing', 'instances', 'insufficient', 'water', 'supply', 'last', 'days', 'locality', 'already', 'given', 'many', 'complaints', 'kindly', 'requesting', 'look', 'matter', 'personally', 'needful', 'shall', 'much', 'thankful']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "#Data cleaning\n",
    "\n",
    "# 1. unpunctuate \n",
    "# 2. to lower\n",
    "# 3. Remove numerals\n",
    "# 4. Remove Newline for subject\n",
    "\n",
    "\n",
    "# Data loading\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Subject'] = dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Complaint'] = dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower() \n",
    "\n",
    "\n",
    "#rRemoving new lines in the subject field\n",
    "dataset['Subject'] = dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "#removing Numeric \n",
    "dataset['Complaint'] = dataset['Complaint'].str.replace('[^a-zA-Z ]','').str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# creating dataframe for each departments\n",
    "water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "\n",
    "#print(env.shape)    #(29, 4)\n",
    "#print(water.shape)  #(17, 4)\n",
    "#print(pwd.shape)    #(39, 4)\n",
    "#print(ksrtc.shape)  #(13, 4)\n",
    "#print(kseb.shape)   #(22, 4)\n",
    "#dataset.head()\n",
    "#print(pwd)\n",
    "\n",
    "#Filtering out Subjects and complaints from the dataframe\n",
    "df_water = water[['Subject','Complaint']]\n",
    "df_pwd   = pwd[['Subject','Complaint']]\n",
    "df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "df_kseb  = kseb[['Subject','Complaint']]\n",
    "df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "dfwater  = df_water[['Subject','Complaint']]\n",
    "dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = Water\n",
    "dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "dfwater=dfwater[['Subject_and_Complaint']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = PWD\n",
    "dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "#print(dfpwd)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = ksrtc\n",
    "dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "#print(dfksrtc)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = kseb\n",
    "dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "#print(dfkseb)\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = env\n",
    "dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "dfenv =dfenv [['Subject_and_Complaint']]\n",
    "#print(dfenv )\n",
    "\n",
    "#==================================Tokenization Begins : =============================================\n",
    "\n",
    "sentence= []\n",
    "\"\"\"def stopword_remove(tokens):\n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = list(stop_words)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\"\"\"\n",
    "    \n",
    "                     \n",
    "\n",
    "\n",
    "water_token = []\n",
    "#Tokenising water data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i, row in dfwater.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    #tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "    result = [i for i in water_token if not i in stop_words]\n",
    "    print(result)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "#print(type(tokens))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "pwd_token = []\n",
    "#Tokenising pwd data    \n",
    "for i, row in dfpwd.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    pwd_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( pwd_token)\n",
    "\n",
    "ksrtc_token =[]\n",
    "#Tokenising ksrtc data    \n",
    "for i, row in dfksrtc.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    ksrtc_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( ksrtc_token)\n",
    "\n",
    "kseb_token = []\n",
    "#Tokenising kseb data    \n",
    "for i, row in dfkseb.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    kseb_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(kseb_token)\n",
    "\n",
    "env_token = []\n",
    "#Tokenising env data    \n",
    "for i, row in dfenv.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    env_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(env_token)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
