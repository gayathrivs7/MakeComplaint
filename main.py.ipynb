{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en') #loading English\n",
    "\n",
    "\n",
    "#opening csv\n",
    "myfile = open('/home/user/Complaint/MakeComplaint/data.csv').read()\n",
    "data=nlp(myfile)\n",
    "\n",
    "#df=pd.DataFrame(data=data)\n",
    "#df=nlp(df)\n",
    "#print(df)\n",
    "print(type(data))\n",
    "for token in data[:8]:\n",
    "    print(token.text)\n",
    "#fetching the headers\n",
    "\n",
    "#for colname in frames:\n",
    "    #print(colname.columns)\n",
    "    \n",
    "    \n",
    "    \n",
    "#keys = ['Water Authority','KSEB','KSRTC','PWD','Environment and climate change','MVD']\n",
    "#df=pd.concat(frames,keys=keys)\n",
    "#df\n",
    "\n",
    "\n",
    "\n",
    "#print(doc_file)\n",
    "\n",
    "#tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "#tokens=tokenizer.tokenize(text)\n",
    "#print(\"Tree\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "dataset['Departments'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset.Departments.value_counts().plot(kind='pie', \n",
    "                                  figsize=(8,6), \n",
    "                                  fontsize=13, \n",
    "                                  autopct='%1.1f%%', \n",
    "                                  wedgeprops={'linewidth': 5}\n",
    "                                  )\n",
    "plt.axis('off')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"shan't\", 'did', \"that'll\", 'does', \"couldn't\", 'which', 'each', 'yourself', 'be', \"needn't\", 'here', 'needn', 'because', 'ma', 'but', 'have', \"don't\", 'were', 'he', 'these', 'just', 'into', \"mightn't\", 'when', 'there', 'nor', \"she's\", 'all', 'shouldn', 'those', 'of', 'o', 'than', 'both', 'the', 'who', 're', 'we', 'herself', 'at', 'doing', 'few', 'won', 'over', 'doesn', 'most', 'our', 'them', 'and', 'do', 'didn', \"didn't\", 'to', 'y', 'not', 'through', \"you'd\", 'itself', 'where', 'between', 'myself', 'before', 's', \"hadn't\", \"wasn't\", 'been', 'up', 'other', 'd', \"aren't\", 'against', 'once', \"haven't\", 'having', 'again', 'hasn', 'being', 'very', 'with', 'wasn', 'a', 'only', \"it's\", 'was', 'i', 'shan', 'after', 'isn', 'hadn', 'himself', 'him', \"isn't\", 'has', 'aren', 'on', 'what', 'weren', 'why', 'about', 'in', 'it', \"weren't\", 'mightn', 'for', 'ourselves', 'more', 'will', \"hasn't\", 'me', 'yourselves', 'no', 'yours', 'off', 'above', 'that', 'is', 'then', 'below', 'whom', 'their', 'wouldn', 'from', 'my', 'while', 'm', 'by', 'own', 'now', 'its', 'his', 'under', 'she', 'an', 'don', \"wouldn't\", 'as', 'her', 'during', 'themselves', 'can', 'or', \"should've\", 'had', 'same', 'this', 'any', \"you're\", 'some', 'out', \"you'll\", 'll', 'are', 'you', 'such', \"doesn't\", 'haven', 't', 'mustn', 'theirs', 'further', 've', 'so', 'your', \"you've\", 'down', 'if', 'couldn', 'should', 'ain', 'ours', 'how', 'they', \"shouldn't\", 'am', 'too', \"mustn't\", \"won't\", 'hers', 'until']\n",
      "[['no', 'water', 'supply', 'connection', 'no', 'water', 'pipeline', 'connection', 'in', 'amma', 'gardens', 'residential', 'area', 'erattakalangu', 'malayinkeezhu'], ['scarcity', 'of', 'water', 'in', 'day', 'time', 'there', 'is', 'scarcity', 'of', 'water', 'in', 'my', 'area', 'vanchiyooron', 'day', 'time', 'this', 'creates', 'great', 'trouble', 'for', 'people', 'who', 'are', 'getting', 'ready', 'for', 'their', 'work', 'schools', 'office', 'etc'], ['water', 'scarcity', 'there', 'is', 'a', 'huge', 'scarcity', 'of', 'water', 'in', 'remote', 'areas', 'and', 'people', 'have', 'to', 'walk', 'large', 'distancesstanding', 'in', 'queue', 'to', 'fetch', 'water', 'this', 'problem', 'exiss', 'in', 'some', 'of', 'the', 'hilly', 'areas', 'in', 'idukki', 'district', 'of', 'kerala', 'si', 'i', 'humbly', 'request', 'to', 'take', 'necessary', 'actions', 'to', 'tackle', 'the', 'problem', 'in', 'the', 'near', 'future'], ['water', 'scarcity', 'frequent', 'scarcity', 'of', 'water', 'during', 'morning'], ['no', 'water', 'supply', 'available', 'there', 'is', 'more', 'then', 'houses', 'in', 'over', 'area', 'but', 'no', 'water', 'supply', 'available', 'therepeople', 'can', 'not', 'get', 'water', 'of', 'their', 'needs', 'therefore', 'i', 'request', 'the', 'concerning', 'authorities', 'to', 'look', 'into', 'the', 'matter', 'seriously', 'and', 'take', 'necessary', 'steps', 'for', 'solving', 'the', 'problem', 'so', 'the', 'water', 'supply', 'may', 'kindly', 'be', 'made', 'daily', 'in', 'our', 'locality', 'people', 'may', 'get', 'rid', 'of', 'the', 'problem', 'of', 'no', 'water', 'supply'], ['stealing', 'of', 'water', 'from', 'sealed', 'pipes', 'i', 'stayed', 'in', 'a', 'hotel', 'in', 'kovalam', 'beach', 'called', 'palm', 'grove', 'second', 'beach', 'road', 'kovalam', 'near', 'kovalam', 'bus', 'stand', 'i', 'came', 'to', 'know', 'that', 'the', 'hotel', 'has', 'water', 'connection', 'without', 'water', 'supplybecause', 'the', 'authority', 'sealed', 'the', 'pipe', 'for', 'big', 'dues', 'of', 'bill', 'so', 'they', 'are', 'stealing', 'the', 'water', 'from', 'the', 'sealed', 'pipe', 'last', 'more', 'than', 'a', 'year', 'they', 'have', 'huge', 'capacity', 'of', 'water', 'storage', 'under', 'the', 'building', 'approx', 'ilters', 'capacity', 'me', 'stayed', 'in', 'this', 'hotel', 'for', 'nights', 'and', 'staff', 'in', 'there', 'told', 'me', 'all', 'the', 'things', 'regarding', 'this', 'please', 'take', 'immediate', 'action', 'against', 'this', 'they', 'fix', 'with', 'small', 'lengthy', 'pipe', 'with', 'two', 'side', 'of', 'thread', 'connector', 'connected', 'to', 'sealed', 'pipewhich', 'is', 'also', 'not', 'caped', 'with', 'glue', 'but', 'it', 'is', 'closed', 'with', 'thread', 'cap', 'usually', 'there', 'is', 'water', 'supply', 'hardly', 'to', 'days', 'per', 'week', 'any', 'of', 'these', 'day', 'they', 'steal', 'the', 'water', 'once', 'they', 'fill', 'their', 'liters', 'appox', 'filled', 'can', 'use', 'week', 'please', 'take', 'necessary', 'action', 'against', 'this'], ['water', 'leakage', 'water', 'leakage', 'in', 'our', 'locality', 'is', 'still', 'unrepairedit', 'causes', 'water', 'shortage', 'in', 'other', 'areas', 'too'], ['smelling', 'water', 'water', 'flowing', 'through', 'the', 'pipe', 'has', 'a', 'foul', 'smell', 'therefore', 'it', 'unfits', 'for', 'drinking', 'and', 'cooking', 'purposes'], ['water', 'theft', 'the', 'amount', 'of', 'unauthorised', 'connection', 'to', 'water', 'mains', 'cause', 'huge', 'bills', 'to', 'the', 'authorised', 'consumer'], ['leaking', 'pipes', 'in', 'the', 'public', 'pipes', 'public', 'pipe', 'in', 'triivandrum', 'city', 'is', 'leaking', 'thus', 'leads', 'to', 'water', 'shortage'], ['water', 'leakage', 'during', 'summer', 'season', 'the', 'drinking', 'water', 'pipe', 'near', 'at', 'puthoor', 'junction', 'is', 'broken', 'and', 'the', 'water', 'is', 'flowing', 'for', 'days', 'please', 'take', 'necessary', 'action'], ['water', 'related', 'complaint', 'shortage', 'of', 'drinking', 'water'], ['water', 'scarcity', 'scarcity', 'of', 'drinking', 'water', 'in', 'summer'], ['water', 'leakage', 'leakage', 'of', 'water', 'in', 'mg', 'road'], ['water', 'is', 'not', 'enough', 'please', 'setup', 'enough', 'water', 'resource', 'in', 'rural', 'areas'], ['water', 'not', 'coming', 'edathua', 'i', 'am', 'residing', 'in', 'edathua', 'panchayat', 'kuttanad', 'taluk', 'i', 'am', 'staying', 'in', 'a', 'rented', 'house', 'water', 'connection', 'and', 'meter', 'is', 'there', 'but', 'water', 'we', 'are', 'not', 'getting', 'waterour', 'house', 'consumer', 'number', 'is', 'eda', 'our', 'neighbouring', 'houseconsumer', 'noeda', 'also', 'not', 'getting', 'water', 'our', 'well', 'also', 'no', 'waterwe', 'are', 'facing', 'great', 'difficulties', 'in', 'our', 'daytoday', 'needs', 'so', 'i', 'kindly', 'request', 'you', 'to', 'take', 'the', 'necessary', 'action', 'for', 'the', 'same'], ['non', 'availability', 'for', 'drinking', 'water', 'we', 'are', 'totally', 'more', 'residing', 'in', 'our', 'attuparambil', 'eravipuram', 'kollam', 'locality', 'we', 'are', 'facing', 'a', 'severe', 'problem', 'of', 'growing', 'instances', 'of', 'insufficient', 'water', 'supply', 'for', 'the', 'last', 'days', 'in', 'our', 'locality', 'we', 'have', 'already', 'given', 'many', 'complaints', 'kindly', 'am', 'requesting', 'you', 'to', 'look', 'into', 'this', 'matter', 'personally', 'if', 'you', 'do', 'the', 'needful', 'then', 'i', 'shall', 'be', 'very', 'much', 'thankful', 'to', 'you']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "\n",
    "#Data cleaning\n",
    "\n",
    "# 1. unpunctuate \n",
    "# 2. to lower\n",
    "# 3. Remove numerals\n",
    "# 4. Remove Newline for subject\n",
    "\n",
    "\n",
    "# Data loading\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Subject'] = dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Complaint'] = dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower() \n",
    "\n",
    "\n",
    "#rRemoving new lines in the subject field\n",
    "dataset['Subject'] = dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "#removing Numeric \n",
    "dataset['Complaint'] = dataset['Complaint'].str.replace('[^a-zA-Z ]','').str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# creating dataframe for each departments\n",
    "water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "\n",
    "#print(env.shape)    #(29, 4)\n",
    "#print(water.shape)  #(17, 4)\n",
    "#print(pwd.shape)    #(39, 4)\n",
    "#print(ksrtc.shape)  #(13, 4)\n",
    "#print(kseb.shape)   #(22, 4)\n",
    "#dataset.head()\n",
    "#print(pwd)\n",
    "\n",
    "#Filtering out Subjects and complaints from the dataframe\n",
    "df_water = water[['Subject','Complaint']]\n",
    "df_pwd   = pwd[['Subject','Complaint']]\n",
    "df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "df_kseb  = kseb[['Subject','Complaint']]\n",
    "df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "dfwater  = df_water[['Subject','Complaint']]\n",
    "dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = Water\n",
    "dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "dfwater=dfwater[['Subject_and_Complaint']]\n",
    "#print(df1_water)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = PWD\n",
    "dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "#print(dfpwd)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = ksrtc\n",
    "dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "#print(dfksrtc)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = kseb\n",
    "dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "#print(dfkseb)\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = env\n",
    "dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "dfenv =dfenv [['Subject_and_Complaint']]\n",
    "#print(dfenv )\n",
    "\n",
    "#==================================Tokenization Begins : =============================================\n",
    "\n",
    "sentence= []\n",
    "def stopword_remove(tokens):\n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = list(stop_words)\n",
    "    print(stop_words)\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\n",
    "    \n",
    "                     \n",
    "\n",
    "\n",
    "water_token = []\n",
    "#Tokenising water data\n",
    "for i, row in dfwater.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "\n",
    "print(stopword_remove(water_token))\n",
    "    \n",
    "#print(water_token)\n",
    "\n",
    "pwd_token = []\n",
    "#Tokenising pwd data    \n",
    "for i, row in dfpwd.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    pwd_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(  pwd_token)\n",
    "\n",
    "ksrtc_token =[]\n",
    "#Tokenising ksrtc data    \n",
    "for i, row in dfksrtc.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    ksrtc_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( ksrtc_token)\n",
    "\n",
    "kseb_token = []\n",
    "#Tokenising kseb data    \n",
    "for i, row in dfkseb.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    kseb_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(kseb_token)\n",
    "\n",
    "env_token = []\n",
    "#Tokenising env data    \n",
    "for i, row in dfenv.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    env_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(env_token)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
