{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                             Subject  \\\n",
      "0   1         No water supply connection.   \n",
      "1   2                  Road re tarring.\\n   \n",
      "2   3  Power cuts without a prior notice.   \n",
      "3   4     Scarcity of water in day time.    \n",
      "4   5                      Water scarcity   \n",
      "\n",
      "                                           Complaint      Departments  \n",
      "0  No water pipeline connection in amma gardens r...  Water Authority  \n",
      "1  I am a resident of sreekaryam  Ambadi Nagar la...              PWD  \n",
      "2  As everyone knows that electricity is the majo...             KSEB  \n",
      "3  There is scarcity of water in my area Vanchiyo...  Water Authority  \n",
      "4  There is a huge scarcity of water in remote ar...  Water Authority  \n",
      "   id Subject                                          Complaint  \\\n",
      "0   1          no water pipeline connection in amma gardens r...   \n",
      "1   2          i am a resident of sreekaryam  ambadi nagar la...   \n",
      "2   3          as everyone knows that electricity is the majo...   \n",
      "3   4          there is scarcity of water in my area vanchiyo...   \n",
      "4   5          there is a huge scarcity of water in remote ar...   \n",
      "\n",
      "       Departments  \n",
      "0  Water Authority  \n",
      "1              PWD  \n",
      "2             KSEB  \n",
      "3  Water Authority  \n",
      "4  Water Authority  \n",
      "(30, 4)\n",
      "                                 Subject_and_Complaint\n",
      "12    the number of deaths from cardiovascular dise...\n",
      "13    people make river water polluted by dumping h...\n",
      "19    due to the sand mining there is more of effec...\n",
      "20    in our areas during night some strangers are ...\n",
      "33    fishes in the river pampa are dying massively...\n",
      "40    construction is going on the trivandrum in th...\n",
      "42    many industries dump wastes into rivers  lake...\n",
      "43    burning of plastics in public places cause a ...\n",
      "44    dumping of wastes in the public places causes...\n",
      "45    activities like waste disposal from residenti...\n",
      "46    overfishing  which causes a reduction in dive...\n",
      "47    artificial light at night is one of the most ...\n",
      "48    the electronic waste problem is huge the elec...\n",
      "49    ocean acidification is caused when co₂ dissol...\n",
      "50    noise produced by vehicles  political parties...\n",
      "58    now a days many people are cutting down the t...\n",
      "62    polution by ksrtc bus is very heavy today so ...\n",
      "65    quarries are bad for the environment in sever...\n",
      "70                            save alappad stop mining\n",
      "72    i would like to inform you that city resident...\n",
      "74    preserving biodiversity  saving forest can he...\n",
      "100   intolerable temperature change in summer seas...\n",
      "103                         intense heat during summer\n",
      "110   one among the factors which shaped kerala as ...\n",
      "112   due to excessive use of chlorine and other di...\n",
      "113   we should have more projects on planting tree...\n",
      "114   need proper regulations to control the pollution\n",
      "116   increased deforestation  uncontrolled constru...\n",
      "118   the pollution levels in the kochi city is ris...\n",
      "120   waste disposal in public premises make life h...\n",
      "\n",
      "\n",
      "Water Tokens\n",
      "\n",
      "\n",
      "[['water', 'pipeline', 'connection', 'amma', 'gardens', 'residential', 'area', 'erattakalangu', 'malayinkeezhu'], ['scarcity', 'water', 'area', 'vanchiyoor', 'day', 'time', 'creates', 'great', 'trouble', 'people', 'getting', 'ready', 'work', 'schools', 'office', 'etc'], ['huge', 'scarcity', 'water', 'remote', 'areas', 'people', 'walk', 'large', 'distances', 'standing', 'queue', 'fetch', 'water', 'problem', 'exiss', 'hilly', 'areas', 'idukki', 'district', 'kerala', 'si', 'humbly', 'request', 'take', 'necessary', 'actions', 'tackle', 'problem', 'near', 'future'], ['frequent', 'scarcity', 'water', 'morning'], ['100', 'houses', 'area', 'water', 'supply', 'available', 'therepeople', 'get', 'water', 'needs', 'therefore', 'request', 'concerning', 'authorities', 'look', 'matter', 'seriously', 'take', 'necessary', 'steps', 'solving', 'problem', 'water', 'supply', 'may', 'kindly', 'made', 'daily', 'locality', 'people', 'may', 'get', 'rid', 'problem', 'water', 'supply'], ['stayed', 'hotel', 'kovalam', 'beach', 'called', 'palm', 'grove', 'second', 'beach', 'road', 'kovalam', 'near', 'kovalam', 'bus', 'stand', 'came', 'know', 'hotel', 'water', 'connection', 'without', 'water', 'supply', 'authority', 'sealed', 'pipe', 'big', 'dues', 'bill', 'stealing', 'water', 'sealed', 'pipe', 'last', 'year', 'huge', 'capacity', 'water', 'storage', 'building', 'approx', '20000', 'ilters', 'capacity', 'stayed', 'hotel', '3', 'nights', 'staff', 'told', 'things', 'regarding', 'please', 'take', 'immediate', 'action', 'fix', 'small', 'lengthy', 'pipe', 'two', 'side', 'thread', 'connector', 'connected', 'sealed', 'pipewhich', 'also', 'caped', 'glue', 'closed', 'thread', 'cap', 'usually', 'water', 'supply', 'hardly', '3', '4', 'days', 'per', 'week', 'day', 'steal', 'water', 'fill', '20000', 'liters', 'appox', 'filled', 'use', '1', 'week', 'please', 'take', 'necessary', 'action'], ['water', 'leakage', 'locality', 'still', 'unrepaired', 'causes', 'water', 'shortage', 'areas'], ['water', 'flowing', 'pipe', 'foul', 'smell', 'therefore', 'unfits', 'drinking', 'cooking', 'purposes'], ['amount', 'unauthorised', 'connection', 'water', 'mains', 'cause', 'huge', 'bills', 'authorised', 'consumer'], ['public', 'pipe', 'triivandrum', 'city', 'leaking', 'thus', 'leads', 'water', 'shortage'], ['drinking', 'water', 'pipe', 'near', 'puthoor', 'junction', 'broken', 'water', 'flowing', '2', 'days', 'please', 'take', 'necessary', 'action'], ['shortage', 'drinking', 'water'], ['scarcity', 'drinking', 'water', 'summer'], ['leakage', 'water', 'mg', 'road'], ['please', 'setup', 'enough', 'water', 'resource', 'rural', 'areas'], ['residing', 'edathua', 'panchayat', 'kuttanad', 'taluk', 'staying', 'rented', 'house', 'water', 'connection', 'meter', 'water', 'getting', 'waterour', 'house', 'consumer', 'number', '471eda', 'neighbouring', 'houseconsumer', 'no818eda', 'also', 'getting', 'water', 'well', 'also', 'waterwe', 'facing', 'great', 'difficulties', 'daytoday', 'needs', 'kindly', 'request', 'take', 'necessary', 'action'], ['totally', 'residing', 'attuparambil', 'eravipuram', 'kollam', 'locality', 'facing', 'severe', 'problem', 'growing', 'instances', 'insufficient', 'water', 'supply', 'last', '5', 'days', 'locality', 'already', 'given', 'many', 'complaints', 'kindly', 'requesting', 'look', 'matter', 'personally', 'needful', 'shall', 'much', 'thankful'], ['last', 'one', 'month', 'kochi', 'facing', 'acute', 'shortage', 'water', 'supply', 'kwa', 'supply', 'system', 'summer', 'getting', 'bad', 'worse', 'shortage', 'water', 'aggravating', 'condition'], ['writing', 'inform', 'residents', 'punnakunnam', 'pulinkunnu', 'kuttanadu', 'alappuzha', 'facing', 'shortage', 'drinking', 'water', 'last', '10', 'monthsin', 'fact', 'every', 'member', 'society', 'disturbed', 'account', 'unavailability', 'water', 'supply', 'basic', 'need', 'every', 'human'], ['new', 'water', 'pipe', 'connection', 'installed', 'front', 'house', 'leaking', 'water', 'leaking', 'great', 'force', 'getting', 'wasted'], ['please', 'note', 'informing', 'drinking', 'water', 'keep', 'flowing', 'road', 'always', 'wet', 'compound', 'fully', 'accumulated', 'meter', 'cabin'], ['may', 'one', 'two', 'week', 'dont', 'get', 'water', 'even', 'provide', 'water', 'supply', 'time', 'late', 'like', 'midnight', 'low', 'pressure'], ['please', 'issue', 'good', 'water', 'meter'], ['consumer', 'waterworks', 'sub', 'division', 'thrissur', 'per', 'mentioned', 'consumer', 'number', 'getting', 'water', 'past', 'four', 'months', 'house', 'leakage', 'tiled', 'portion', 'road', 'thrissur', 'corporation', 'noticed', 'reported', 'assistant', 'engineer', 'action', 'taken', 'rectify', 'leakage', 'restore', 'water', 'supply', 'house'], ['since', 'january', 'consuming', 'mudmix', 'water', 'every', 'supply', 'water', 'authority', 'storage', 'tank', 'destroy', 'mud', 'resulted', 'taps', 'bathroom', 'systems', 'also'], ['public', 'tap', 'remains', 'idle', 'past', 'couple', 'weeks', 'affected', 'lives', 'people', 'neighborhood', 'awkwardly'], ['recieved', 'bill', '792', 'rs', 'house', 'closed', 'state', '3', 'months', 'information', 'consumption', 'details', 'previous', 'reading', 'information', 'bill'], ['water', 'supply', 'vazhathope', 'pachayath', 'two', 'weeks', 'people', 'need', 'look', 'upon', 'water', 'sources', 'much', 'frustrating'], ['regular', 'water', 'supply', 'september', '2017', 'onwards', 'till', 'date'], ['water', 'loosing', 'distribution', 'line', 'every', 'day', 'pumping', 'progressthis', 'water', 'trapped', 'walk', 'way', 'public', 'useand', 'time', 'mosqitos', 'growingseveral', 'time', 'iform', 'water', 'athority', 'kochi', 'office'], ['domestic', 'water', 'supply', 'houses', 'situated', 'near', 'kunnathuvathucal', 'bridge', 'last', '3', 'days'], ['name', 'wrongly', 'recorded', 'water', 'connection', 'records'], ['able', 'complete', 'payment', 'transaction', 'water', 'authority', 'website'], ['pay', 'utility', 'bills', 'mostly', 'via', 'online', 'payment', 'services', 'water', 'bill', 'facing', 'problem', 'paying', 'bill', 'water', 'authority', 'website'], ['wastage', 'drinking', 'water', 'due', 'damaged', 'pipeline'], ['trying', 'make', 'bill', 'payment', 'entered', 'credentials', 'tried', 'login', 'account', 'everytime', 'try', 'login', 'get', 'error', 'message'], ['request', 'check', 'meter', 'replace', 'repair', 'early', 'possible'], ['location', 'water', 'connection', 'since', 'summer', 'facing', 'severe', 'water', 'scarcity', 'please', 'set', 'connection', 'loction'], ['pay', 'bill', 'e', 'payment', 'web', 'site', 'charge', 'additional', 'rupees', '10', 'transaction']]\n",
      "\n",
      "\n",
      "PWD Tokens\n",
      "\n",
      "\n",
      "[['resident', 'sreekaryam', 'ambadi', 'nagar', 'lane', '3', 'road', 'full', 'potholes', 'kindly', 'necessary', 'steps', 'maintenance', 'road'], ['condition', 'road', 'rural', 'areas', 'kerala', 'miserable', 'corruption', 'contract', 'maintenance', 'road', 'causing', 'problems', 'leads', 'frequent', 'damage', 'newly', 'constructed', 'tared', 'roads', 'potholes', 'road', 'leads', 'accidents', 'losing', 'balance', 'vehicles', 'paved', 'way', 'damage', 'road'], ['living', 'area', 'road', 'harsh', '500', 'people', 'living', 'area', 'travelling', 'unpaved', 'road', 'difficult', 'taskirequests', 'tar', 'road', 'early', 'possible'], ['due', 'recent', 'landslide', 'activity', 'roads', 'got', 'shattered', 'traffic', 'stopped', 'many', 'days', 'please', 'make', 'tarring', 'process', 'faster'], ['mr', 'kumar', 'locality', 'constructing', 'wall', 'taking', 'footpath', 'pwd'], ['road', 'works', 'without', 'prior', 'notice', 'day', 'time', 'cause', 'heavy', 'traffic', 'congestion'], ['melattumoozhy', 'thannippara', 'road', 'bad', 'condition', 'accidents', 'increasing', 'day', 'day', 'please', 'take', 'necessary', 'actions', 'retarring', 'process'], ['road', 'sreekaryam', 'proper', 'width', 'well', 'maintained'], ['id', 'like', 'make', 'public', 'works', 'department', 'aware', 'number', 'potholes', 'impeding', 'traffic', 'also', 'causing', 'undue', 'wear', 'tear', 'vehicles', 'hitting', 'pothole', 'even', 'speed', 'limit', 'pop', 'tire', 'damage', 'car', 'even', 'pose', 'physical', 'threat', 'drivers', 'pedestrians', 'know', 'state', 'law', 'permits', 'drivers', 'seek', 'reimbursement', 'losses', 'due', 'road', 'hazards', 'defects', 'result', 'negligence', 'potential', 'liability', 'claims', 'high', 'several', 'potholes', 'located', 'maple', 'street', '12th', '13th', 'streets', 'one', 'least', 'two', 'feet', 'diameter', 'intersection', '13th', 'pine', 'know', 'crew', 'cant', 'get', 'every', 'pothole', 'right', 'away', 'growing', 'many', 'months', 'attached', 'photos', 'illustrate', 'problem'], ['roads', 'safe', 'running', 'heavyweight', 'vehicle', 'poor', 'maintenance', 'problem', 'aggravates', 'especially', 'rainy', 'season', 'major', 'problem', 'india', 'roads', 'high', 'traffic', 'condition', 'road', 'used', 'various', 'types', 'vehicles', 'highspeed', 'trucks', 'cars', 'tractors', 'twowheelers', 'driven', 'carts', 'cyclists', 'etc', 'things', 'create', 'high', 'traffic', 'jam', 'congestion', 'road', 'accident', 'etcthe', 'roads', 'india', 'lack', 'wayside', 'amenities', 'like', 'first', 'aid', 'centers', 'telephone', 'booths', 'repair', 'shops', 'restaurants', 'clean', 'toilets', 'create', 'serious', 'problems', 'drivers', 'moreover', 'little', 'attention', 'given', 'road', 'safety', 'issues', 'also', 'road', 'safety', 'rules', 'violation', 'laws', 'road', 'transportation', 'system', 'country', 'requires', 'immediate', 'modernization', 'latest', 'technology', 'road', 'transport', 'sector', 'use', 'old', 'technology', 'vehicles', 'still', 'prevalent', 'ultimately', 'increase', 'number', 'road', 'accidents', 'due', 'bad', 'road', 'condition', 'transport', 'companies', 'bear', 'huge', 'amount', 'per', 'year', 'wear', 'tear', 'vehicles', 'important', 'point', 'proper', 'attention', 'given', 'road', 'direction', 'railway', 'department', 'always', 'indifferent', 'attitude', 'biggest', 'barrier', 'transport', 'india', 'railway', 'crossings', 'despite', 'government', 'permissions', 'government', 'employees', 'make', 'reasonable', 'contributions', 'even', 'bribe', 'timeconsuming', 'transport', 'traders', 'also', 'large', 'businessmen', 'businessmen', 'also', 'raised'], ['roads', 'many', 'pitfalls', 'sometimes', 'cause', 'accidents', 'unwary', 'drivers'], ['rising', 'peakhour', 'traffic', 'congestion', 'inescapable', 'condition', 'many', 'areas', 'trivandrum', 'city', 'sufficient', 'traffic', 'control', 'signal', 'systems', 'handle', 'situations'], ['roads', 'properly', 'maintained', 'repair', 'works', 'roads', 'last', 'days', 'proper', 'transportation', 'facility', 'basic', 'right', 'citizens'], ['actually', 'dont', 'good', 'roads', 'worthy', 'tax', 'pay', 'hopefully', 'government', 'find', 'way', 'fix', 'thanks'], ['pathholes', 'road', 'extremly', 'half', 'feet', 'size', 'accident', 'prone', 'today', 'effect', 'daily', 'travelling', 'student', 'employees', 'suffering', 'also', 'may', 'cause', 'health', 'problems'], ['drainage', 'work', 'muthambioorallur', 'road', 'thadoli', 'thazha', 'junction', 'koyilandy', 'taluk', 'calicut', 'district', 'length', '100', 'mtr', 'progressing', 'outlet', 'crossing', 'road', 'directed', 'towards', 'compound', 'wall', 'letting', 'water', 'flow', 'nayadan', 'puzha', 'lake', 'completion', 'water', 'flow', 'directly', 'bottom', 'compound', 'wall', 'hitting', 'compound', 'wall', 'changes', 'direction', 'flow', 'damage', 'wall', 'nature', 'place', 'loose', 'mud', 'learnt', 'provision', 'continue', 'drainage', 'limit', 'road', 'requested', 'kindly', 'needful', 'avoid', 'damage', 'wall', 'length', '15', 'mtr', 'early', 'action', 'requested', 'canal', 'water', 'open', 'last', 'january'], ['sir', 'please', 'initiate', 'surprise', 'visit', 'kerala', 'know', 'conditions', 'roads', '6', 'monthsafter', 'rainy', 'season', 'since', 'roads', 'repaired', 'also', 'roads', 'broken', 'instead', 'chipping', 'existing', 'roads', 'resurfaced', 'increases', 'height', 'roads', 'height', 'roads', 'increased', 'height', 'houses', 'office', 'complexes', 'increased', 'know', 'take', 'help', 'media', 'channels', 'like', 'asianet', 'news', 'manorama', 'news', 'indiavision', 'etc', 'also', 'common', 'trend', 'ie', 'roads', 'repaired', 'broken', 'manually', 'underlying', 'cables', 'underground', 'left', 'without', 'repairing', 'sirmadam', 'per', 'day', 'lacs', 'vehicles', 'entering', 'roads', 'showrooms', 'much', 'tax', 'collected', 'isnt', 'sufficient', 'repair', 'roads', 'roads', 'leveled', 'properly', 'much', 'fuel', 'saved', 'prices', 'fuel', 'controlled', 'certain', 'extent', 'right', 'hope', 'would', 'take', 'factors', 'consideration'], ['dear', 'sir', 'due', 'intervention', 'politicians', 'every', 'footpath', 'flooded', 'vendors', 'selling', 'tender', 'cocanuts', 'shoe', 'repairs', 'petty', 'shops', 'filled', 'pan', 'masalas', 'liquiors', 'tea', 'snacks', 'notnot', 'traders', 'blocking', 'view', 'side', 'roads', 'motorist', 'predict', 'see', 'going', 'emerge', 'side', 'roads', 'petty', 'shops', 'well', 'concreated', 'base', 'running', 'businesses', 'like', 'real', 'estate', 'rentals', 'etcetc', 'idea', 'growing', 'nation', 'city', 'clean', 'roads', 'responsible', 'pwd', 'authority', 'issue', 'notice', 'people', 'evict', 'themgod', 'bad', 'country', 'pity', 'consideration', 'appeal', 'something', 'stop'], ['heavy', 'traffic', 'ss', 'kovil', 'road', 'thampanoor', 'large', 'amount', 'vehicle', 'parking'], ['connection', 'othukkungal', 'town', 'malappuram', 'district', 'kerala', 'beautification', 'existing', 'bus', 'waiting', 'shed', 'towards', 'kottakkal', 'removed', 'last', 'year', 'till', 'date', 'new', 'shed', 'constructed', 'makes', 'difficult', 'common', 'passengers', 'kindly', 'take', 'necessary', 'action', 'construction', 'waiting', 'shed', 'helpful', 'layman'], ['road', 'sreekaryam', 'ambadi', 'nagar', 'chithravila', 'lot', 'gutter', 'please', 'necessary', 'action', 'retar', 'road'], ['road', 'kotooli', 'mangotu', 'vayal', 'road', 'completely', 'digged', 'middle', 'pregnant', 'ladies', 'may', 'give', 'delivery', 'go', 'road', 'slippery', 'chance', 'high', 'please', 'something', 'kind', 'accidents', 'lot', 'kids', 'also', 'passing', 'road', 'chances', 'hitting', 'kids', 'driver', 'try', 'avoid', 'digged', 'part', 'middle', 'road', 'make', 'pedestrians', 'edge', 'may', 'result', 'hit', 'fall', 'resulting', 'injury', 'please', 'consider', 'solve', 'early', 'possible'], ['road', 'going', 'towards', 'trivandrum', 'technopark', 'phase', '3', 'gate', 'towards', 'technopark', 'buildings', 'road', 'starting', 'nippol', 'toyota', 'going', 'towards', 'kallingal', 'road', 'name', 'kallingal', 'attinkuzhy', 'road', 'road', 'damaged', 'last', '15', 'years', 'one', 'caring', 'minimum', '300', 'vehicles', 'daily', 'goes', 'morning', 'evening', 'towards', 'offices', 'like', '1', 'meter', 'gutter', 'middle', 'road', 'making', 'health', 'issues', 'people', 'danger', 'situation', 'urgent', 'action', 'required'], ['current', 'driving', 'licence', 'poor', 'make', 'like', 'pvc', 'card', 'digital', 'card'], ['roads', 'villages', 'proper', 'condition', 'people', 'travelplease', 'take', 'necessary', 'action', 'regarding'], ['road', 'full', 'pits'], ['submitted', 'road', 'condition', 'karukaputhurpallipadamthichur', 'palakkad', 'distis', 'pathetic', 'condition', 'even', 'suitable', 'footwalk', 'due', 'boarder', 'villages', 'two', 'constituency', 'mla', 'bothers', 'area', 'please', 'needful', 'earliest'], ['sir', 'public', 'wants', 'know', 'pwd', 'still', 'continuing', 'toll', 'charge', 'poovathumkadavu', 'bridge', 'poor', 'maintenance', 'road', 'street', 'light', 'misbehaviour', 'toll', 'collectors', 'passengers', 'every', 'day', 'public', 'suffering', 'area', 'whole', 'money', 'bridge', 'collected', 'public', 'gst', 'road', 'tax', 'insurance', 'money', 'going', 'nearby', 'mathilakam', 'bridge', 'toll', 'fee', 'stopped', '1', 'year', 'back'], ['road', 'ramamangalam', 'choondy', 'dug', 'works', 'related', 'kwh', 'condition', 'travel', 'used', 'travel', 'around', '40', 'km', 'daily', 'include', 'road', 'also'], ['register', 'complaint', 'poor', 'road', 'conditions', 'big', 'pot', 'holes', 'arookutty', 'aroor', 'road', 'alappuzha', 'district'], ['damaged', 'long', 'duration', 'potholes', 'converted', 'hidden', 'hazards', 'bikers', 'potential', 'risk', 'road', 'accidents'], ['roads', 'city', 'damaged', 'quality', 'needed'], ['keshavadasapuram', 'traffic', 'block', 'lack', 'planning'], ['low', 'quality', 'roads'], ['drivers', 'dont', 'know', 'correct', 'times', 'roots', 'many', 'bus', 'times'], ['tarring', 'roads', 'damaged', 'suddenly', 'reason', 'behind'], ['road', 'maintained', 'properly'], ['many', 'drivers', 'reckless', 'follow', 'road', 'rules', 'law', 'enforcement', 'lax', 'violations', 'makes', 'things', 'difficult', 'drivers', 'unpredictable', 'driving', 'others', 'road', 'pedestrians', 'walking', 'roadside', 'crossing', 'roads', 'makes', 'roads', 'dangerous', 'ordinary', 'citizens'], ['proper', 'maintenance', 'roads', 'leads', 'pot', 'holes', 'roads'], ['everybody', 'knows', 'highway', 'connecting', 'kochi', 'muvattupzha', 'one', 'busiest', 'crowed', 'road', 'ernakulam', 'city', 'withing', 'last', '3', 'years', 'steady', 'increase', 'unauthorized', 'road', 'side', 'business', 'establishments', 'small', 'tent', 'establishments', 'unauthorized', 'illegal', 'creating', 'lot', 'accidents', 'past', 'months', 'cars', 'bikes', 'tent', 'stop', 'immediately', 'see', 'shacks', 'created', 'sudden', 'unexpected', 'accidents', 'build', 'road', 'reduce', 'road', 'visibility', 'example', 'shack', 'next', 'peruvammuzhy', 'selling', 'fish', 'created', 'countless', 'accidents', 'hope', 'department', 'takes', 'actions', 'business', 'establishments', 'immediatelythe', 'effected', 'areas', 'kolenchery', 'valakom'], ['pathanapurm', 'pattazhy', 'road', 'maintained', 'road', '12m', 'width', 'plan', 'less', '5'], ['manathoor', 'maniykumpparakarimkunnam', 'road', 'worst', 'condition', 'construction', 'pala', 'thodupuzha', 'road', 'many', 'vehicles', 'used', 'road', 'shortcut', 'road', 'fully', 'destroyed', 'please', 'retarr', 'road', 'implement', 'proper', 'sign', 'boards', 'road', 'markings']]\n",
      "[['number', 'deaths', 'cardiovascular', 'disease', 'attributed', 'air', 'pollution', 'much', 'higher', 'expectedair', 'pollution', 'caused', 'twice', 'many', 'deaths', 'cvd', 'respiratory', 'diseases'], ['people', 'make', 'river', 'water', 'polluted', 'dumping', 'household', 'wastage', 'industrial', 'wastage'], ['due', 'sand', 'mining', 'effect', 'ecosystem', 'severe', 'impact', 'plants', 'animals', 'rivers'], ['areas', 'night', 'strangers', 'dumping', 'hotel', 'waste', 'domestic', 'waste', 'foul', 'smelling', 'sides', 'road', 'wastes', 'remain', 'th', 'road', 'uncleaned', 'camera', 'survelliance', 'facility', 'catch', 'people', 'throwing', 'wastes'], ['fishes', 'river', 'pampa', 'dying', 'massively', 'due', 'deposits', 'oil', 'factories', 'nearby'], ['construction', 'going', 'trivandrum', 'paddy', 'fields', 'please', 'take', 'necessary', 'steps', 'save', 'farming'], ['many', 'industries', 'dump', 'wastes', 'rivers', 'lakes', 'ponds', 'streams', 'attempt', 'hide', 'wastes', 'epa', 'nspectors', 'water', 'sources', 'feed', 'major', 'crops', 'food', 'becomes', 'contaminated', 'variety', 'chemicals', 'bacteria', 'causing', 'rampant', 'health', 'problems'], ['burning', 'plastics', 'public', 'places', 'cause', 'major', 'health', 'concern', 'rate', 'lung', 'cancer', 'patients', 'increasing', 'day', 'day', 'high', 'time', 'check', 'activities'], ['dumping', 'wastes', 'public', 'places', 'causes', 'major', 'health', 'issues', 'inviting', 'eradicated', 'disease', 'mechanism', 'collect', 'wastes', 'households', 'disposed', 'properly'], ['activities', 'like', 'waste', 'disposal', 'residential', 'commercial', 'industrial', 'areas', 'oil', 'spills', 'runoff', 'agriculture', 'contaminate', 'bodies', 'water'], ['overfishing', 'causes', 'reduction', 'diversity', 'marine', 'life', 'fishermen', 'considering', 'breeding', 'time'], ['artificial', 'light', 'night', 'one', 'obvious', 'physical', 'changes', 'humans', 'made', 'biosphere', 'artificial', 'light', 'also', 'affects', 'dispersal', 'orientation', 'migration', 'hormone', 'levels', 'resulting', 'disrupted', 'circadian', 'rhythms'], ['electronic', 'waste', 'problem', 'huge', 'electronics', 'end', 'landfills', 'toxics', 'like', 'lead', 'mercury', 'cadmium', 'leach', 'soil', 'water'], ['ocean', 'acidification', 'caused', 'co₂', 'dissolves', 'ocean', 'bonding', 'sea', 'water', 'creating', 'carbonic', 'acid', 'acid', 'reduces', 'ph', 'levels', 'water'], ['noise', 'produced', 'vehicles', 'political', 'parties', 'religious', 'centers', 'causes', 'great', 'harm', 'human', 'ears'], ['days', 'many', 'people', 'cutting', 'trees', 'purposes', 'example', 'many', 'oragansations', 'builders', 'cut', 'trees', 'build', 'projects', 'cause', 'real', 'harm', 'humans', 'also', 'utilizing', 'fertile', 'paddy', 'fields', 'construction', 'affect', 'environment', 'oxygen', 'content', 'air', 'become', 'low', 'oxygen', 'content', 'level', 'decreases', 'air', 'survival', 'living', 'beings', 'move', 'harder', 'way', 'also', 'major', 'factor', 'ozone', 'depletion', 'ozone', 'holes', 'formed', 'harmful', 'radiations', 'enter', 'earth', 'holes', 'causes', 'real', 'harm', 'living', 'beings', 'continues', 'way', 'threatening', 'part', 'lives', 'please', 'take', 'serious', 'issue', 'make', 'necessary', 'useful', 'remedies'], ['polution', 'ksrtc', 'bus', 'heavy', 'today', 'government', 'fix', 'soon', 'possible'], ['quarries', 'bad', 'environment', 'several', 'ways', 'abruptly', 'interrupt', 'continuity', 'open', 'space', 'cause', 'soil', 'erosion', 'air', 'dust', 'pollution', 'deterioration', 'water', 'quality', 'residential', 'area', 'create', 'noise', 'hazards', 'request', 'higher', 'authority', 'investigate', 'punish', 'officials', 'hand', 'quarrying', 'illegal', 'mining', 'time', 'government', 'create', 'awareness', 'potentially', 'negative', 'impact', 'quarrying'], ['save', 'alappad', 'stop', 'mining'], ['would', 'like', 'inform', 'city', 'residents', 'facing', 'difficulties', 'dump', 'domestic', 'wastes', 'humbly', 'request', 'take', 'necessary', 'actions'], ['preserving', 'biodiversity', 'saving', 'forest', 'help', 'overcome', 'issuesalso', 'recycling', 'avoiding', 'usage', 'plastic', 'efficient', 'use', 'fuel'], ['intolerable', 'temperature', 'change', 'summer', 'season', 'cause', 'dried', 'rivers', 'skin', 'disease'], ['intense', 'heat', 'summer'], ['one', 'among', 'factors', 'shaped', 'kerala', 'gods', 'country', 'euphoric', 'climate', 'never', 'touched', 'extremes', 'thanks', 'moderating', 'influence', 'sea', 'mighty', 'western', 'ghats', 'scenario', 'changed', 'lot', 'kerala', 'witnessing', 'unprecedental', 'surge', 'temperature', 'kumbhachoodu', 'termed', 'old', 'generation', 'time', 'high', 'impacting', 'livelihood', 'many'], ['due', 'excessive', 'use', 'chlorine', 'disinfectants', 'water', 'causing', 'long', 'term', 'health', 'problems', 'like', 'hair', 'fall', 'rashes', 'etc', 'amount', 'disinfectants', 'used', 'water', 'supplied', 'need', 'reconsidered'], ['projects', 'planting', 'trees', 'dont', 'cut', 'big', 'grownup', 'trees'], ['need', 'proper', 'regulations', 'control', 'pollution'], ['increased', 'deforestation', 'uncontrolled', 'constructiondevelopment', 'activities', 'vehicle', 'emissions', 'heavily', 'contribute', 'increase', 'temperature', 'government', 'build', 'new', 'policies', 'also', 'consider', 'switching', 'renewable', 'energy', 'sources'], ['pollution', 'levels', 'kochi', 'city', 'rising', 'rapidly', 'government', 'initiate', 'steps', 'curb'], ['waste', 'disposal', 'public', 'premises', 'make', 'life', 'hard', 'people', 'living', 'around']]\n",
      "\n",
      "\n",
      " Env Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " KSEB Count \n",
      "\n",
      "\n",
      "{'month': 1, 'failure': 2, 'say': 1, 'everyone': 1, 'transformer': 2, 'state': 1, 'industries': 1, 'devices': 1, 'set': 1, 'replace': 1, 'madavoor': 1, 'wrongly': 1, 'ease': 1, 'avoid': 1, 'loss': 1, 'meter': 2, 'procedure': 1, 'unnoticed': 1, 'electric': 2, 'major': 1, 'money': 1, 'bribe': 2, 'find': 1, 'exploded': 1, 'electrical': 1, 'old': 1, 'adjoining': 1, 'shortage': 1, 'evening': 1, 'farming': 1, 'past': 1, '700': 1, 'knows': 1, 'please': 3, 'night': 2, 'misbehaved': 1, 'sure': 1, 'morning': 1, 'though': 1, 'issue': 3, 'day': 2, 'rs': 1, 'three': 1, 'recently': 1, 'last': 2, 'section': 1, 'look': 1, 'trouble': 1, 'new': 2, 'crawl': 1, 'going': 1, 'many': 2, 'lot': 1, 'home': 2, 'communication': 1, 'give': 1, 'cuts': 3, 'phase': 2, 'use': 1, 'get': 1, 'city': 1, 'well': 1, 'load': 2, 'got': 4, 'action': 1, 'still': 1, 'continues': 1, 'lineman': 1, 'electronic': 1, 'till': 1, 'big': 1, 'houses': 1, 'always': 1, 'bad': 2, 'reason': 1, 'frequently': 1, 'years': 1, 'times': 1, 'low': 1, 'peoples': 1, 'current': 1, 'working': 4, 'daysremaining': 1, 'connectionplease': 1, 'lights': 2, 'prior': 2, 'months': 2, 'proper': 1, 'even': 3, 'house': 2, 'values': 1, 'scenario': 1, 'public': 1, 'locality': 2, 'employees': 1, 'power': 9, 'drunken': 1, 'unable': 1, 'normalplease': 1, 'burnt': 1, 'near': 1, 'grabbing': 1, 'hot': 1, 'result': 1, 'affect': 1, 'failures': 1, 'cut': 1, 'easily': 1, 'facing': 3, 'havent': 1, 'unavailability': 1, 'trivandrum': 1, 'overhead': 1, 'condition': 1, 'first': 1, 'necessary': 1, 'equipments': 1, 'supply': 2, 'phases': 1, 'corrupt': 1, 'robbery': 1, 'ensurde': 1, 'large': 1, 'complaint': 1, 'heavy': 1, 'damaged': 1, 'needed': 1, 'shedding': 2, 'rectified': 1, 'raining': 1, 'difficult': 1, 'makes': 1, 'particular': 1, 'failed': 1, 'regular': 1, 'daysplease': 1, 'problem': 3, 'connected': 1, 'examinations': 1, 'make': 2, 'comes': 1, 'sector': 2, 'connections': 1, 'summer': 1, 'almost': 1, 'request': 1, 'checking': 1, 'one': 2, 'applied': 1, 'fast': 1, 'time': 6, 'left': 1, 'announcements': 1, 'occurring': 1, 'take': 1, 'fix': 1, 'activities': 1, 'wires': 4, 'voltage': 3, 'must': 1, 'highly': 1, '15': 1, 'appliances': 1, 'every': 2, 'electricity': 7, 'using': 2, 'different': 1, 'due': 3, 'overall': 1, 'us': 2, 'peak': 1, 'platforms': 1, 'came': 1, '3': 1, 'street': 1, 'sound': 1, 'high': 3, 'fastly': 1, 'without': 2, 'repair': 2, 'showing': 1, 'notice': 1, 'frequent': 1, 'unsocial': 1, 'experiences': 1, 'since': 1, 'connection': 5, 'force': 1}\n",
      "\n",
      "\n",
      " KSRTC Count \n",
      "\n",
      "\n",
      "{'willing': 1, 'arrange': 1, 'busesplease': 1, 'atleast': 2, 'effective': 1, 'onky': 1, 'rudely': 1, 'standing': 1, 'percent': 1, 'services': 4, 'nadakkavu': 1, 'dont': 2, 'inform': 1, 'passenger': 2, 'kills': 1, 'carelessly': 1, 'venjaramoodu': 1, 'miss': 1, 'face': 1, 'alloted': 1, 'rashly': 1, 'rescheduling': 1, 'six': 1, 'locations': 1, 'past': 1, 'cottton': 1, 'feelplease': 1, 'equality': 1, 'control': 1, 'college': 4, 'helpful': 2, 'forget': 1, 'timings': 1, 'caused': 1, 'kazhakkuttam': 1, 'running': 1, 'hours': 2, 'bothered': 2, 'filled': 1, 'solely': 1, 'pasengers': 1, 'please': 1, 'night': 1, 'reach': 4, 'kumarakam': 2, 'morning': 2, 'shortcuts': 1, 'sometimes': 1, 'trivandrumidukkikattappana': 1, 'man': 1, 'day': 1, '23': 1, 'city': 4, 'balance': 1, 'recently': 3, 'stopped': 1, 'frequently': 1, 'brutally': 1, 'kattakkada': 1, 'local': 1, 'provide': 2, 'going': 2, 'spend': 1, 'occupied': 1, 'busses': 2, 'difficulty': 1, 'keep': 1, 'innocent': 1, 'females': 1, 'dependable': 1, 'kulathurstudents': 1, 'see': 2, 'rushy': 1, 'time': 4, 'conductor': 1, 'great': 1, 'safety': 1, 'causing': 1, 'government': 1, 'accidents': 1, 'damage': 1, 'one': 1, 'intended': 1, 'get': 1, 'sir': 1, 'authorites': 1, 'well': 1, 'sreekaryam': 1, 'got': 2, 'action': 2, 'leave': 1, 'mukkam': 1, 'area': 2, 'give': 1, 'school': 1, 'venjaramood': 1, 'fully': 1, 'always': 1, 'usually': 1, 'reason': 1, 'lady': 1, 'done': 1, 'times': 1, 'low': 1, 'several': 1, 'due': 3, 'proper': 1, 'even': 3, 'safer': 1, 'town': 1, 'daily': 1, 'public': 3, 'lack': 2, 'student': 1, 'change': 1, 'reserved': 2, 'us': 1, 'travelled': 1, 'risk': 1, 'drove': 1, 'value': 1, 'inconvenience': 1, 'confirm': 1, 'upon': 1, 'road': 2, 'class': 1, 'transportation': 1, 'bus': 14, 'kindly': 1, 'present': 1, '25': 1, 'workers': 1, 'super': 1, 'limited': 1, 'life': 1, 'destination': 1, 'right': 1, 'ignoring': 1, 'schedule': 1, 'would': 4, 'trivandrum': 1, 'route': 3, 'hit': 1, 'necessary': 1, 'increase': 1, 'ask': 1, 'week': 1, 'around': 3, 'reaching': 1, 'regular': 1, 'much': 1, 'femalesas': 1, 'stationso': 1, 'found': 1, 'income': 1, 'amount': 1, 'cant': 1, 'none': 1, 'hoping': 1, 'ymcacross': 1, 'kattakada': 1, 'travellers': 1, 'speed': 1, 'kottayam': 1, 'given': 1, 'kottukunnam': 1, 'reduced': 1, 'kl157912': 1, 'raining': 1, 'traveller': 1, 'cancelled': 1, 'difficult': 1, 'driver': 2, 'rural': 1, 'others': 1, 'behave': 1, 'people': 3, 'number': 2, 'took': 1, 'add': 1, 'ksrtc': 8, 'crossing': 1, 'heavily': 1, 'travelling': 1, 'seat': 4, 'femalesthen': 1, 'male': 1, 'travel': 1, 'problem': 3, 'via': 1, 'make': 1, 'busesatleast': 1, 'dashed': 1, 'lots': 2, 'almost': 1, 'conductors': 1, 'request': 2, 'argue': 1, 'person': 1, 'experienced': 1, 'fast': 2, 'whole': 1, 'areas': 1, 'late': 3, 'work': 1, 'needful': 1, 'facing': 1, 'students': 3, 'busy': 1, 'earlier': 1, 'lines': 1, 'station': 1, '730': 1, 'seats': 4, 'choose': 1, 'causes': 1, 'convenient': 1, 'buseskindly': 1, '2': 1, 'totally': 1, 'depending': 1, 'passengers': 3, 'buses': 10, 'take': 2, 'transport': 2, 'using': 1, 'hill': 1, 'noticed': 1, 'behaving': 1, 'stopping': 1, 'word': 1, 'back': 2, 'mid': 1, 'came': 1, 'stop': 4, 'depend': 1, 'vehicles': 1, 'least': 1, 'like': 1, 'overspeeding': 2, 'muvattupuza': 1, 'use': 1, 'car': 4, 'service': 5, 'tired': 1, 'railway': 2, 'commute': 2, 'arrive': 1, 'ernakulam': 1, 'advice': 1, 'travelyesterday': 1, 'drivers': 4, 'never': 1, 'ran': 1, 'access': 1}\n",
      "\n",
      "\n",
      " PWD Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " KSRTC Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'water_freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-142249bbaa54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;31m#x.most_repeated_keyword_lib(dfenv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m \u001b[0mwater_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpwd_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mksrtc_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkseb_lis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-142249bbaa54>\u001b[0m in \u001b[0;36mjump\u001b[0;34m(self, status)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mwater_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpwd_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mksrtc_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkseb_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv_lis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_repeated_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwater_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpwd_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mksrtc_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkseb_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv_freq\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwater_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpwd_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mksrtc_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkseb_lis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'water_freq' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "from gensim.summarization import keywords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "global dataset\n",
    "\n",
    "\n",
    "class Main:\n",
    "         \n",
    "    global departments\n",
    "    \n",
    "    \n",
    "    def __init__(self,dataset):\n",
    "        #/home/gayathri/project/MakeComplaint/data.csv\n",
    "        self.dataset=dataset\n",
    "        #print(self.dataset)\n",
    "        self.dataset= pd.read_csv(self.dataset)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def department_class(self):\n",
    "        departments=self.dataset['Departments'].unique() \n",
    "        return departments\n",
    "        \n",
    "    \n",
    "    def punctuate(self):\n",
    "        punctuations = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
    "        text=self.dataset['Subject']\n",
    "\n",
    "        # To take input from the user\n",
    "        # my_str = input(\"Enter a string: \")\n",
    "\n",
    "        # remove punctuation from the string\n",
    "        no_punct = \"\"\n",
    "        no_punctuate =[]\n",
    "        for char in  self.dataset['Subject']:\n",
    "\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "                no_punctuate.append(no_punct)\n",
    "\n",
    "        # display the unpunctuated string\n",
    "        #print(no_punctuate)\n",
    "        return(no_punctuate)\n",
    "\n",
    "        \n",
    "    def data_clean(self):\n",
    "        \n",
    "        \n",
    "       \n",
    "        print(self.dataset.head())\n",
    "        # unpunctuate and lower case\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "            # unpunctuate and lower case\n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint'].str.replace(',',' ').str.lower() \n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Complaint'] = self.dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\P{P}-]','').str.lower()\n",
    "        #print( self.dataset.head())\n",
    "\n",
    "\n",
    "\n",
    "        #rRemoving new lines in the subject field\n",
    "        self.dataset['Subject'] =  self.dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "        #removing Numeric \n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint']\n",
    "        print( self.dataset.head())\n",
    "        \n",
    "    def dataframing(self,dataset):\n",
    "        # creating dataframe for each departments\n",
    "        water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "        pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "        ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "        kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "        env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "        print(env.shape)    #(30, 4)\n",
    "        #print(water.shape)  #(39, 4)\n",
    "        #print(pwd.shape)    #(42, 4)\n",
    "        #print(ksrtc.shape)  #(17, 4)\n",
    "        #print(kseb.shape)   #(22, 4)\n",
    "        #dataset.head()\n",
    "        #print(pwd)\n",
    "\n",
    "  \n",
    "\n",
    "        #Filtering out Subjects and complaints from the dataframe\n",
    "        df_water = water[['Subject','Complaint']]\n",
    "        df_pwd   = pwd[['Subject','Complaint']]\n",
    "        df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "        df_kseb  = kseb[['Subject','Complaint']]\n",
    "        df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "        dfwater  = df_water[['Subject','Complaint']]\n",
    "        dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "        dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "        dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "        dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "        \n",
    "        dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "        dfwater=dfwater[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "        dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "        dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "        dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "        dfenv =dfenv [['Subject_and_Complaint']]\n",
    "        print(dfenv )\n",
    "        return (dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "        \n",
    "        \n",
    "    def tokenisation(self,dfwater,dfpwd,dfksrtc,dfkseb,dfenv):\n",
    "        water_token = []\n",
    "        water_list=[]\n",
    "            #Tokenising water data\n",
    "            \n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        #lemmatizer.lemmatize(\"corpora\")\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i, row in dfwater.iterrows():\n",
    "                #print(i,row['Subject'], row['Complaint'])\n",
    "                \n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in water_token if not i in stop_words]\n",
    "            #lemmatized_output = [i for i in lemmatizer.lemmatize(i) for i in result]\n",
    "        \n",
    "            water_list.append(result)\n",
    "        print(\"\\n\\nWater Tokens\\n\\n\")\n",
    "        print(water_list)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "        pwd_token = []\n",
    "\n",
    "        pwd_list = []\n",
    "        #Tokenising pwd data  \n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result1 = [i for i in pwd_token if not i in stop_words]\n",
    "            pwd_list.append(result1)\n",
    "            \n",
    "        print(\"\\n\\nPWD Tokens\\n\\n\")\n",
    "        print(pwd_list)\n",
    "            \n",
    "            #print( pwd_token)\n",
    "\n",
    "\n",
    "        ksrtc_token =[]\n",
    "        ksrtc_list =[]\n",
    "        #Tokenising ksrtc data    \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in ksrtc_token if not i in stop_words]\n",
    "            ksrtc_list.append(result)\n",
    "            #print(ksrtc_list)\n",
    "            #print( ksrtc_token)\n",
    "            \n",
    "            \n",
    "            \n",
    "        kseb_token = []\n",
    "        kseb_list= []\n",
    "        #Tokenising kseb data    \n",
    "        for i, row in dfkseb.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in kseb_token if not i in stop_words]\n",
    "            kseb_list.append(result)\n",
    "        #print(kseb_list)\n",
    "        #print(kseb_token)\n",
    "        \n",
    "        \n",
    "        env_token = []\n",
    "        env_list = []\n",
    "        #Tokenising env data  \n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in env_token if not i in stop_words]\n",
    "            env_list.append(result)\n",
    "        print(env_list)\n",
    "            #print(env_token)\n",
    "        return(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "\n",
    "\n",
    "   \n",
    "    def word_frequency(self,water_list,pwd_list,ksrtc_list,kseb_list,env_list):\n",
    "        \n",
    "        #word frequencies  Environment department\n",
    "\n",
    "        wordfreq = []\n",
    "       \n",
    "    \n",
    "        for word  in env_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        env_count =Counter(wordfreq)\n",
    "        env_count= dict(env_count)\n",
    "        print(\"\\n\\n Env Count \\n\\n\")\n",
    "        print(type(env_count))\n",
    "        \n",
    "    \n",
    "        #word frequencies  KSEB department\n",
    "        wordfreq = []\n",
    "        for word  in kseb_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        kseb_count = Counter(wordfreq)\n",
    "        kseb_count= dict(kseb_count) \n",
    "        print(\"\\n\\n KSEB Count \\n\\n\")\n",
    "        print(kseb_count)\n",
    "    \n",
    "\n",
    "        \n",
    "        #word frequencies  KSRTC department\n",
    "\n",
    "        wordfreq = []\n",
    "        \n",
    "        for word  in ksrtc_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        ksrtc_count =Counter(wordfreq)\n",
    "        ksrtc_count= dict(ksrtc_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(ksrtc_count)\n",
    "    \n",
    "        \n",
    "        #word frequencies  pwd department\n",
    "\n",
    "        for word  in pwd_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        pwd_count =Counter(wordfreq)\n",
    "        pwd_count = dict(pwd_count)\n",
    "        print(\"\\n\\n PWD Count \\n\\n\")\n",
    "        print(type(pwd_count))\n",
    "        \n",
    "        \n",
    "        #word frequencies  water department\n",
    "\n",
    "        wordfreq = []\n",
    "        for word  in water_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        water_count =Counter(wordfreq)\n",
    "        water_count= dict(water_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(type(water_count))\n",
    "        return(water_count,pwd_count,ksrtc_count,kseb_count,env_count)\n",
    "\n",
    "\n",
    "    def most_repeated_keywords(self,water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq ):\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n Water Freq newwwwwwwwww\")\n",
    "        print(water_freq)\n",
    "        \n",
    "        #print sorted(prices.iteritems(), lambda x, y : cmp(x[1], y[1]))\n",
    "\n",
    "        \n",
    "        water_lis =[]\n",
    "        water_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in water_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        water_dict=(items[:5])\n",
    "        water_lis.append(water_dict)\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        print(\"\\n\\nKEYWORDS  WATER\\n\\n\")\n",
    "        print(water_lis)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n PWD Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        pwd_lis =[]\n",
    "        pwd_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in pwd_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        pwd_dict=(items[:5])\n",
    "        pwd_lis.append(pwd_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  PWD\\n\\n\")\n",
    "        print(pwd_lis)\n",
    "        \n",
    "        \n",
    "        # Finding the most repeated words kseb\n",
    "        print(\"\\n\\n KSEB Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        kseb_lis =[]\n",
    "        kseb_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in kseb_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        kseb_dict=(items[:5])\n",
    "        kseb_lis.append(kseb_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSEB\\n\\n\")\n",
    "        print(kseb_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words ksrtc\n",
    "\n",
    "        print(\"\\n\\n KSRTC Freq newwwwwwwwww\")\n",
    "        print(ksrtc_freq)\n",
    "        \n",
    "        \n",
    "        ksrtc_lis =[]\n",
    "        ksrtc_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in ksrtc_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        ksrtc_dict=(items[:5])\n",
    "        ksrtc_lis.append(ksrtc_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSRTC\\n\\n\")\n",
    "        print(ksrtc_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words env\n",
    "        env_lis =[]\n",
    "      \n",
    "        #env_freq_list = { }\n",
    "        for lists in env_freq:\n",
    "            #env_freq_list.update({})\n",
    "            lists=dict(lists)\n",
    "            items = [(v, k) for k, v in lists.items()]\n",
    "            #print(type(items))\n",
    "            items.sort()\n",
    "            items.reverse()\n",
    "            items = [k for v, k in items]\n",
    "            #print(items)\n",
    "            env_dict=(items[0:4])\n",
    "            #print(env_dict)\n",
    "            env_lis.append(env_dict) \n",
    "        \n",
    "                \n",
    "        print(\"\\n\\nKEYWORDS  ENV\\n\\n\")\n",
    "        print(env_lis)\n",
    "       \n",
    "        \n",
    "        \n",
    "        return(water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis )\n",
    "                \n",
    "        \n",
    "    def most_repeated_keyword_lib(self,dfenv,dfwater,dfpwd,dfksrtc,dfkseb):\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        env_keyword = []\n",
    "        env_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : ENV\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in env_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            env_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            env_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(env_summary)\n",
    "        \n",
    "        # water Keyword\n",
    "        \n",
    "        water_keyword = []\n",
    "        water_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : Water\\n\\n\")\n",
    "        \n",
    "        \n",
    "        for i, row in dfwater.iterrows():\n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in water_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            water_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            water_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(water_summary)\n",
    "        \n",
    "        \n",
    "        #pwd keyword\n",
    "        \n",
    "        pwd_keyword = []\n",
    "        pwd_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : PWD\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in pwd_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            pwd_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            pwd_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(pwd_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        ksrtc_keyword = []\n",
    "        ksrtc_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSRTC\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in ksrtc_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            ksrtc_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            ksrtc_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(ksrtc_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        kseb_keyword = []\n",
    "        kseb_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSEB\\n\\n\")\n",
    "        #print(dfkseb)\n",
    "        \n",
    "        for i, row in dfkseb.iterrows():\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in kseb_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            kseb_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            kseb_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(kseb_summary)\n",
    "        return(env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def jump(self,status):\n",
    "        if status == 1:\n",
    "            env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary=self.most_repeated_keyword_lib(dfenv,dfwater,dfpwd,dfksrtc,dfkseb)\n",
    "        else:\n",
    "            \n",
    "            water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis = self.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq )\n",
    "        return(water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis)\n",
    "            \n",
    "    def test(self):\n",
    "        text_data = input(\"Enter complaint\")\n",
    "        text_data= text_data.replace('[^\\w\\s]','').lower()\n",
    "        \n",
    "        \n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "        for x in text_data.lower(): \n",
    "            if x in punctuations: \n",
    "                text_data = text_data.replace(x, \" \") \n",
    "  \n",
    "   \n",
    "        print(text_data) \n",
    "        \n",
    "            \n",
    "        test_token = word_tokenize(text_data)\n",
    "        print(test_token)\n",
    "        test_list =[]\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i in test_token:\n",
    "            \n",
    "            \n",
    "            if i not in stop_words:\n",
    "        \n",
    "                test_list.append(i)\n",
    "        print(test_list)\n",
    "        \n",
    "        #frequency : \n",
    "        \n",
    "\n",
    "        \n",
    "        counts = Counter(test_list)\n",
    "        count = dict(counts)\n",
    "        print(count)  # word frequency\n",
    "    \n",
    "        items = [(v, k) for k, v in counts.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)  # sorted high to low\n",
    "        test_dict=(items[0:5])\n",
    "        print(test_dict)  #key only\n",
    "        \n",
    "        return(test_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept):\n",
    "        #keyword matching \n",
    "        #water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis\n",
    "        print(\"\\n\\nTest Keywords \\n \\n\")\n",
    "        print(keywords)\n",
    "        \n",
    "        \n",
    "        #pwd predict\n",
    "        pwd_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in pwd_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                pwd_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n PWD predict \\n\\n\")    \n",
    "        print(pwd_predict)\n",
    "        \n",
    "        #water predict\n",
    "        \n",
    "        \n",
    "        water_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in water_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                water_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n Water predict \\n\\n\")    \n",
    "        print(water_predict)\n",
    "        \n",
    "         #ksrtc predict\n",
    "        \n",
    "        \n",
    "        ksrtc_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in ksrtc_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                ksrtc_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n ksrtc predict \\n\\n\")    \n",
    "        print(ksrtc_predict)\n",
    "        \n",
    "        #kseb predict\n",
    "        \n",
    "        kseb_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in kseb_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                kseb_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n kseb predict \\n\\n\")    \n",
    "        print(kseb_predict)\n",
    "        \n",
    "        \n",
    "        #env predict\n",
    "        \n",
    "        env_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in env_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                env_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\nenv predict \\n\\n\")    \n",
    "        print(env_predict)\n",
    "        \n",
    "        department=dept\n",
    "        dept_values =[1,2,3,4,5]\n",
    "        depart_dict = dict(zip(dept_values,department))\n",
    "        print(depart_dict)\n",
    "        \n",
    "        if len(env_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[5])\n",
    "            \n",
    "        if len(pwd_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[2])\n",
    "            \n",
    "        if len(water_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[1])\n",
    "            \n",
    "        if len(kseb_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[3])\n",
    "            \n",
    "        if len(ksrtc_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[4])\n",
    "            \n",
    "            \n",
    "        \n",
    "                  \n",
    "        \n",
    "        \n",
    "file =   '/home/gayathri/project/MakeComplaint/data.csv'   \n",
    "\n",
    "x= Main(file)\n",
    "x.punctuate()\n",
    "x.data_clean()\n",
    "dfwater,dfpwd,dfksrtc,dfkseb,dfenv=x.dataframing(x.dataset)\n",
    "\n",
    "water_list,pwd_list,ksrtc_list,kseb_list,env_list = x.tokenisation(dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "\n",
    "water_count,pwd_count,ksrtc_count,kseb_count,env_count = x.word_frequency(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "#x.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq)\n",
    "#x.most_repeated_keyword_lib(dfenv) \n",
    "\n",
    "water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis=x.jump(0)\n",
    "\n",
    "keywords=x.test()\n",
    "dept=x.department_class()\n",
    "x.evaluate(keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
