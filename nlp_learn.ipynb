{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using NLTK library, we can do lot of text preprocesing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#function to split text into word\n",
    "\n",
    "tokens = word_tokenize(\"The quick brown fox jumps over the lazy dog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "print(word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english')) \n",
    "print(stopWords)\n",
    "phrases = sent_tokenize(data)\n",
    "words = word_tokenize(data)\n",
    " \n",
    "print(phrases)\n",
    "print(words)\n",
    "wordsFiltered = []\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "print(wordsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopword removal\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english')) \n",
    "print(stopWords)\n",
    "words = word_tokenize(data)\n",
    "wordsFiltered = []\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "print(wordsFiltered)\n",
    "print(len(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "#3 stemmer alogirthms are used here\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "# went is not working\n",
    "words = [\"go\",\"went\",\"gone\",\"games\"]\n",
    "ps = PorterStemmer()\n",
    "lanca_stemmer = LancasterStemmer()\n",
    "sb_stemmer = SnowballStemmer(\"english\",)\n",
    "print(\"=========Porter Stemmer======\")\n",
    "for w in words:\n",
    "    print(w ,\" : \" ,ps.stem(w))\n",
    "    \n",
    "print(\"=========Lanca Stemmer======\")\n",
    "for w in words:\n",
    "\n",
    "    print(w ,\" : \" ,lanca_stemmer.stem(w))\n",
    "    \n",
    "print(\"=========Snowball Stemmer======\")\n",
    "for w in words:\n",
    "    \n",
    "    print(w ,\" : \" ,sb_stemmer.stem(w))\n",
    "    \n",
    "    \n",
    " #Porter stemmer and Snowball stemmer working in similar manner   \n",
    "#lanca is not so good\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speech tagging\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "document = 'Whether you\\'re new to programming or an experienced developer, it\\'s easy to learn and use Python.'\n",
    "sentences = nltk.sent_tokenize(document) \n",
    "for sent in sentences:\n",
    "    print(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering from Speech tagging\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "document = 'Today the Netherlands celebrates King\\'s Day. To honor this tradition, the Dutch embassy in San Francisco invited me to'\n",
    "sentences = nltk.sent_tokenize(document)  \n",
    "data = []\n",
    "for sent in sentences:\n",
    "    data = data + nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "for w in data:\n",
    "    if 'VB' in w[1]:\n",
    "        print(w)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#natural language prediction\n",
    "import nltk\n",
    "\n",
    " \n",
    "from nltk.corpus import names\n",
    "\n",
    "def gender_features(word): \n",
    "    return {'last_letter': word[-1]}\n",
    "\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "train_set = featuresets\n",
    "classifier = nltk.MaxentClassifier.train(train_set) \n",
    "print(classifier.classify(gender_features('Frank')))\n",
    "name = input(\"Name: \")\n",
    "print(classifier.classify(gender_features(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]\n",
    " \n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
    " \n",
    "train_set = negative_features + positive_features + neutral_features\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "neg = 0\n",
    "pos = 0\n",
    "sentence = \"Awesome movie, I liked it\"\n",
    "sentence = sentence.lower()\n",
    "words = sentence.split(' ')\n",
    "for word in words:\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    " \n",
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "print('Negative: ' + str(float(neg)/len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree ['This', 'is', 'Gayathri', \"'s\", 'book', 'is', \"n't\", 'it', '?']\n",
      "WordPunct ['This', 'is', 'Gayathri', \"'\", 's', 'book', 'isn', \"'\", 't', 'it', '?']\n",
      "porter stemmer\n",
      "Lemmatizer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "\n",
    "#Tokenize using TreeBank Tokenizer\n",
    "\n",
    "text=\"This is Gayathri's book isn't it?\"\n",
    "\n",
    "tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "tokenizer1=nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "tokens=tokenizer.tokenize(text)\n",
    "tokens1=tokenizer1.tokenize(text) #wordPunct\n",
    "\n",
    "print(\"Tree\", tokens)\n",
    "print(\"WordPunct\" ,tokens1)\n",
    "\n",
    "#stemmer\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "print(\"porter stemmer\")\n",
    "\" \".join(stemmer.stem(token)for token in tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jump over the lazy dog'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "\n",
    "#Tokenzie using TreeBank Tokenizer\n",
    "\n",
    "text=\"This is Gayathri's book isn't it?\"\n",
    "\n",
    "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\" \".join(lemmatizer.lemmatize(token)for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'is', 'was', 'kay', 'the', 'stop', 'words', 'filtration', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " ',',\n",
       " 'showing',\n",
       " 'kay',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'filtration',\n",
       " '.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "sentence= []\n",
    "def stopword_remove(tokens):\n",
    "      \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    print(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\n",
    "                     \n",
    "    \n",
    "    \n",
    "    \n",
    "example_sent = \"This is a sample sentence, showing off is was kay the stop words filtration.\"\n",
    "\n",
    "tokens = word_tokenize(example_sent)\n",
    "#print(type(tokens))\n",
    "stopword_remove(tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['a', 't', 'hers', 'do', 'above', 'any', 're', 'up', 'other', 'about', 'doing', 'further', 'then', 'if', 'when', 'myself', \"should've\", 'our', 'we', 'off', 'between', \"wouldn't\", 'because', 'don', 'my', 'being', 'himself', 'down', 'of', 'and', 'for', \"hasn't\", \"you'll\", 'against', 'each', 'them', 'their', 'ma', 'only', 'over', \"you're\", \"shan't\", 'y', 'are', 'o', 'very', 'all', 'your', 'wouldn', 'he', 'below', 'more', 'nor', 'mightn', 'by', 'once', 'while', 'wasn', 'as', \"weren't\", 'yourself', 'who', 'which', 'ourselves', 'ours', 'itself', 'yours', 'herself', 'no', \"won't\", 'haven', 'both', 'not', 'or', 'has', 'what', 'have', 'so', \"needn't\", 'm', 'didn', 'mustn', 'this', 'themselves', 'under', 'you', \"mustn't\", 'be', \"shouldn't\", \"didn't\", \"haven't\", 'same', 'doesn', 'am', 'with', \"wasn't\", 'until', 'she', 'had', 'him', 'it', 'that', 'into', 'shan', 'to', 'just', 'an', 'before', \"she's\", 'such', 'yourselves', 'theirs', 's', 'now', 'but', 'those', \"hadn't\", \"it's\", 'from', 'on', \"couldn't\", 'hadn', \"that'll\", \"don't\", 'is', 'the', 'having', 'out', 'd', 'during', 'at', 'won', 'was', 'here', 'were', 'me', \"isn't\", 'i', 'they', \"aren't\", 'his', 'too', 'there', \"you'd\", 'isn', 'been', \"you've\", 've', 'shouldn', 'again', 'most', 'did', 'should', 'its', 'how', \"doesn't\", 'whom', 'after', 'needn', 'weren', 'in', 'these', 'aren', 'does', 'ain', 'will', 'couldn', 'through', 'why', 'own', 'few', 'hasn', 'can', 'than', 'some', 'll', 'where', 'her', \"mightn't\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'sample',\n",
       " 'sentence',\n",
       " ',',\n",
       " 'showing',\n",
       " 'kay',\n",
       " 'stop',\n",
       " 'words',\n",
       " 'filtration',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "sentence= []\n",
    "def stopword_remove(tokens):\n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = list(stop_words)\n",
    "    print(stop_words)\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\n",
    "                     \n",
    "    \n",
    "    \n",
    "    \n",
    "example_sent = \"This is a sample sentence, showing off is was kay the stop words filtration.\"\n",
    "tokens = word_tokenize(example_sent)\n",
    "print(type(tokens))\n",
    "stopword_remove(tokens)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLTK', 'leading', 'platform', 'building', 'Python', 'programs', 'work', 'human', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "input_str = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(input_str)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 305\n",
      "First ten stop words: ['everywhere', 'a', 'noone', 'hers', 'do', 'onto', 'another', 'above', 'any', 'somewhere']\n",
      "\n",
      "['NLTK', 'leading', 'platform', 'building', 'Python', 'programs', 'work', 'human', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:10])\n",
    "doc = spacy_nlp('NLTK is a leading platform for building Python programs to work with human language data.')\n",
    "tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "print()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ea404cf1237f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m#tokenizer=nltk.tokenize.TreebankWordTokenizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mwater_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject_and_Complaint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwater_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;31m#result = [i for i in water_token if not i in stop_words]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-ea404cf1237f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m#tokenizer=nltk.tokenize.TreebankWordTokenizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mwater_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject_and_Complaint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwater_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;31m#result = [i for i in water_token if not i in stop_words]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "#Data cleaning\n",
    "\n",
    "# 1. unpunctuate \n",
    "# 2. to lower\n",
    "# 3. Remove numerals\n",
    "# 4. Remove Newline for subject\n",
    "\n",
    "\n",
    "# Data loading\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Subject'] = dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Complaint'] = dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower() \n",
    "\n",
    "\n",
    "#rRemoving new lines in the subject field\n",
    "dataset['Subject'] = dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "#removing Numeric \n",
    "dataset['Complaint'] = dataset['Complaint']\n",
    "\n",
    "\n",
    "# creating dataframe for each departments\n",
    "water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "\n",
    "#print(env.shape)    #(29, 4)\n",
    "#print(water.shape)  #(17, 4)\n",
    "#print(pwd.shape)    #(39, 4)\n",
    "#print(ksrtc.shape)  #(13, 4)\n",
    "#print(kseb.shape)   #(22, 4)\n",
    "#dataset.head()\n",
    "#print(pwd)\n",
    "\n",
    "#Filtering out Subjects and complaints from the dataframe\n",
    "df_water = water[['Subject','Complaint']]\n",
    "df_pwd   = pwd[['Subject','Complaint']]\n",
    "df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "df_kseb  = kseb[['Subject','Complaint']]\n",
    "df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "dfwater  = df_water[['Subject','Complaint']]\n",
    "dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = Water\n",
    "dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "dfwater=dfwater[['Subject_and_Complaint']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = PWD\n",
    "dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "#print(dfpwd)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = ksrtc\n",
    "dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "#print(dfksrtc)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = kseb\n",
    "dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "#print(dfkseb)\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = env\n",
    "dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "dfenv =dfenv [['Subject_and_Complaint']]\n",
    "#print(dfenv )\n",
    "\n",
    "#==================================Tokenization Begins : =============================================\n",
    "\n",
    "\n",
    "print(type(doc ))\n",
    "#print(tokens)\n",
    "\n",
    "sentence= []\n",
    "\"\"\"def stopword_remove(tokens):\n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = list(stop_words)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\"\"\"\n",
    "    \n",
    "                     \n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "water_token = []\n",
    "#Tokenising water data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i, row in dfwater.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    #tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "    tokens = [token.text for water_token in doc if not token.is_stop]\n",
    "    #result = [i for i in water_token if not i in stop_words]\n",
    "    print(result)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "\n",
    "  \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(type(tokens))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "pwd_token = []\n",
    "#Tokenising pwd data    \n",
    "for i, row in dfpwd.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    pwd_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( pwd_token)\n",
    "\n",
    "ksrtc_token =[]\n",
    "#Tokenising ksrtc data    \n",
    "for i, row in dfksrtc.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    ksrtc_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( ksrtc_token)\n",
    "\n",
    "kseb_token = []\n",
    "#Tokenising kseb data    \n",
    "for i, row in dfkseb.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    kseb_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(kseb_token)\n",
    "\n",
    "env_token = []\n",
    "#Tokenising env data    \n",
    "for i, row in dfenv.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    env_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(env_token)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================Original==================================================================\n",
      "There is a road going towards Trivandrum Technopark Phase 3 and it has a gate towards the Technopark buildings from this road. It is starting from Nippol Toyota and going towards Kallingal . The road name is Kallingal - Attinkuzhy Road. This Road is damaged for last 1.5 years and no one is caring about this. there are minimum 300 vehicles daily goes through it in the morning and evening towards offices. Now it is like 1 meter gutter in the middle of the road making health issues to the people. It is in very danger situation. URGENT action required.\n",
      "===================================Processed================================================================\n",
      "there is a road going towards trivandrum technopark phase  and it has a gate towards the technopark buildings from this road. it is starting from nippol toyota and going towards kallingal . the road name is kallingal - attinkuzhy road. this road is damaged for last . years and no one is caring about this. there are minimum  vehicles daily goes through it in the morning and evening towards offices. now it is like  meter gutter in the middle of the road making health issues to the people. it is in very danger situation. urgent action required.\n",
      "=========================================Summary==========================================================\n",
      "it is starting from nippol toyota and going towards kallingal .\n",
      "the road name is kallingal - attinkuzhy road.\n",
      "this road is damaged for last .\n",
      "now it is like  meter gutter in the middle of the road making health issues to the people.\n",
      "==================================Keywords=================================================================\n",
      "technopark\n",
      "road\n",
      "meter\n",
      "vehicles daily\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "text = \"There is a road going towards Trivandrum Technopark Phase 3 and it has a gate towards the \"+ \\\n",
    "\"Technopark buildings from this road. It is starting from Nippol Toyota and going towards \"+\\\n",
    "\"Kallingal . The road name is Kallingal - Attinkuzhy Road. This Road is damaged for last 1.5 \"+\\\n",
    "\"years and no one is caring about this. there are minimum 300 vehicles daily goes through it in \"+\\\n",
    "\"the morning and evening towards offices. Now it is like 1 meter gutter in the middle of the road \"+\\\n",
    " \"making health issues to the people. It is in very danger situation. URGENT action required.\"\n",
    "print(\"================================Original==================================================================\")\n",
    "print(text)\n",
    "\n",
    "text = text.strip().lower()\n",
    "\n",
    "#text=text.re.sub('[^a-zA-Z ]',\"\")\n",
    "\n",
    "#text = nltk.sent_tokenize(text)\n",
    "output = re.sub(r'\\d+', '', text)\n",
    "print(\"===================================Processed================================================================\")\n",
    "print(output)\n",
    "\n",
    "print(\"=========================================Summary==========================================================\")\n",
    "print(summarize(output, ratio = 0.5))\n",
    "print(\"==================================Keywords=================================================================\")\n",
    "\n",
    "print(keywords(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'road', 'going', 'towards', 'Trivandrum', 'Technopark', 'Phase', 'gate', 'towards', 'Technopark', 'buildings', 'road', 'It', 'starting', 'Nippol', 'Toyota', 'going', 'towards', 'Kallingal', 'The', 'road', 'name', 'Kallingal', 'Attinkuzhy', 'Road', 'This', 'Road', 'damaged', 'last', 'years', 'one', 'caring', 'minimum', 'vehicles', 'daily', 'goes', 'morning', 'evening', 'towards', 'offices', 'Now', 'like', 'meter', 'gutter', 'middle', 'road', 'making', 'health', 'issues', 'people', 'It', 'danger', 'situation', 'URGENT', 'action', 'required']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#method 2 summarisation\n",
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "article_text = \"There is a road going towards Trivandrum Technopark Phase 3 and it has a gate towards the \"+ \\\n",
    "\"Technopark buildings from this road. It is starting from Nippol Toyota and going towards \"+\\\n",
    "\"Kallingal . The road name is Kallingal - Attinkuzhy Road. This Road is damaged for last 1.5 \"+\\\n",
    "\"years and no one is caring about this. there are minimum 300 vehicles daily goes through it in \"+\\\n",
    "\"the morning and evening towards offices. Now it is like 1 meter gutter in the middle of the road \"+\\\n",
    " \"making health issues to the people. It is in very danger situation. URGENT action required.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  \n",
    "article_text = re.sub(r'\\s+', ' ', article_text)  \n",
    "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )  \n",
    "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)  \n",
    "sentence_list = nltk.sent_tokenize(article_text)  \n",
    "word_frequencies = []\n",
    "tokenize = nltk.word_tokenize(formatted_article_text)\n",
    "\n",
    "tok =[]\n",
    "for word in tokenize:\n",
    "    result = [i for i in tokenize if not i in stop_words]\n",
    "print(result) \n",
    "\n",
    "word_frequencies = {}  \n",
    "for word in  tokenize:\n",
    "     if word not in stop_words:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "                \n",
    "maximum_frequncy = max(word_frequencies.values()) \n",
    "print(maximum_frequncy)\n",
    "for word in word_frequencies.keys(): \n",
    "     word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "        \n",
    "sentence_scores = {} \n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):if word in word_frequencies.keys():\n",
    "            \n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                \n",
    "            \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hellomzcsdn,,m\n",
    "df\n",
    "v\n",
    "fd\n",
    "vjjd\n",
    "ds\n",
    "fsnhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Saudis', 'are', 'preparing', 'a', 'report', 'that', 'will', 'acknowledge', 'that'], ['Saudi', 'journalist', 'Jamal', \"Khashoggi's\", 'death', 'was', 'the', 'result', 'of', 'an'], ['interrogation', 'that', 'went', 'wrong,', 'one', 'that', 'was', 'intended', 'to', 'lead'], ['to', 'his', 'abduction', 'from', 'Turkey,', 'according', 'to', 'two', 'sources.']]\n",
      "Dictionary(33 unique tokens: ['Turkey,', 'his', 'that', 'interrogation', 'death']...)\n",
      "{'Turkey,': 26, 'his': 30, 'that': 7, 'interrogation': 20, 'death': 13, 'lead': 21, 'an': 12, 'of': 15, 'to': 23, 'abduction': 27, \"Khashoggi's\": 10, 'according': 28, 'one': 22, 'wrong,': 25, 'went': 24, 'sources.': 31, 'preparing': 5, 'journalist': 14, 'The': 1, 'a': 2, 'acknowledge': 3, 'two': 32, 'the': 17, 'from': 29, 'report': 6, 'Saudi': 11, 'Jamal': 9, 'intended': 19, 'will': 8, 'result': 16, 'was': 18, 'are': 4, 'Saudis': 0}\n",
      "Dictionary(48 unique tokens: ['his', 'that', 'paths', 'interrogation', 'acknowledge']...)\n",
      "{'his': 30, 'that': 7, 'paths': 36, 'interrogation': 20, 'acknowledge': 3, 'death': 13, 'to': 23, 'intended': 19, 'and': 41, 'A': 46, 'Saudi': 11, 'well': 45, 'in': 34, 'abduction': 27, 'IV': 39, 'according': 28, 'two': 32, 'report': 6, 'ordering': 43, 'result': 16, 'intersection': 35, 'are': 4, 'lead': 21, 'Turkey,': 26, 'of': 15, 'an': 12, 'trees': 37, \"Khashoggi's\": 10, 'survey': 47, 'minors': 42, 'one': 22, 'sources.': 31, 'journalist': 14, 'The': 1, 'a': 2, 'graph': 33, 'the': 17, 'from': 29, 'wrong,': 25, 'preparing': 5, 'Widths': 40, 'Graph': 38, 'went': 24, 'will': 8, 'Jamal': 9, 'quasi': 44, 'was': 18, 'Saudis': 0}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "documents = [\"The Saudis are preparing a report that will acknowledge that\", \n",
    "             \"Saudi journalist Jamal Khashoggi's death was the result of an\", \n",
    "             \"interrogation that went wrong, one that was intended to lead\", \n",
    "             \"to his abduction from Turkey, according to two sources.\"]\n",
    "\n",
    "documents_2 = [\"One source says the report will likely conclude that\", \n",
    "                \"the operation was carried out without clearance and\", \n",
    "                \"transparency and that those involved will be held\", \n",
    "                \"responsible. One of the sources acknowledged that the\", \n",
    "                \"report is still being prepared and cautioned that\", \n",
    "                \"things could change.\"]\n",
    "\n",
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in documents]\n",
    "\n",
    "print(texts)\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "print(dictionary)\n",
    "\n",
    "# Show the word to id map\n",
    "print(dictionary.token2id)\n",
    "\n",
    "# adding new doc to dictionary\n",
    "documents_2 = [\"The intersection graph of paths in trees\",\n",
    "               \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "               \"Graph minors A survey\"]\n",
    "\n",
    "texts_2 = [[text for text in doc.split()] for doc in documents_2]\n",
    "\n",
    "dictionary.add_documents(texts_2)\n",
    "\n",
    "\n",
    "print(dictionary)\n",
    "\n",
    "\n",
    "print(dictionary.token2id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'apple': 3, 'egg': 2, 'banana': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "list1=['apple','egg','apple','banana','egg','apple']\n",
    "counts = Counter(list1)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-440e5399e1f1>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-440e5399e1f1>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for j in len(:\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "list1 = [['a','b','c'],['a','a','b']]\n",
    "wordfreq = []\n",
    "inner_list=[]\n",
    "for i in len(list1):\n",
    "    for j in len(:\n",
    "        inner_list.append(i.count(j))\n",
    "    wordfreq.append(inner_list)\n",
    "print(wordfreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 'Group2', 'A': 'Group1', 'D': 'Group2', 'B': 'Group1'}\n"
     ]
    }
   ],
   "source": [
    "groups = [['Group1', 'A', 'B'], ['Group2', 'C', 'D']]\n",
    "\n",
    "result = {}\n",
    "for group in groups:\n",
    "    for item in group[1:]:\n",
    "        result[item] = group[0]\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e 30\n",
      "b 13\n",
      "d 4\n",
      "c 2\n",
      "a 1\n",
      "{'f': 4, 'd': 4, 'a': 1, 'c': 2, 'b': 13, 'e': 30}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a1 = {'a':1, 'b':13, 'd':4, 'c':2, 'e':30}\n",
    "a1_sorted_keys = sorted(a1, key=a1.get, reverse=True)\n",
    "for r in a1_sorted_keys:\n",
    "    print(r, a1[r])\n",
    "a1.update({'f':4})\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 23), ('d', 17), ('c', 5), ('a', 2), ('e', 1)]\n"
     ]
    }
   ],
   "source": [
    "d = {'a':2, 'b':23, 'c':5, 'd':17, 'e':1}\n",
    "items = [(v, k) for k, v in d.items()]\n",
    "items.sort()\n",
    "items.reverse()\n",
    "items = [(k, v) for v, k in items]\n",
    "print(items)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                             Subject  \\\n",
      "0   1         No water supply connection.   \n",
      "1   2                  Road re tarring.\\n   \n",
      "2   3  Power cuts without a prior notice.   \n",
      "3   4     Scarcity of water in day time.    \n",
      "4   5                      Water scarcity   \n",
      "\n",
      "                                           Complaint      Departments  \n",
      "0  No water pipeline connection in amma gardens r...  Water Authority  \n",
      "1  I am a resident of sreekaryam  Ambadi Nagar la...              PWD  \n",
      "2  As everyone knows that electricity is the majo...             KSEB  \n",
      "3  There is scarcity of water in my area Vanchiyo...  Water Authority  \n",
      "4  There is a huge scarcity of water in remote ar...  Water Authority  \n",
      "   id Subject                                          Complaint  \\\n",
      "0   1          no water pipeline connection in amma gardens r...   \n",
      "1   2          i am a resident of sreekaryam  ambadi nagar la...   \n",
      "2   3          as everyone knows that electricity is the majo...   \n",
      "3   4          there is scarcity of water in my area vanchiyo...   \n",
      "4   5          there is a huge scarcity of water in remote ar...   \n",
      "\n",
      "       Departments  \n",
      "0  Water Authority  \n",
      "1              PWD  \n",
      "2             KSEB  \n",
      "3  Water Authority  \n",
      "4  Water Authority  \n",
      "(30, 4)\n",
      "                                 Subject_and_Complaint\n",
      "12    the number of deaths from cardiovascular dise...\n",
      "13    people make river water polluted by dumping h...\n",
      "19    due to the sand mining there is more of effec...\n",
      "20    in our areas during night some strangers are ...\n",
      "33    fishes in the river pampa are dying massively...\n",
      "40    construction is going on the trivandrum in th...\n",
      "42    many industries dump wastes into rivers  lake...\n",
      "43    burning of plastics in public places cause a ...\n",
      "44    dumping of wastes in the public places causes...\n",
      "45    activities like waste disposal from residenti...\n",
      "46    overfishing  which causes a reduction in dive...\n",
      "47    artificial light at night is one of the most ...\n",
      "48    the electronic waste problem is huge the elec...\n",
      "49    ocean acidification is caused when co₂ dissol...\n",
      "50    noise produced by vehicles  political parties...\n",
      "58    now a days many people are cutting down the t...\n",
      "62    polution by ksrtc bus is very heavy today so ...\n",
      "65    quarries are bad for the environment in sever...\n",
      "70                            save alappad stop mining\n",
      "72    i would like to inform you that city resident...\n",
      "74    preserving biodiversity  saving forest can he...\n",
      "100   intolerable temperature change in summer seas...\n",
      "103                         intense heat during summer\n",
      "110   one among the factors which shaped kerala as ...\n",
      "112   due to excessive use of chlorine and other di...\n",
      "113   we should have more projects on planting tree...\n",
      "114   need proper regulations to control the pollution\n",
      "116   increased deforestation  uncontrolled constru...\n",
      "118   the pollution levels in the kochi city is ris...\n",
      "120   waste disposal in public premises make life h...\n",
      "\n",
      "\n",
      "Water Tokens\n",
      "\n",
      "\n",
      "[['water', 'pipeline', 'connection', 'amma', 'gardens', 'residential', 'area', 'erattakalangu', 'malayinkeezhu'], ['scarcity', 'water', 'area', 'vanchiyoor', 'day', 'time', 'creates', 'great', 'trouble', 'people', 'getting', 'ready', 'work', 'schools', 'office', 'etc'], ['huge', 'scarcity', 'water', 'remote', 'areas', 'people', 'walk', 'large', 'distances', 'standing', 'queue', 'fetch', 'water', 'problem', 'exiss', 'hilly', 'areas', 'idukki', 'district', 'kerala', 'si', 'humbly', 'request', 'take', 'necessary', 'actions', 'tackle', 'problem', 'near', 'future'], ['frequent', 'scarcity', 'water', 'morning'], ['100', 'houses', 'area', 'water', 'supply', 'available', 'therepeople', 'get', 'water', 'needs', 'therefore', 'request', 'concerning', 'authorities', 'look', 'matter', 'seriously', 'take', 'necessary', 'steps', 'solving', 'problem', 'water', 'supply', 'may', 'kindly', 'made', 'daily', 'locality', 'people', 'may', 'get', 'rid', 'problem', 'water', 'supply'], ['stayed', 'hotel', 'kovalam', 'beach', 'called', 'palm', 'grove', 'second', 'beach', 'road', 'kovalam', 'near', 'kovalam', 'bus', 'stand', 'came', 'know', 'hotel', 'water', 'connection', 'without', 'water', 'supply', 'authority', 'sealed', 'pipe', 'big', 'dues', 'bill', 'stealing', 'water', 'sealed', 'pipe', 'last', 'year', 'huge', 'capacity', 'water', 'storage', 'building', 'approx', '20000', 'ilters', 'capacity', 'stayed', 'hotel', '3', 'nights', 'staff', 'told', 'things', 'regarding', 'please', 'take', 'immediate', 'action', 'fix', 'small', 'lengthy', 'pipe', 'two', 'side', 'thread', 'connector', 'connected', 'sealed', 'pipewhich', 'also', 'caped', 'glue', 'closed', 'thread', 'cap', 'usually', 'water', 'supply', 'hardly', '3', '4', 'days', 'per', 'week', 'day', 'steal', 'water', 'fill', '20000', 'liters', 'appox', 'filled', 'use', '1', 'week', 'please', 'take', 'necessary', 'action'], ['water', 'leakage', 'locality', 'still', 'unrepaired', 'causes', 'water', 'shortage', 'areas'], ['water', 'flowing', 'pipe', 'foul', 'smell', 'therefore', 'unfits', 'drinking', 'cooking', 'purposes'], ['amount', 'unauthorised', 'connection', 'water', 'mains', 'cause', 'huge', 'bills', 'authorised', 'consumer'], ['public', 'pipe', 'triivandrum', 'city', 'leaking', 'thus', 'leads', 'water', 'shortage'], ['drinking', 'water', 'pipe', 'near', 'puthoor', 'junction', 'broken', 'water', 'flowing', '2', 'days', 'please', 'take', 'necessary', 'action'], ['shortage', 'drinking', 'water'], ['scarcity', 'drinking', 'water', 'summer'], ['leakage', 'water', 'mg', 'road'], ['please', 'setup', 'enough', 'water', 'resource', 'rural', 'areas'], ['residing', 'edathua', 'panchayat', 'kuttanad', 'taluk', 'staying', 'rented', 'house', 'water', 'connection', 'meter', 'water', 'getting', 'waterour', 'house', 'consumer', 'number', '471eda', 'neighbouring', 'houseconsumer', 'no818eda', 'also', 'getting', 'water', 'well', 'also', 'waterwe', 'facing', 'great', 'difficulties', 'daytoday', 'needs', 'kindly', 'request', 'take', 'necessary', 'action'], ['totally', 'residing', 'attuparambil', 'eravipuram', 'kollam', 'locality', 'facing', 'severe', 'problem', 'growing', 'instances', 'insufficient', 'water', 'supply', 'last', '5', 'days', 'locality', 'already', 'given', 'many', 'complaints', 'kindly', 'requesting', 'look', 'matter', 'personally', 'needful', 'shall', 'much', 'thankful'], ['last', 'one', 'month', 'kochi', 'facing', 'acute', 'shortage', 'water', 'supply', 'kwa', 'supply', 'system', 'summer', 'getting', 'bad', 'worse', 'shortage', 'water', 'aggravating', 'condition'], ['writing', 'inform', 'residents', 'punnakunnam', 'pulinkunnu', 'kuttanadu', 'alappuzha', 'facing', 'shortage', 'drinking', 'water', 'last', '10', 'monthsin', 'fact', 'every', 'member', 'society', 'disturbed', 'account', 'unavailability', 'water', 'supply', 'basic', 'need', 'every', 'human'], ['new', 'water', 'pipe', 'connection', 'installed', 'front', 'house', 'leaking', 'water', 'leaking', 'great', 'force', 'getting', 'wasted'], ['please', 'note', 'informing', 'drinking', 'water', 'keep', 'flowing', 'road', 'always', 'wet', 'compound', 'fully', 'accumulated', 'meter', 'cabin'], ['may', 'one', 'two', 'week', 'dont', 'get', 'water', 'even', 'provide', 'water', 'supply', 'time', 'late', 'like', 'midnight', 'low', 'pressure'], ['please', 'issue', 'good', 'water', 'meter'], ['consumer', 'waterworks', 'sub', 'division', 'thrissur', 'per', 'mentioned', 'consumer', 'number', 'getting', 'water', 'past', 'four', 'months', 'house', 'leakage', 'tiled', 'portion', 'road', 'thrissur', 'corporation', 'noticed', 'reported', 'assistant', 'engineer', 'action', 'taken', 'rectify', 'leakage', 'restore', 'water', 'supply', 'house'], ['since', 'january', 'consuming', 'mudmix', 'water', 'every', 'supply', 'water', 'authority', 'storage', 'tank', 'destroy', 'mud', 'resulted', 'taps', 'bathroom', 'systems', 'also'], ['public', 'tap', 'remains', 'idle', 'past', 'couple', 'weeks', 'affected', 'lives', 'people', 'neighborhood', 'awkwardly'], ['recieved', 'bill', '792', 'rs', 'house', 'closed', 'state', '3', 'months', 'information', 'consumption', 'details', 'previous', 'reading', 'information', 'bill'], ['water', 'supply', 'vazhathope', 'pachayath', 'two', 'weeks', 'people', 'need', 'look', 'upon', 'water', 'sources', 'much', 'frustrating'], ['regular', 'water', 'supply', 'september', '2017', 'onwards', 'till', 'date'], ['water', 'loosing', 'distribution', 'line', 'every', 'day', 'pumping', 'progressthis', 'water', 'trapped', 'walk', 'way', 'public', 'useand', 'time', 'mosqitos', 'growingseveral', 'time', 'iform', 'water', 'athority', 'kochi', 'office'], ['domestic', 'water', 'supply', 'houses', 'situated', 'near', 'kunnathuvathucal', 'bridge', 'last', '3', 'days'], ['name', 'wrongly', 'recorded', 'water', 'connection', 'records'], ['able', 'complete', 'payment', 'transaction', 'water', 'authority', 'website'], ['pay', 'utility', 'bills', 'mostly', 'via', 'online', 'payment', 'services', 'water', 'bill', 'facing', 'problem', 'paying', 'bill', 'water', 'authority', 'website'], ['wastage', 'drinking', 'water', 'due', 'damaged', 'pipeline'], ['trying', 'make', 'bill', 'payment', 'entered', 'credentials', 'tried', 'login', 'account', 'everytime', 'try', 'login', 'get', 'error', 'message'], ['request', 'check', 'meter', 'replace', 'repair', 'early', 'possible'], ['location', 'water', 'connection', 'since', 'summer', 'facing', 'severe', 'water', 'scarcity', 'please', 'set', 'connection', 'loction'], ['pay', 'bill', 'e', 'payment', 'web', 'site', 'charge', 'additional', 'rupees', '10', 'transaction']]\n",
      "\n",
      "\n",
      "PWD Tokens\n",
      "\n",
      "\n",
      "[['resident', 'sreekaryam', 'ambadi', 'nagar', 'lane', '3', 'road', 'full', 'potholes', 'kindly', 'necessary', 'steps', 'maintenance', 'road'], ['condition', 'road', 'rural', 'areas', 'kerala', 'miserable', 'corruption', 'contract', 'maintenance', 'road', 'causing', 'problems', 'leads', 'frequent', 'damage', 'newly', 'constructed', 'tared', 'roads', 'potholes', 'road', 'leads', 'accidents', 'losing', 'balance', 'vehicles', 'paved', 'way', 'damage', 'road'], ['living', 'area', 'road', 'harsh', '500', 'people', 'living', 'area', 'travelling', 'unpaved', 'road', 'difficult', 'taskirequests', 'tar', 'road', 'early', 'possible'], ['due', 'recent', 'landslide', 'activity', 'roads', 'got', 'shattered', 'traffic', 'stopped', 'many', 'days', 'please', 'make', 'tarring', 'process', 'faster'], ['mr', 'kumar', 'locality', 'constructing', 'wall', 'taking', 'footpath', 'pwd'], ['road', 'works', 'without', 'prior', 'notice', 'day', 'time', 'cause', 'heavy', 'traffic', 'congestion'], ['melattumoozhy', 'thannippara', 'road', 'bad', 'condition', 'accidents', 'increasing', 'day', 'day', 'please', 'take', 'necessary', 'actions', 'retarring', 'process'], ['road', 'sreekaryam', 'proper', 'width', 'well', 'maintained'], ['id', 'like', 'make', 'public', 'works', 'department', 'aware', 'number', 'potholes', 'impeding', 'traffic', 'also', 'causing', 'undue', 'wear', 'tear', 'vehicles', 'hitting', 'pothole', 'even', 'speed', 'limit', 'pop', 'tire', 'damage', 'car', 'even', 'pose', 'physical', 'threat', 'drivers', 'pedestrians', 'know', 'state', 'law', 'permits', 'drivers', 'seek', 'reimbursement', 'losses', 'due', 'road', 'hazards', 'defects', 'result', 'negligence', 'potential', 'liability', 'claims', 'high', 'several', 'potholes', 'located', 'maple', 'street', '12th', '13th', 'streets', 'one', 'least', 'two', 'feet', 'diameter', 'intersection', '13th', 'pine', 'know', 'crew', 'cant', 'get', 'every', 'pothole', 'right', 'away', 'growing', 'many', 'months', 'attached', 'photos', 'illustrate', 'problem'], ['roads', 'safe', 'running', 'heavyweight', 'vehicle', 'poor', 'maintenance', 'problem', 'aggravates', 'especially', 'rainy', 'season', 'major', 'problem', 'india', 'roads', 'high', 'traffic', 'condition', 'road', 'used', 'various', 'types', 'vehicles', 'highspeed', 'trucks', 'cars', 'tractors', 'twowheelers', 'driven', 'carts', 'cyclists', 'etc', 'things', 'create', 'high', 'traffic', 'jam', 'congestion', 'road', 'accident', 'etcthe', 'roads', 'india', 'lack', 'wayside', 'amenities', 'like', 'first', 'aid', 'centers', 'telephone', 'booths', 'repair', 'shops', 'restaurants', 'clean', 'toilets', 'create', 'serious', 'problems', 'drivers', 'moreover', 'little', 'attention', 'given', 'road', 'safety', 'issues', 'also', 'road', 'safety', 'rules', 'violation', 'laws', 'road', 'transportation', 'system', 'country', 'requires', 'immediate', 'modernization', 'latest', 'technology', 'road', 'transport', 'sector', 'use', 'old', 'technology', 'vehicles', 'still', 'prevalent', 'ultimately', 'increase', 'number', 'road', 'accidents', 'due', 'bad', 'road', 'condition', 'transport', 'companies', 'bear', 'huge', 'amount', 'per', 'year', 'wear', 'tear', 'vehicles', 'important', 'point', 'proper', 'attention', 'given', 'road', 'direction', 'railway', 'department', 'always', 'indifferent', 'attitude', 'biggest', 'barrier', 'transport', 'india', 'railway', 'crossings', 'despite', 'government', 'permissions', 'government', 'employees', 'make', 'reasonable', 'contributions', 'even', 'bribe', 'timeconsuming', 'transport', 'traders', 'also', 'large', 'businessmen', 'businessmen', 'also', 'raised'], ['roads', 'many', 'pitfalls', 'sometimes', 'cause', 'accidents', 'unwary', 'drivers'], ['rising', 'peakhour', 'traffic', 'congestion', 'inescapable', 'condition', 'many', 'areas', 'trivandrum', 'city', 'sufficient', 'traffic', 'control', 'signal', 'systems', 'handle', 'situations'], ['roads', 'properly', 'maintained', 'repair', 'works', 'roads', 'last', 'days', 'proper', 'transportation', 'facility', 'basic', 'right', 'citizens'], ['actually', 'dont', 'good', 'roads', 'worthy', 'tax', 'pay', 'hopefully', 'government', 'find', 'way', 'fix', 'thanks'], ['pathholes', 'road', 'extremly', 'half', 'feet', 'size', 'accident', 'prone', 'today', 'effect', 'daily', 'travelling', 'student', 'employees', 'suffering', 'also', 'may', 'cause', 'health', 'problems'], ['drainage', 'work', 'muthambioorallur', 'road', 'thadoli', 'thazha', 'junction', 'koyilandy', 'taluk', 'calicut', 'district', 'length', '100', 'mtr', 'progressing', 'outlet', 'crossing', 'road', 'directed', 'towards', 'compound', 'wall', 'letting', 'water', 'flow', 'nayadan', 'puzha', 'lake', 'completion', 'water', 'flow', 'directly', 'bottom', 'compound', 'wall', 'hitting', 'compound', 'wall', 'changes', 'direction', 'flow', 'damage', 'wall', 'nature', 'place', 'loose', 'mud', 'learnt', 'provision', 'continue', 'drainage', 'limit', 'road', 'requested', 'kindly', 'needful', 'avoid', 'damage', 'wall', 'length', '15', 'mtr', 'early', 'action', 'requested', 'canal', 'water', 'open', 'last', 'january'], ['sir', 'please', 'initiate', 'surprise', 'visit', 'kerala', 'know', 'conditions', 'roads', '6', 'monthsafter', 'rainy', 'season', 'since', 'roads', 'repaired', 'also', 'roads', 'broken', 'instead', 'chipping', 'existing', 'roads', 'resurfaced', 'increases', 'height', 'roads', 'height', 'roads', 'increased', 'height', 'houses', 'office', 'complexes', 'increased', 'know', 'take', 'help', 'media', 'channels', 'like', 'asianet', 'news', 'manorama', 'news', 'indiavision', 'etc', 'also', 'common', 'trend', 'ie', 'roads', 'repaired', 'broken', 'manually', 'underlying', 'cables', 'underground', 'left', 'without', 'repairing', 'sirmadam', 'per', 'day', 'lacs', 'vehicles', 'entering', 'roads', 'showrooms', 'much', 'tax', 'collected', 'isnt', 'sufficient', 'repair', 'roads', 'roads', 'leveled', 'properly', 'much', 'fuel', 'saved', 'prices', 'fuel', 'controlled', 'certain', 'extent', 'right', 'hope', 'would', 'take', 'factors', 'consideration'], ['dear', 'sir', 'due', 'intervention', 'politicians', 'every', 'footpath', 'flooded', 'vendors', 'selling', 'tender', 'cocanuts', 'shoe', 'repairs', 'petty', 'shops', 'filled', 'pan', 'masalas', 'liquiors', 'tea', 'snacks', 'notnot', 'traders', 'blocking', 'view', 'side', 'roads', 'motorist', 'predict', 'see', 'going', 'emerge', 'side', 'roads', 'petty', 'shops', 'well', 'concreated', 'base', 'running', 'businesses', 'like', 'real', 'estate', 'rentals', 'etcetc', 'idea', 'growing', 'nation', 'city', 'clean', 'roads', 'responsible', 'pwd', 'authority', 'issue', 'notice', 'people', 'evict', 'themgod', 'bad', 'country', 'pity', 'consideration', 'appeal', 'something', 'stop'], ['heavy', 'traffic', 'ss', 'kovil', 'road', 'thampanoor', 'large', 'amount', 'vehicle', 'parking'], ['connection', 'othukkungal', 'town', 'malappuram', 'district', 'kerala', 'beautification', 'existing', 'bus', 'waiting', 'shed', 'towards', 'kottakkal', 'removed', 'last', 'year', 'till', 'date', 'new', 'shed', 'constructed', 'makes', 'difficult', 'common', 'passengers', 'kindly', 'take', 'necessary', 'action', 'construction', 'waiting', 'shed', 'helpful', 'layman'], ['road', 'sreekaryam', 'ambadi', 'nagar', 'chithravila', 'lot', 'gutter', 'please', 'necessary', 'action', 'retar', 'road'], ['road', 'kotooli', 'mangotu', 'vayal', 'road', 'completely', 'digged', 'middle', 'pregnant', 'ladies', 'may', 'give', 'delivery', 'go', 'road', 'slippery', 'chance', 'high', 'please', 'something', 'kind', 'accidents', 'lot', 'kids', 'also', 'passing', 'road', 'chances', 'hitting', 'kids', 'driver', 'try', 'avoid', 'digged', 'part', 'middle', 'road', 'make', 'pedestrians', 'edge', 'may', 'result', 'hit', 'fall', 'resulting', 'injury', 'please', 'consider', 'solve', 'early', 'possible'], ['road', 'going', 'towards', 'trivandrum', 'technopark', 'phase', '3', 'gate', 'towards', 'technopark', 'buildings', 'road', 'starting', 'nippol', 'toyota', 'going', 'towards', 'kallingal', 'road', 'name', 'kallingal', 'attinkuzhy', 'road', 'road', 'damaged', 'last', '15', 'years', 'one', 'caring', 'minimum', '300', 'vehicles', 'daily', 'goes', 'morning', 'evening', 'towards', 'offices', 'like', '1', 'meter', 'gutter', 'middle', 'road', 'making', 'health', 'issues', 'people', 'danger', 'situation', 'urgent', 'action', 'required'], ['current', 'driving', 'licence', 'poor', 'make', 'like', 'pvc', 'card', 'digital', 'card'], ['roads', 'villages', 'proper', 'condition', 'people', 'travelplease', 'take', 'necessary', 'action', 'regarding'], ['road', 'full', 'pits'], ['submitted', 'road', 'condition', 'karukaputhurpallipadamthichur', 'palakkad', 'distis', 'pathetic', 'condition', 'even', 'suitable', 'footwalk', 'due', 'boarder', 'villages', 'two', 'constituency', 'mla', 'bothers', 'area', 'please', 'needful', 'earliest'], ['sir', 'public', 'wants', 'know', 'pwd', 'still', 'continuing', 'toll', 'charge', 'poovathumkadavu', 'bridge', 'poor', 'maintenance', 'road', 'street', 'light', 'misbehaviour', 'toll', 'collectors', 'passengers', 'every', 'day', 'public', 'suffering', 'area', 'whole', 'money', 'bridge', 'collected', 'public', 'gst', 'road', 'tax', 'insurance', 'money', 'going', 'nearby', 'mathilakam', 'bridge', 'toll', 'fee', 'stopped', '1', 'year', 'back'], ['road', 'ramamangalam', 'choondy', 'dug', 'works', 'related', 'kwh', 'condition', 'travel', 'used', 'travel', 'around', '40', 'km', 'daily', 'include', 'road', 'also'], ['register', 'complaint', 'poor', 'road', 'conditions', 'big', 'pot', 'holes', 'arookutty', 'aroor', 'road', 'alappuzha', 'district'], ['damaged', 'long', 'duration', 'potholes', 'converted', 'hidden', 'hazards', 'bikers', 'potential', 'risk', 'road', 'accidents'], ['roads', 'city', 'damaged', 'quality', 'needed'], ['keshavadasapuram', 'traffic', 'block', 'lack', 'planning'], ['low', 'quality', 'roads'], ['drivers', 'dont', 'know', 'correct', 'times', 'roots', 'many', 'bus', 'times'], ['tarring', 'roads', 'damaged', 'suddenly', 'reason', 'behind'], ['road', 'maintained', 'properly'], ['many', 'drivers', 'reckless', 'follow', 'road', 'rules', 'law', 'enforcement', 'lax', 'violations', 'makes', 'things', 'difficult', 'drivers', 'unpredictable', 'driving', 'others', 'road', 'pedestrians', 'walking', 'roadside', 'crossing', 'roads', 'makes', 'roads', 'dangerous', 'ordinary', 'citizens'], ['proper', 'maintenance', 'roads', 'leads', 'pot', 'holes', 'roads'], ['everybody', 'knows', 'highway', 'connecting', 'kochi', 'muvattupzha', 'one', 'busiest', 'crowed', 'road', 'ernakulam', 'city', 'withing', 'last', '3', 'years', 'steady', 'increase', 'unauthorized', 'road', 'side', 'business', 'establishments', 'small', 'tent', 'establishments', 'unauthorized', 'illegal', 'creating', 'lot', 'accidents', 'past', 'months', 'cars', 'bikes', 'tent', 'stop', 'immediately', 'see', 'shacks', 'created', 'sudden', 'unexpected', 'accidents', 'build', 'road', 'reduce', 'road', 'visibility', 'example', 'shack', 'next', 'peruvammuzhy', 'selling', 'fish', 'created', 'countless', 'accidents', 'hope', 'department', 'takes', 'actions', 'business', 'establishments', 'immediatelythe', 'effected', 'areas', 'kolenchery', 'valakom'], ['pathanapurm', 'pattazhy', 'road', 'maintained', 'road', '12m', 'width', 'plan', 'less', '5'], ['manathoor', 'maniykumpparakarimkunnam', 'road', 'worst', 'condition', 'construction', 'pala', 'thodupuzha', 'road', 'many', 'vehicles', 'used', 'road', 'shortcut', 'road', 'fully', 'destroyed', 'please', 'retarr', 'road', 'implement', 'proper', 'sign', 'boards', 'road', 'markings']]\n",
      "[['number', 'deaths', 'cardiovascular', 'disease', 'attributed', 'air', 'pollution', 'much', 'higher', 'expectedair', 'pollution', 'caused', 'twice', 'many', 'deaths', 'cvd', 'respiratory', 'diseases'], ['people', 'make', 'river', 'water', 'polluted', 'dumping', 'household', 'wastage', 'industrial', 'wastage'], ['due', 'sand', 'mining', 'effect', 'ecosystem', 'severe', 'impact', 'plants', 'animals', 'rivers'], ['areas', 'night', 'strangers', 'dumping', 'hotel', 'waste', 'domestic', 'waste', 'foul', 'smelling', 'sides', 'road', 'wastes', 'remain', 'th', 'road', 'uncleaned', 'camera', 'survelliance', 'facility', 'catch', 'people', 'throwing', 'wastes'], ['fishes', 'river', 'pampa', 'dying', 'massively', 'due', 'deposits', 'oil', 'factories', 'nearby'], ['construction', 'going', 'trivandrum', 'paddy', 'fields', 'please', 'take', 'necessary', 'steps', 'save', 'farming'], ['many', 'industries', 'dump', 'wastes', 'rivers', 'lakes', 'ponds', 'streams', 'attempt', 'hide', 'wastes', 'epa', 'nspectors', 'water', 'sources', 'feed', 'major', 'crops', 'food', 'becomes', 'contaminated', 'variety', 'chemicals', 'bacteria', 'causing', 'rampant', 'health', 'problems'], ['burning', 'plastics', 'public', 'places', 'cause', 'major', 'health', 'concern', 'rate', 'lung', 'cancer', 'patients', 'increasing', 'day', 'day', 'high', 'time', 'check', 'activities'], ['dumping', 'wastes', 'public', 'places', 'causes', 'major', 'health', 'issues', 'inviting', 'eradicated', 'disease', 'mechanism', 'collect', 'wastes', 'households', 'disposed', 'properly'], ['activities', 'like', 'waste', 'disposal', 'residential', 'commercial', 'industrial', 'areas', 'oil', 'spills', 'runoff', 'agriculture', 'contaminate', 'bodies', 'water'], ['overfishing', 'causes', 'reduction', 'diversity', 'marine', 'life', 'fishermen', 'considering', 'breeding', 'time'], ['artificial', 'light', 'night', 'one', 'obvious', 'physical', 'changes', 'humans', 'made', 'biosphere', 'artificial', 'light', 'also', 'affects', 'dispersal', 'orientation', 'migration', 'hormone', 'levels', 'resulting', 'disrupted', 'circadian', 'rhythms'], ['electronic', 'waste', 'problem', 'huge', 'electronics', 'end', 'landfills', 'toxics', 'like', 'lead', 'mercury', 'cadmium', 'leach', 'soil', 'water'], ['ocean', 'acidification', 'caused', 'co₂', 'dissolves', 'ocean', 'bonding', 'sea', 'water', 'creating', 'carbonic', 'acid', 'acid', 'reduces', 'ph', 'levels', 'water'], ['noise', 'produced', 'vehicles', 'political', 'parties', 'religious', 'centers', 'causes', 'great', 'harm', 'human', 'ears'], ['days', 'many', 'people', 'cutting', 'trees', 'purposes', 'example', 'many', 'oragansations', 'builders', 'cut', 'trees', 'build', 'projects', 'cause', 'real', 'harm', 'humans', 'also', 'utilizing', 'fertile', 'paddy', 'fields', 'construction', 'affect', 'environment', 'oxygen', 'content', 'air', 'become', 'low', 'oxygen', 'content', 'level', 'decreases', 'air', 'survival', 'living', 'beings', 'move', 'harder', 'way', 'also', 'major', 'factor', 'ozone', 'depletion', 'ozone', 'holes', 'formed', 'harmful', 'radiations', 'enter', 'earth', 'holes', 'causes', 'real', 'harm', 'living', 'beings', 'continues', 'way', 'threatening', 'part', 'lives', 'please', 'take', 'serious', 'issue', 'make', 'necessary', 'useful', 'remedies'], ['polution', 'ksrtc', 'bus', 'heavy', 'today', 'government', 'fix', 'soon', 'possible'], ['quarries', 'bad', 'environment', 'several', 'ways', 'abruptly', 'interrupt', 'continuity', 'open', 'space', 'cause', 'soil', 'erosion', 'air', 'dust', 'pollution', 'deterioration', 'water', 'quality', 'residential', 'area', 'create', 'noise', 'hazards', 'request', 'higher', 'authority', 'investigate', 'punish', 'officials', 'hand', 'quarrying', 'illegal', 'mining', 'time', 'government', 'create', 'awareness', 'potentially', 'negative', 'impact', 'quarrying'], ['save', 'alappad', 'stop', 'mining'], ['would', 'like', 'inform', 'city', 'residents', 'facing', 'difficulties', 'dump', 'domestic', 'wastes', 'humbly', 'request', 'take', 'necessary', 'actions'], ['preserving', 'biodiversity', 'saving', 'forest', 'help', 'overcome', 'issuesalso', 'recycling', 'avoiding', 'usage', 'plastic', 'efficient', 'use', 'fuel'], ['intolerable', 'temperature', 'change', 'summer', 'season', 'cause', 'dried', 'rivers', 'skin', 'disease'], ['intense', 'heat', 'summer'], ['one', 'among', 'factors', 'shaped', 'kerala', 'gods', 'country', 'euphoric', 'climate', 'never', 'touched', 'extremes', 'thanks', 'moderating', 'influence', 'sea', 'mighty', 'western', 'ghats', 'scenario', 'changed', 'lot', 'kerala', 'witnessing', 'unprecedental', 'surge', 'temperature', 'kumbhachoodu', 'termed', 'old', 'generation', 'time', 'high', 'impacting', 'livelihood', 'many'], ['due', 'excessive', 'use', 'chlorine', 'disinfectants', 'water', 'causing', 'long', 'term', 'health', 'problems', 'like', 'hair', 'fall', 'rashes', 'etc', 'amount', 'disinfectants', 'used', 'water', 'supplied', 'need', 'reconsidered'], ['projects', 'planting', 'trees', 'dont', 'cut', 'big', 'grownup', 'trees'], ['need', 'proper', 'regulations', 'control', 'pollution'], ['increased', 'deforestation', 'uncontrolled', 'constructiondevelopment', 'activities', 'vehicle', 'emissions', 'heavily', 'contribute', 'increase', 'temperature', 'government', 'build', 'new', 'policies', 'also', 'consider', 'switching', 'renewable', 'energy', 'sources'], ['pollution', 'levels', 'kochi', 'city', 'rising', 'rapidly', 'government', 'initiate', 'steps', 'curb'], ['waste', 'disposal', 'public', 'premises', 'make', 'life', 'hard', 'people', 'living', 'around']]\n",
      "\n",
      "\n",
      " Env Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " KSEB Count \n",
      "\n",
      "\n",
      "{'values': 1, 'activities': 1, 'many': 2, '15': 1, 'fix': 1, 'public': 1, 'load': 2, 'necessary': 1, 'years': 1, '700': 1, 'bad': 2, 'unnoticed': 1, 'notice': 1, 'facing': 3, 'avoid': 1, 'one': 2, 'morning': 1, 'request': 1, 'ease': 1, 'sure': 1, 'going': 1, 'overall': 1, 'replace': 1, 'high': 3, 'wrongly': 1, 'big': 1, 'lineman': 1, 'examinations': 1, 'grabbing': 1, 'problem': 3, 'till': 1, 'connection': 5, 'time': 6, 'voltage': 3, 'take': 1, 'platforms': 1, 'city': 1, 'electric': 2, 'look': 1, 'came': 1, '3': 1, 'locality': 2, 'failed': 1, 'highly': 1, 'robbery': 1, 'reason': 1, 'please': 3, 'old': 1, 'fast': 1, 'complaint': 1, 'recently': 1, 'every': 2, 'employees': 1, 'madavoor': 1, 'action': 1, 'devices': 1, 'since': 1, 'overhead': 1, 'unsocial': 1, 'knows': 1, 'well': 1, 'exploded': 1, 'particular': 1, 'frequently': 1, 'connectionplease': 1, 'loss': 1, 'cut': 1, 'sound': 1, 'repair': 2, 'near': 1, 'month': 1, 'power': 9, 'due': 3, 'procedure': 1, 'failures': 1, 'hot': 1, 'easily': 1, 'issue': 3, 'damaged': 1, 'give': 1, 'sector': 2, 'comes': 1, 'needed': 1, 'large': 1, 'unable': 1, 'checking': 1, 'connections': 1, 'three': 1, 'first': 1, 'difficult': 1, 'result': 1, 'everyone': 1, 'communication': 1, 'using': 2, 'money': 1, 'adjoining': 1, 'phase': 2, 'meter': 2, 'working': 4, 'different': 1, 'shortage': 1, 'failure': 2, 'makes': 1, 'announcements': 1, 'cuts': 3, 'last': 2, 'phases': 1, 'affect': 1, 'supply': 2, 'say': 1, 'force': 1, 'summer': 1, 'section': 1, 'without': 2, 'lights': 2, 'corrupt': 1, 'heavy': 1, 'rectified': 1, 'past': 1, 'drunken': 1, 'havent': 1, 'even': 3, 'major': 1, 'unavailability': 1, 'find': 1, 'continues': 1, 'ensurde': 1, 'wires': 4, 'though': 1, 'new': 2, 'trivandrum': 1, 'low': 1, 'day': 2, 'times': 1, 'rs': 1, 'houses': 1, 'use': 1, 'evening': 1, 'industries': 1, 'make': 2, 'appliances': 1, 'got': 4, 'bribe': 2, 'transformer': 2, 'showing': 1, 'shedding': 2, 'daysplease': 1, 'trouble': 1, 'home': 2, 'left': 1, 'frequent': 1, 'applied': 1, 'state': 1, 'regular': 1, 'still': 1, 'set': 1, 'scenario': 1, 'experiences': 1, 'fastly': 1, 'almost': 1, 'us': 2, 'farming': 1, 'burnt': 1, 'house': 2, 'proper': 1, 'electricity': 7, 'night': 2, 'misbehaved': 1, 'get': 1, 'prior': 2, 'condition': 1, 'peak': 1, 'crawl': 1, 'raining': 1, 'must': 1, 'equipments': 1, 'lot': 1, 'street': 1, 'occurring': 1, 'months': 2, 'electrical': 1, 'normalplease': 1, 'electronic': 1, 'daysremaining': 1, 'peoples': 1, 'current': 1, 'always': 1, 'connected': 1}\n",
      "\n",
      "\n",
      " KSRTC Count \n",
      "\n",
      "\n",
      "{'amount': 1, 'person': 1, 'town': 1, 'others': 1, 'drivers': 4, 'lady': 1, 'rural': 1, 'rushy': 1, 'safer': 1, 'kottayam': 1, 'like': 1, 'filled': 1, 'inconvenience': 1, 'late': 3, 'public': 3, 'hill': 1, 'busses': 2, 'necessary': 1, 'well': 1, 'buses': 10, 'right': 1, 'traveller': 1, 'needful': 1, 'lack': 2, 'commute': 2, 'keep': 1, 'one': 1, 'transportation': 1, 'busy': 1, 'kindly': 1, 'sreekaryam': 1, 'reaching': 1, 'present': 1, 'spend': 1, 'access': 1, 'control': 1, 'lots': 2, 'ask': 1, 'mukkam': 1, 'via': 1, 'kl157912': 1, 'timings': 1, 'frequently': 1, 'caused': 1, 'depending': 1, 'seats': 4, 'confirm': 1, '25': 1, 'hit': 1, 'destination': 1, 'provide': 2, 'time': 4, 'found': 1, 'city': 4, 'station': 1, 'buseskindly': 1, 'shortcuts': 1, 'came': 1, 'alloted': 1, 'got': 2, 'see': 2, 'transport': 2, 'reason': 1, 'accidents': 1, 'almost': 1, 'arrive': 1, 'busesatleast': 1, 'fast': 2, 'solely': 1, 'government': 1, 'kattakada': 1, 'use': 1, 'venjaramoodu': 1, 'kattakkada': 1, 'stopping': 1, 'life': 1, 'route': 3, 'week': 1, 'passenger': 2, 'action': 2, 'totally': 1, 'took': 1, 'feelplease': 1, 'cant': 1, 'risk': 1, 'bothered': 2, 'helpful': 2, 'going': 2, 'argue': 1, 'travelled': 1, 'causes': 1, 'equality': 1, 'people': 3, 'super': 1, 'recently': 3, 'busesplease': 1, 'femalesas': 1, 'seat': 4, 'kulathurstudents': 1, 'reduced': 1, 'authorites': 1, 'due': 3, 'hours': 2, 'percent': 1, 'area': 2, 'cottton': 1, 'around': 3, 'experienced': 1, 'driver': 2, 'effective': 1, 'cancelled': 1, 'much': 1, 'stopped': 1, 'choose': 1, 'give': 1, 'forget': 1, 'tired': 1, 'ran': 1, 'make': 1, 'miss': 1, 'advice': 1, 'intended': 1, 'change': 1, 'overspeeding': 2, 'bus': 14, 'back': 2, 'number': 2, 'venjaramood': 1, 'facing': 1, 'service': 5, 'convenient': 1, 'trivandrum': 1, 'arrange': 1, 'travel': 1, 'kills': 1, 'atleast': 2, 'travelyesterday': 1, '2': 1, 'crossing': 1, 'willing': 1, 'muvattupuza': 1, 'great': 1, 'local': 1, 'services': 4, 'workers': 1, 'locations': 1, 'ernakulam': 1, 'income': 1, 'class': 1, 'lines': 1, 'causing': 1, 'take': 2, 'kazhakkuttam': 1, 'behaving': 1, 'school': 1, 'upon': 1, 'value': 1, 'morning': 2, 'rescheduling': 1, 'leave': 1, 'given': 1, 'occupied': 1, 'running': 1, 'earlier': 1, 'passengers': 3, 'usually': 1, 'increase': 1, 'several': 1, 'even': 3, 'student': 1, 'students': 3, 'dont': 2, 'whole': 1, 'femalesthen': 1, 'travelling': 1, 'onky': 1, 'would': 4, 'ksrtc': 8, 'speed': 1, 'dependable': 1, 'schedule': 1, 'college': 4, 'innocent': 1, 'travellers': 1, 'fully': 1, 'ignoring': 1, 'balance': 1, 'drove': 1, 'never': 1, 'noticed': 1, 'difficult': 1, 'damage': 1, 'conductor': 1, 'day': 1, 'railway': 2, 'females': 1, 'inform': 1, 'six': 1, 'safety': 1, 'limited': 1, 'depend': 1, 'sometimes': 1, 'times': 1, 'reserved': 2, 'stop': 4, 'rudely': 1, 'kottukunnam': 1, 'word': 1, 'dashed': 1, 'reach': 4, 'vehicles': 1, 'carelessly': 1, 'man': 1, 'regular': 1, 'nadakkavu': 1, 'done': 1, 'standing': 1, 'kumarakam': 2, 'mid': 1, 'difficulty': 1, 'brutally': 1, 'please': 1, 'us': 1, 'behave': 1, '730': 1, 'male': 1, 'add': 1, 'proper': 1, 'pasengers': 1, 'night': 1, 'get': 1, 'conductors': 1, 'using': 1, 'none': 1, 'problem': 3, 'rashly': 1, 'face': 1, 'ymcacross': 1, 'sir': 1, 'work': 1, 'trivandrumidukkikattappana': 1, 'raining': 1, 'car': 4, 'areas': 1, 'low': 1, 'road': 2, 'heavily': 1, 'past': 1, 'hoping': 1, 'request': 2, 'daily': 1, 'stationso': 1, 'always': 1, 'least': 1, '23': 1}\n",
      "\n",
      "\n",
      " PWD Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " KSRTC Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " Water Freq newwwwwwwwww\n",
      "{'amount': 1, 'bills': 2, 'stand': 1, 'connector': 1, 'loction': 1, 'system': 1, 'error': 1, 'late': 1, 'called': 1, 'public': 3, 'consuming': 1, 'affected': 1, 'necessary': 5, '1': 1, 'bad': 1, 'way': 1, 'portion': 1, 'fact': 1, 'mains': 1, 'rural': 1, 'sources': 1, 'second': 1, 'kindly': 3, 'records': 1, 'bill': 7, 'pachayath': 1, 'exiss': 1, 'si': 1, 'wrongly': 1, 'big': 1, 'steps': 1, 'many': 1, 'pipewhich': 1, 'erattakalangu': 1, 'people': 5, 'matter': 2, 'requesting': 1, 'connection': 8, '20000': 2, 'time': 4, 'pumping': 1, 'midnight': 1, 'instances': 1, 'city': 1, 'installed': 1, 'resulted': 1, 'look': 3, 'came': 1, 'month': 1, 'locality': 4, 'mostly': 1, 'solving': 1, 'alappuzha': 1, 'palm': 1, 'corporation': 1, 'beach': 2, 'every': 4, 'use': 1, 'humbly': 1, 'week': 3, 'glue': 1, 'totally': 1, 'dues': 1, 'taps': 1, 'concerning': 1, 'site': 1, 'taken': 1, 'frustrating': 1, 'hotel': 3, 'may': 3, 'distribution': 1, 'four': 1, 'repair': 1, 'regarding': 1, 'idukki': 1, 'residential': 1, 'force': 1, 'wasted': 1, 'authority': 4, 'panchayat': 1, 'fully': 1, 'punnakunnam': 1, 'iform': 1, 'charge': 1, 'issue': 1, 'resource': 1, '792': 1, 'make': 1, 'name': 1, 'given': 1, 'weeks': 2, 'large': 1, 'office': 2, 'bus': 1, 'idle': 1, 'transaction': 2, 'number': 2, 'noticed': 1, 'facing': 6, 'daytoday': 1, 'thread': 2, 'residents': 1, 'unfits': 1, 'cabin': 1, 'everytime': 1, 'leaking': 3, 'worse': 1, 'schools': 1, 'steal': 1, 'meter': 4, 'services': 1, 'things': 1, 'accumulated': 1, 'getting': 6, 'writing': 1, 'amma': 1, 'take': 6, 'complaints': 1, 'rs': 1, '100': 1, 'upon': 1, 'disturbed': 1, 'systems': 1, 'summer': 3, 'kwa': 1, 'without': 1, 'pipe': 7, 'regular': 1, 'tank': 1, 'trying': 1, 'good': 1, 'tiled': 1, 'therefore': 2, 'kovalam': 3, '5': 1, 'vazhathope': 1, 'ready': 1, 'consumer': 4, 'unavailability': 1, 'needs': 2, 'building': 1, 'web': 1, 'tried': 1, 'seriously': 1, 'malayinkeezhu': 1, 'basic': 1, 'told': 1, 'new': 1, 'leads': 1, 'appox': 1, 'houses': 2, 'cause': 1, 'domestic': 1, 'attuparambil': 1, 'pulinkunnu': 1, 'message': 1, 'unauthorised': 1, 'also': 4, 'frequent': 1, 'location': 1, 'approx': 1, 'standing': 1, 'distances': 1, 'date': 1, 'eravipuram': 1, 'huge': 3, 'assistant': 1, 'rented': 1, 'condition': 1, 'waterour': 1, 'bathroom': 1, 'areas': 4, 'side': 1, 'thus': 1, 'website': 2, 'consumption': 1, 'daily': 1, 'queue': 1, 'destroy': 1, 'always': 1, 'ilters': 1, 'lengthy': 1, 'houseconsumer': 1, 'division': 1, 'recorded': 1, 'drinking': 7, 'waterworks': 1, 'shall': 1, 'like': 1, 'filled': 1, 'tap': 1, 'fix': 1, 'neighborhood': 1, 'well': 1, 'actions': 1, 'hilly': 1, 'thankful': 1, 'pay': 2, 'mudmix': 1, 'district': 1, 'difficulties': 1, 'keep': 1, 'one': 2, 'morning': 1, 'utility': 1, 'e': 1, 'authorities': 1, 'staying': 1, 'aggravating': 1, 'junction': 1, 'replace': 1, 'loosing': 1, 'growingseveral': 1, 'informing': 1, 'set': 1, 'closed': 2, 'kunnathuvathucal': 1, 'awkwardly': 1, 'onwards': 1, 'provide': 1, 'credentials': 1, 'problem': 6, 'puthoor': 1, 'stealing': 1, 'till': 1, 'edathua': 1, 'gardens': 1, 'possible': 1, '3': 4, 'sealed': 3, 'day': 3, 'sub': 1, 'enough': 1, 'purposes': 1, 'front': 1, 'stayed': 2, 'capacity': 2, 'therepeople': 1, 'cooking': 1, 'waterwe': 1, 'action': 5, 'need': 2, 'growing': 1, 'trapped': 1, 'great': 3, 'know': 1, 'mud': 1, 'road': 4, 'causes': 1, 'kerala': 1, 'leakage': 4, 'rectify': 1, 'couple': 1, 'residing': 2, 'fill': 1, 'near': 4, 'authorised': 1, 'future': 1, 'due': 1, 'account': 2, 'restore': 1, 'login': 2, 'area': 3, 'thrissur': 2, 'paying': 1, 'useand': 1, 'much': 2, 'immediate': 1, 'damaged': 1, 'mg': 1, 'note': 1, 'walk': 2, 'grove': 1, 'storage': 2, 'scarcity': 5, 'check': 1, 'made': 1, 'kuttanad': 1, 'acute': 1, 'monthsin': 1, 'shortage': 6, 'needful': 1, 'taluk': 1, 'kollam': 1, 'since': 2, '2': 1, 'engineer': 1, 'recieved': 1, 'january': 1, '4': 1, 'etc': 1, 'hardly': 1, 'staff': 1, 'triivandrum': 1, 'last': 5, 'previous': 1, 'kochi': 2, 'unrepaired': 1, 'reading': 1, 'broken': 1, 'foul': 1, 'reported': 1, 'bridge': 1, 'usually': 1, 'past': 2, '471eda': 1, 'mosqitos': 1, 'information': 2, 'even': 1, 'dont': 1, 'vanchiyoor': 1, 'society': 1, 'try': 1, 'water': 58, 'available': 1, '2017': 1, 'compound': 1, 'small': 1, 'human': 1, 'no818eda': 1, 'member': 1, 'line': 1, 'work': 1, 'pressure': 1, 'low': 1, 'online': 1, 'two': 3, 'fetch': 1, 'entered': 1, 'inform': 1, 'neighbouring': 1, 'situated': 1, 'already': 1, 'insufficient': 1, 'september': 1, 'personally': 1, 'wastage': 1, 'caped': 1, 'trouble': 1, 'mentioned': 1, 'able': 1, 'state': 1, 'rupees': 1, 'progressthis': 1, 'remains': 1, 'via': 1, 'severe': 2, 'please': 7, 'cap': 1, 'days': 4, 'rid': 1, 'flowing': 3, 'athority': 1, 'setup': 1, 'house': 6, 'additional': 1, 'tackle': 1, 'details': 1, 'payment': 4, 'pipeline': 2, 'complete': 1, 'get': 4, '10': 2, 'liters': 1, 'year': 1, 'kuttanadu': 1, 'still': 1, 'wet': 1, 'per': 2, 'early': 1, 'supply': 15, 'lives': 1, 'months': 2, 'nights': 1, 'request': 4, 'creates': 1, 'smell': 1, 'connected': 1, 'remote': 1}\n",
      "['water', 'supply', 'connection', 'please', 'pipe', 'drinking', 'bill', 'take', 'shortage', 'problem', 'house', 'getting', 'facing', 'scarcity', 'people', 'necessary', 'last', 'action', 'time', 'road', 'request', 'payment', 'near', 'meter', 'locality', 'leakage', 'get', 'every', 'days', 'consumer', 'authority', 'areas', 'also', '3', 'week', 'two', 'summer', 'sealed', 'public', 'may', 'look', 'leaking', 'kovalam', 'kindly', 'huge', 'hotel', 'great', 'flowing', 'day', 'area', 'weeks', 'website', 'walk', 'transaction', 'thrissur', 'thread', 'therefore', 'storage', 'stayed', 'since', 'severe', 'residing', 'pipeline', 'per', 'pay', 'past', 'one', 'office', 'number', 'needs', 'need', 'much', 'months', 'matter', 'login', 'kochi', 'information', 'houses', 'closed', 'capacity', 'bills', 'beach', 'account', '20000', '10', 'year', 'wrongly', 'writing', 'worse', 'work', 'without', 'wet', 'well', 'web', 'way', 'waterworks', 'waterwe', 'waterour', 'wasted', 'wastage', 'via', 'vazhathope', 'vanchiyoor', 'utility', 'usually', 'useand', 'use', 'upon', 'unrepaired', 'unfits', 'unavailability', 'unauthorised', 'trying', 'try', 'trouble', 'triivandrum', 'tried', 'trapped', 'totally', 'told', 'till', 'tiled', 'thus', 'things', 'therepeople', 'thankful', 'taps', 'tap', 'tank', 'taluk', 'taken', 'tackle', 'systems', 'system', 'sub', 'still', 'steps', 'stealing', 'steal', 'staying', 'state', 'standing', 'stand', 'staff', 'sources', 'solving', 'society', 'smell', 'small', 'situated', 'site', 'side', 'si', 'shall', 'setup', 'set', 'services', 'seriously', 'september', 'second', 'schools', 'rural', 'rupees', 'rs', 'rid', 'resulted', 'restore', 'resource', 'residents', 'residential', 'requesting', 'reported', 'replace', 'repair', 'rented', 'remote', 'remains', 'regular', 'regarding', 'rectify', 'records', 'recorded', 'recieved', 'ready', 'reading', 'queue', 'puthoor', 'purposes', 'punnakunnam', 'pumping', 'pulinkunnu', 'provide', 'progressthis', 'previous', 'pressure', 'possible', 'portion', 'pipewhich', 'personally', 'paying', 'panchayat', 'palm', 'pachayath', 'onwards', 'online', 'noticed', 'note', 'no818eda', 'nights', 'new', 'neighbouring', 'neighborhood', 'needful', 'name', 'mudmix', 'mud', 'mostly', 'mosqitos', 'morning', 'monthsin', 'month', 'midnight', 'mg', 'message', 'mentioned', 'member', 'many', 'malayinkeezhu', 'make', 'mains', 'made', 'low', 'loosing', 'loction', 'location', 'lives', 'liters', 'line', 'like', 'lengthy', 'leads', 'late', 'large', 'kwa', 'kuttanadu', 'kuttanad', 'kunnathuvathucal', 'kollam', 'know', 'kerala', 'keep', 'junction', 'january', 'issue', 'insufficient', 'instances', 'installed', 'informing', 'inform', 'immediate', 'ilters', 'iform', 'idukki', 'idle', 'humbly', 'human', 'houseconsumer', 'hilly', 'hardly', 'growingseveral', 'growing', 'grove', 'good', 'glue', 'given', 'gardens', 'future', 'fully', 'frustrating', 'front', 'frequent', 'four', 'foul', 'force', 'fix', 'filled', 'fill', 'fetch', 'fact', 'exiss', 'everytime', 'even', 'etc', 'error', 'eravipuram', 'erattakalangu', 'entered', 'enough', 'engineer', 'edathua', 'early', 'e', 'dues', 'due', 'dont', 'domestic', 'division', 'disturbed', 'district', 'distribution', 'distances', 'difficulties', 'details', 'destroy', 'daytoday', 'date', 'damaged', 'daily', 'credentials', 'creates', 'couple', 'corporation', 'cooking', 'consumption', 'consuming', 'connector', 'connected', 'condition', 'concerning', 'compound', 'complete', 'complaints', 'city', 'check', 'charge', 'causes', 'cause', 'caped', 'cap', 'came', 'called', 'cabin', 'bus', 'building', 'broken', 'bridge', 'big', 'bathroom', 'basic', 'bad', 'awkwardly', 'available', 'authorities', 'authorised', 'attuparambil', 'athority', 'assistant', 'approx', 'appox', 'amount', 'amma', 'always', 'already', 'alappuzha', 'aggravating', 'affected', 'additional', 'acute', 'actions', 'accumulated', 'able', '792', '5', '471eda', '4', '2017', '2', '100', '1']\n",
      "\n",
      "\n",
      "KEYWORDS  WATER\n",
      "\n",
      "\n",
      "[['water', 'supply', 'connection', 'please', 'pipe']]\n",
      "\n",
      "\n",
      " PWD Freq newwwwwwwwww\n",
      "{'amount': 3, 'person': 1, 'town': 2, 'drivers': 11, 'rushy': 1, 'system': 1, 'great': 1, 'tea': 1, 'late': 3, 'cause': 3, 'public': 7, 'roads': 30, 'card': 2, 'hope': 2, 'immediatelythe': 1, '1': 2, 'bad': 3, 'right': 4, 'way': 2, 'notice': 2, 'lack': 4, 'karukaputhurpallipadamthichur': 1, 'problems': 3, 'impeding': 1, 'despite': 1, 'dear': 1, 'busy': 1, 'kindly': 4, 'urgent': 1, 'frequently': 1, 'lots': 2, 'road': 66, 'add': 1, 'worst': 1, 'today': 1, 'starting': 1, 'dug': 1, 'channels': 1, 'mathilakam': 1, 'provide': 2, 'completion': 1, 'politicians': 1, 'pregnant': 1, 'station': 1, 'carelessly': 1, 'corruption': 1, 'unpredictable': 1, 'came': 1, 'technology': 2, 'pathholes': 1, 'transport': 6, 'register': 1, 'accidents': 10, 'busses': 2, 'jam': 1, 'losses': 1, 'venjaramoodu': 1, 'include': 1, 'aggravates': 1, 'reimbursement': 1, 'vehicle': 2, 'tax': 3, 'necessary': 6, 'sir': 4, 'fall': 1, 'feet': 2, 'companies': 1, 'bothered': 2, 'nearby': 1, 'rules': 2, 'half': 1, '12th': 1, 'repair': 3, 'moreover': 1, 'tire': 1, 'streets': 1, 'emerge': 1, 'authorites': 1, 'crowed': 1, 'example': 1, 'lax': 1, 'collected': 2, 'minimum': 1, 'driver': 3, 'establishments': 3, 'idea': 1, 'issue': 1, 'make': 6, 'name': 1, 'valakom': 1, 'man': 1, 'cables': 1, 'office': 1, 'overspeeding': 2, 'limit': 2, 'ladies': 1, 'attention': 2, 'congestion': 3, 'facing': 1, 'convenient': 1, 'leads': 3, 'attached': 1, 'travelyesterday': 1, 'loose': 1, 'footpath': 2, 'class': 1, 'money': 2, 'muvattupuza': 1, 'phase': 1, 'meter': 1, 'nagar': 2, 'services': 4, 'parking': 1, 'masalas': 1, 'effective': 1, 'thadoli': 1, 'causing': 3, 'leveled': 1, 'booths': 1, 'clean': 2, 'steady': 1, 'repairs': 1, '100': 1, 'upon': 1, 'important': 1, 'vendors': 1, 'injury': 1, 'rescheduling': 1, 'reasonable': 1, 'worthy': 1, 'regular': 1, 'driven': 1, 'running': 3, 'male': 1, 'passengers': 5, 'bikers': 1, 'toll': 3, 'immediately': 1, 'citizens': 2, 'travelling': 3, 'distis': 1, 'tent': 2, 'pathanapurm': 1, 'would': 5, 'ksrtc': 8, 'pan': 1, 'damaged': 4, 'kl157912': 1, 'innocent': 1, 'drove': 1, 'resurfaced': 1, 'difficult': 4, 'stopped': 3, 'poovathumkadavu': 1, 'connecting': 1, 'females': 1, 'limited': 1, 'initiate': 1, '25': 1, 'duration': 1, 'hidden': 1, 'difficulty': 1, 'underlying': 1, 'also': 9, 'dashed': 1, 'shops': 3, 'footwalk': 1, 'carts': 1, 'restaurants': 1, 'rudely': 1, 'maintained': 4, 'serious': 1, '13th': 2, 'telephone': 1, 'date': 1, 'behave': 1, 'requested': 2, 'sign': 1, 'local': 1, 'laws': 1, 'thazha': 1, 'rising': 1, 'shortcut': 1, 'pity': 1, 'types': 1, 'areas': 4, 'pits': 1, 'heavily': 1, 'shattered': 1, 'kwh': 1, 'daily': 4, 'current': 1, 'always': 2, 'least': 2, 'retarring': 1, 'forget': 1, 'rural': 2, 'slippery': 1, 'safer': 1, 'lacs': 1, 'filled': 2, 'flooded': 1, '15': 2, 'intersection': 1, 'crew': 1, 'toyota': 1, 'tarring': 2, 'petty': 2, 'chithravila': 1, 'actions': 2, 'misbehaviour': 1, 'district': 3, 'illegal': 1, 'morning': 3, 'result': 2, 'consideration': 2, 'reaching': 1, 'hit': 2, 'place': 1, 'railway': 4, 'continue': 1, 'mukkam': 1, 'calicut': 1, 'timings': 1, 'nature': 1, 'handle': 1, 'light': 1, 'caused': 1, 'connection': 1, '300': 1, 'problem': 6, 'othukkungal': 1, '2': 1, 'biggest': 1, 'collectors': 1, 'effect': 1, 'season': 2, 'tar': 1, '500': 1, 'passenger': 2, 'aware': 1, 'shortcuts': 1, 'dangerous': 1, 'alloted': 1, 'attitude': 1, 'underground': 1, 'shoe': 1, 'build': 1, 'pathetic': 1, 'violation': 1, 'old': 1, 'hopefully': 1, 'solely': 1, 'us': 1, 'bribe': 1, 'employees': 2, 'know': 6, 'unauthorized': 2, 'cars': 2, 'took': 1, 'since': 1, 'businesses': 1, 'layman': 1, 'increases': 1, 'cant': 2, 'aid': 1, 'centers': 1, 'avoid': 2, 'shack': 1, 'mud': 1, 'going': 6, 'tired': 1, 'kerala': 3, 'little': 1, 'seat': 4, 'kulathurstudents': 1, 'visit': 1, 'barrier': 1, 'evict': 1, 'area': 6, 'cottton': 1, 'immediate': 1, 'digital': 1, 'rentals': 1, 'losing': 1, 'income': 1, 'advice': 1, 'needed': 1, 'plan': 1, 'last': 5, 'caring': 1, 'needful': 3, 'monthsafter': 1, 'arrange': 1, 'atleast': 2, 'consider': 1, 'isnt': 1, 'tear': 2, 'mr': 1, 'directly': 1, 'locations': 1, 'created': 2, 'condition': 10, 'kochi': 1, 'converted': 1, 'digged': 2, 'complexes': 1, 'conductors': 1, 'constructed': 2, 'argue': 1, 'bridge': 3, 'withing': 1, 'earlier': 1, 'usually': 1, 'stationso': 1, 'sirmadam': 1, 'increased': 2, 'student': 2, 'highspeed': 1, 'whole': 2, 'femalesthen': 1, 'find': 1, 'try': 1, 'water': 3, 'thodupuzha': 1, 'showrooms': 1, 'resulting': 1, 'schedule': 1, 'college': 4, 'equality': 1, 'fully': 2, 'attinkuzhy': 1, 'safe': 1, 'view': 1, 'work': 2, 'trivandrum': 3, 'passing': 1, 'predict': 1, 'two': 2, 'six': 1, 'good': 1, 'sudden': 1, 'saved': 1, 'offices': 1, 'got': 3, 'reserved': 2, 'lane': 1, 'stop': 6, 'muthambioorallur': 1, 'follow': 1, 'pedestrians': 3, 'indifferent': 1, 'controlled': 1, 'increasing': 1, 'media': 1, 'less': 1, 'compound': 3, 'physical': 1, 'still': 2, 'crossings': 1, 'via': 1, 'mangotu': 1, 'pitfalls': 1, 'entering': 1, 'brutally': 1, 'week': 1, 'please': 9, 'selling': 2, 'days': 2, 'create': 2, 'everybody': 1, 'hitting': 3, 'shed': 3, 'raised': 1, 'proper': 7, 'located': 1, 'kills': 1, 'totally': 1, 'effected': 1, 'related': 1, 'open': 1, 'around': 4, 'small': 1, 'low': 2, 'early': 3, 'street': 2, 'help': 1, 'months': 2, 'especially': 1, 'point': 1, 'cyclists': 1, 'pvc': 1, 'peruvammuzhy': 1, '23': 1, 'lady': 1, 'traveller': 1, 'sufficient': 2, 'process': 2, 'completely': 1, 'instead': 1, 'modernization': 1, 'ambadi': 2, 'keshavadasapuram': 1, 'safety': 3, 'situation': 1, 'years': 2, 'others': 2, 'reduce': 1, 'block': 1, 'dont': 4, 'latest': 1, 'health': 2, 'indiavision': 1, 'tender': 1, 'properly': 3, 'accident': 2, 'present': 1, 'inescapable': 1, 'diameter': 1, 'ask': 1, 'big': 1, 'steps': 1, 'threat': 1, 'next': 1, 'kottayam': 1, 'towards': 6, 'depending': 1, 'seats': 4, 'poor': 4, 'activity': 1, 'access': 1, 'destination': 1, 'construction': 2, 'time': 5, 'liability': 1, 'contributions': 1, 'kolenchery': 1, 'city': 8, 'constructing': 1, 'traders': 2, 'locality': 1, 'enforcement': 1, 'see': 4, 'fee': 1, 'alappuzha': 1, 'driving': 2, 'reason': 2, 'concreated': 1, 'arrive': 1, 'complaint': 1, 'recently': 3, 'every': 3, 'kattakada': 1, 'use': 2, 'regarding': 1, 'timeconsuming': 1, 'life': 1, 'route': 3, 'businessmen': 2, 'gutter': 2, '12m': 1, 'amenities': 1, 'extremly': 1, 'travelled': 1, 'may': 3, 'width': 2, 'authority': 1, 'busesplease': 1, 'cancelled': 1, 'illustrate': 1, 'estate': 1, 'reduced': 1, 'potential': 2, 'pattazhy': 1, 'unpaved': 1, 'sector': 1, 'kumar': 1, 'fuel': 2, 'liquiors': 1, 'miserable': 1, 'hours': 2, 'bikes': 1, 'choose': 1, 'give': 2, 'gst': 1, 'conductor': 1, 'negligence': 1, 'given': 3, 'mid': 1, 'etcetc': 1, 'large': 2, 'bus': 16, 'factors': 1, 'kottakkal': 1, 'number': 4, 'first': 1, 'venjaramood': 1, 'ran': 1, 'hazards': 2, 'nippol': 1, 'pasengers': 1, 'cocanuts': 1, 'retarr': 1, 'prone': 1, 'possible': 2, 'busiest': 1, 'day': 6, 'workers': 1, 'things': 2, 'intervention': 1, 'motorist': 1, 'living': 2, 'paved': 1, 'take': 7, 'kazhakkuttam': 1, 'constituency': 1, 'asianet': 1, 'behaving': 1, 'government': 4, 'transportation': 3, 'palakkad': 1, 'without': 2, 'thanks': 1, 'provision': 1, 'tared': 1, 'surprise': 1, 'heavy': 2, 'heavyweight': 1, 'bear': 1, 'increase': 3, 'tractors': 1, 'vayal': 1, 'responsible': 1, 'students': 3, 'walking': 1, 'implement': 1, 'photos': 1, 'retar': 1, 'kids': 2, 'part': 1, 'letting': 1, 'mtr': 2, 'speed': 2, 'muvattupzha': 1, 'go': 1, 'signal': 1, 'requires': 1, 'basic': 1, 'taskirequests': 1, '5': 1, 'chipping': 1, 'new': 1, 'base': 1, 'buildings': 1, 'behind': 1, 'houses': 1, 'major': 1, 'correct': 1, 'certain': 1, 'pot': 2, 'manorama': 1, 'times': 3, 'licence': 1, 'planning': 1, 'kottukunnam': 1, 'traffic': 9, 'wayside': 1, 'reach': 4, 'twowheelers': 1, 'left': 1, 'wants': 1, 'etcthe': 1, 'frequent': 1, 'unwary': 1, 'high': 4, 'done': 1, 'standing': 1, 'repaired': 2, 'koyilandy': 1, 'newly': 1, 'ymcacross': 1, 'aroor': 1, 'pala': 1, 'kotooli': 1, '730': 1, 'undue': 1, 'night': 1, 'suddenly': 1, 'school': 1, 'using': 1, 'beautification': 1, 'defects': 1, 'raining': 1, 'lake': 1, 'side': 3, 'pose': 1, 'permissions': 1, 'boarder': 1, 'lot': 3, 'inconvenience': 1, 'toilets': 1, 'hoping': 1, 'india': 3, 'required': 1, 'travel': 3, 'ss': 1, 'blocking': 1, 'facility': 1, 'various': 1, 'height': 3, 'business': 2, 'many': 7, 'like': 7, 'fix': 1, 'hill': 1, 'waiting': 2, 'violations': 1, 'well': 3, 'buses': 10, 'themgod': 1, '6': 1, 'pay': 1, 'length': 2, 'highway': 1, 'commute': 2, 'nadakkavu': 1, 'keep': 1, 'taking': 1, 'ordinary': 1, 'one': 4, 'roots': 1, 'existing': 2, 'sreekaryam': 4, 'seek': 1, 'spend': 1, 'junction': 1, 'thannippara': 1, 'long': 1, 'potholes': 5, 'something': 2, 'till': 1, 'outlet': 1, 'progressing': 1, 'rainy': 2, 'malappuram': 1, 'confirm': 1, 'claims': 1, 'vehicles': 9, 'common': 2, 'creating': 1, 'kind': 1, 'goes': 1, 'willing': 1, 'buseskindly': 1, 'found': 1, '3': 3, 'issues': 2, 'flow': 3, 'destroyed': 1, 'removed': 1, 'villages': 2, 'pwd': 3, 'busesatleast': 1, 'id': 1, 'mla': 1, 'melattumoozhy': 1, 'kattakkada': 1, 'stopping': 1, 'gate': 1, 'action': 7, 'feelplease': 1, 'knows': 1, 'wear': 2, 'risk': 2, 'pine': 1, 'nation': 1, 'pop': 1, 'size': 1, 'causes': 1, 'markings': 1, 'people': 7, 'super': 1, 'prices': 1, 'situations': 1, 'quality': 2, 'femalesas': 1, 'prevalent': 1, 'faster': 1, 'ultimately': 1, 'choondy': 1, 'due': 8, 'arookutty': 1, 'percent': 1, 'chances': 1, 'crossing': 3, 'experienced': 1, 'extent': 1, 'submitted': 1, 'law': 2, 'much': 3, 'thampanoor': 1, 'peakhour': 1, 'km': 1, 'miss': 1, 'snacks': 1, 'intended': 1, 'change': 1, 'travelplease': 1, 'back': 3, 'wall': 6, 'nayadan': 1, 'depend': 1, 'harsh': 1, 'continuing': 1, 'service': 5, 'resident': 1, 'charge': 1, 'taluk': 1, 'takes': 1, 'appeal': 1, 'earliest': 1, 'etc': 2, 'boards': 1, 'makes': 3, 'ernakulam': 2, 'puzha': 1, 'fish': 1, 'lines': 1, 'conditions': 2, 'contract': 1, 'full': 2, 'notnot': 1, 'trivandrumidukkikattappana': 1, 'canal': 1, 'broken': 2, 'solve': 1, 'holes': 2, 'value': 1, 'balance': 2, 'countless': 1, 'bothers': 1, 'used': 3, 'directed': 1, 'leave': 1, 'occupied': 1, 'trend': 1, 'past': 2, 'several': 2, 'delivery': 1, 'even': 7, 'year': 3, 'middle': 3, 'suitable': 1, 'onky': 1, 'ie': 1, 'fast': 2, 'recent': 1, 'kovil': 1, 'dependable': 1, 'helpful': 3, 'travellers': 1, '40': 1, 'ignoring': 1, 'news': 2, 'bottom': 1, 'never': 1, 'noticed': 1, 'damage': 6, 'technopark': 2, 'manathoor': 1, 'country': 2, 'inform': 1, 'evening': 1, 'sometimes': 2, 'suffering': 2, 'manually': 1, 'ramamangalam': 1, 'visibility': 1, 'kallingal': 2, 'permits': 1, 'making': 1, 'word': 1, 'huge': 1, 'edge': 1, 'shacks': 1, 'direction': 2, 'systems': 1, 'state': 1, 'chance': 1, 'actually': 1, 'kumarakam': 2, 'department': 3, 'reckless': 1, 'drainage': 2, 'almost': 1, 'works': 4, 'away': 1, 'maintenance': 5, 'real': 1, 'insurance': 1, 'maniykumpparakarimkunnam': 1, 'control': 2, 'landslide': 1, 'roadside': 1, 'get': 2, 'trucks': 1, 'none': 1, 'prior': 1, 'learnt': 1, 'rashly': 1, 'face': 1, 'unexpected': 1, 'growing': 2, 'repairing': 1, 'car': 5, 'changes': 1, 'per': 2, 'danger': 1, 'pothole': 2, 'maple': 1, 'request': 2, 'january': 1}\n",
      "['road', 'roads', 'bus', 'drivers', 'condition', 'buses', 'accidents', 'vehicles', 'traffic', 'please', 'also', 'ksrtc', 'due', 'city', 'take', 'public', 'proper', 'people', 'many', 'like', 'even', 'action', 'wall', 'transport', 'towards', 'stop', 'problem', 'necessary', 'make', 'know', 'going', 'day', 'damage', 'area', 'would', 'time', 'service', 'potholes', 'passengers', 'maintenance', 'last', 'car', 'works', 'sreekaryam', 'sir', 'services', 'see', 'seats', 'seat', 'right', 'reach', 'railway', 'poor', 'one', 'number', 'maintained', 'lack', 'kindly', 'high', 'government', 'dont', 'difficult', 'damaged', 'daily', 'college', 'around', 'areas', 'year', 'well', 'water', 'used', 'trivandrum', 'travelling', 'travel', 'transportation', 'toll', 'times', 'tax', 'students', 'stopped', 'side', 'shops', 'shed', 'safety', 'running', 'route', 'repair', 'recently', 'pwd', 'properly', 'problems', 'pedestrians', 'needful', 'much', 'morning', 'middle', 'may', 'makes', 'lot', 'leads', 'late', 'kerala', 'india', 'increase', 'hitting', 'helpful', 'height', 'got', 'given', 'flow', 'every', 'establishments', 'early', 'driver', 'district', 'department', 'crossing', 'congestion', 'compound', 'causing', 'cause', 'bridge', 'bad', 'back', 'amount', '3', 'years', 'work', 'without', 'width', 'whole', 'wear', 'way', 'waiting', 'villages', 'vehicle', 'use', 'unauthorized', 'two', 'traders', 'town', 'things', 'tent', 'technopark', 'technology', 'tear', 'tarring', 'sufficient', 'suffering', 'student', 'street', 'still', 'speed', 'sometimes', 'something', 'several', 'selling', 'season', 'rural', 'rules', 'risk', 'result', 'reserved', 'requested', 'request', 'repaired', 'reason', 'rainy', 'quality', 'provide', 'process', 'pothole', 'potential', 'pot', 'possible', 'petty', 'per', 'past', 'passenger', 'overspeeding', 'others', 'notice', 'news', 'nagar', 'mtr', 'months', 'money', 'low', 'lots', 'living', 'limit', 'length', 'least', 'law', 'large', 'kumarakam', 'kids', 'kallingal', 'issues', 'increased', 'hours', 'hope', 'holes', 'hit', 'heavy', 'health', 'hazards', 'gutter', 'growing', 'give', 'get', 'fully', 'full', 'fuel', 'footpath', 'filled', 'feet', 'fast', 'existing', 'etc', 'ernakulam', 'employees', 'driving', 'drainage', 'direction', 'digged', 'days', 'created', 'create', 'country', 'control', 'construction', 'constructed', 'consideration', 'conditions', 'commute', 'common', 'collected', 'clean', 'citizens', 'cars', 'card', 'cant', 'busses', 'businessmen', 'business', 'broken', 'bothered', 'balance', 'avoid', 'attention', 'atleast', 'ambadi', 'always', 'actions', 'accident', '15', '13th', '1', 'ymcacross', 'worthy', 'worst', 'workers', 'word', 'withing', 'willing', 'week', 'wayside', 'wants', 'walking', 'visit', 'visibility', 'violations', 'violation', 'view', 'via', 'venjaramoodu', 'venjaramood', 'vendors', 'vayal', 'various', 'value', 'valakom', 'usually', 'using', 'us', 'urgent', 'upon', 'unwary', 'unpredictable', 'unpaved', 'unexpected', 'undue', 'underlying', 'underground', 'ultimately', 'types', 'twowheelers', 'try', 'trucks', 'trivandrumidukkikattappana', 'trend', 'travelyesterday', 'travelplease', 'travellers', 'traveller', 'travelled', 'tractors', 'toyota', 'totally', 'took', 'toilets', 'today', 'tired', 'tire', 'timings', 'timeconsuming', 'till', 'threat', 'thodupuzha', 'themgod', 'thazha', 'thannippara', 'thanks', 'thampanoor', 'thadoli', 'tender', 'telephone', 'tea', 'taskirequests', 'tared', 'tar', 'taluk', 'taking', 'takes', 'systems', 'system', 'surprise', 'super', 'suitable', 'suddenly', 'sudden', 'submitted', 'streets', 'stopping', 'steps', 'steady', 'stationso', 'station', 'state', 'starting', 'standing', 'ss', 'spend', 'solve', 'solely', 'snacks', 'small', 'slippery', 'size', 'six', 'situations', 'situation', 'sirmadam', 'since', 'signal', 'sign', 'showrooms', 'shortcuts', 'shortcut', 'shoe', 'shattered', 'shacks', 'shack', 'serious', 'seek', 'sector', 'school', 'schedule', 'saved', 'safer', 'safe', 'rushy', 'rudely', 'roots', 'roadside', 'rising', 'retarring', 'retarr', 'retar', 'resurfaced', 'resulting', 'restaurants', 'responsible', 'resident', 'rescheduling', 'requires', 'required', 'repairs', 'repairing', 'rentals', 'removed', 'related', 'reimbursement', 'regular', 'register', 'regarding', 'reduced', 'reduce', 'reckless', 'recent', 'reasonable', 'real', 'reaching', 'rashly', 'ran', 'ramamangalam', 'raised', 'raining', 'pvc', 'puzha', 'provision', 'prone', 'progressing', 'prior', 'prices', 'prevalent', 'present', 'pregnant', 'predict', 'pose', 'pop', 'poovathumkadavu', 'politicians', 'point', 'planning', 'plan', 'place', 'pity', 'pits', 'pitfalls', 'pine', 'physical', 'photos', 'phase', 'peruvammuzhy', 'person', 'permits', 'permissions', 'percent', 'peakhour', 'pay', 'paved', 'pattazhy', 'pathholes', 'pathetic', 'pathanapurm', 'passing', 'pasengers', 'part', 'parking', 'pan', 'palakkad', 'pala', 'outlet', 'othukkungal', 'ordinary', 'open', 'onky', 'old', 'offices', 'office', 'occupied', 'notnot', 'noticed', 'none', 'nippol', 'night', 'next', 'newly', 'new', 'never', 'negligence', 'needed', 'nearby', 'nayadan', 'nature', 'nation', 'name', 'nadakkavu', 'muvattupzha', 'muvattupuza', 'muthambioorallur', 'mukkam', 'mud', 'mr', 'motorist', 'moreover', 'monthsafter', 'modernization', 'mla', 'miss', 'miserable', 'misbehaviour', 'minimum', 'mid', 'meter', 'melattumoozhy', 'media', 'mathilakam', 'masalas', 'markings', 'maple', 'manually', 'manorama', 'maniykumpparakarimkunnam', 'mangotu', 'manathoor', 'man', 'male', 'malappuram', 'making', 'major', 'losses', 'losing', 'loose', 'long', 'locations', 'located', 'locality', 'local', 'little', 'liquiors', 'lines', 'limited', 'light', 'life', 'licence', 'liability', 'leveled', 'letting', 'less', 'left', 'leave', 'learnt', 'layman', 'lax', 'laws', 'latest', 'lane', 'landslide', 'lake', 'lady', 'ladies', 'lacs', 'kwh', 'kumar', 'kulathurstudents', 'koyilandy', 'kovil', 'kottukunnam', 'kottayam', 'kottakkal', 'kotooli', 'kolenchery', 'kochi', 'knows', 'km', 'kl157912', 'kind', 'kills', 'keshavadasapuram', 'keep', 'kazhakkuttam', 'kattakkada', 'kattakada', 'karukaputhurpallipadamthichur', 'junction', 'january', 'jam', 'issue', 'isnt', 'intervention', 'intersection', 'intended', 'insurance', 'instead', 'innocent', 'injury', 'initiate', 'inform', 'inescapable', 'indifferent', 'indiavision', 'increasing', 'increases', 'inconvenience', 'income', 'include', 'important', 'implement', 'impeding', 'immediatelythe', 'immediately', 'immediate', 'illustrate', 'illegal', 'ignoring', 'ie', 'idea', 'id', 'huge', 'houses', 'hoping', 'hopefully', 'hill', 'highway', 'highspeed', 'hidden', 'help', 'heavyweight', 'heavily', 'harsh', 'handle', 'half', 'gst', 'great', 'good', 'goes', 'go', 'gate', 'frequently', 'frequent', 'found', 'forget', 'footwalk', 'follow', 'flooded', 'fix', 'fish', 'first', 'find', 'femalesthen', 'femalesas', 'females', 'feelplease', 'fee', 'faster', 'fall', 'factors', 'facing', 'facility', 'face', 'extremly', 'extent', 'experienced', 'example', 'evict', 'everybody', 'evening', 'etcthe', 'etcetc', 'estate', 'especially', 'equality', 'entering', 'enforcement', 'emerge', 'effective', 'effected', 'effect', 'edge', 'earliest', 'earlier', 'duration', 'dug', 'drove', 'driven', 'done', 'distis', 'directly', 'directed', 'digital', 'difficulty', 'diameter', 'destroyed', 'destination', 'despite', 'depending', 'dependable', 'depend', 'delivery', 'defects', 'dear', 'date', 'dashed', 'dangerous', 'danger', 'cyclists', 'current', 'crowed', 'crossings', 'crew', 'creating', 'countless', 'cottton', 'corruption', 'correct', 'converted', 'convenient', 'controlled', 'contributions', 'contract', 'continuing', 'continue', 'constructing', 'constituency', 'consider', 'connection', 'connecting', 'confirm', 'conductors', 'conductor', 'concreated', 'complexes', 'completion', 'completely', 'complaint', 'companies', 'collectors', 'cocanuts', 'class', 'claims', 'choose', 'choondy', 'chithravila', 'chipping', 'charge', 'channels', 'changes', 'change', 'chances', 'chance', 'certain', 'centers', 'causes', 'caused', 'carts', 'caring', 'carelessly', 'cancelled', 'canal', 'came', 'calicut', 'cables', 'busy', 'businesses', 'busiest', 'busesplease', 'buseskindly', 'busesatleast', 'buildings', 'build', 'brutally', 'bribe', 'bottom', 'bothers', 'booths', 'boards', 'boarder', 'blocking', 'block', 'bikes', 'bikers', 'biggest', 'big', 'behind', 'behaving', 'behave', 'beautification', 'bear', 'basic', 'base', 'barrier', 'away', 'aware', 'authority', 'authorites', 'attitude', 'attinkuzhy', 'attached', 'ask', 'asianet', 'arrive', 'arrange', 'aroor', 'arookutty', 'argue', 'appeal', 'amenities', 'almost', 'alloted', 'alappuzha', 'aid', 'aggravates', 'advice', 'add', 'actually', 'activity', 'access', '730', '6', '500', '5', '40', '300', '25', '23', '2', '12th', '12m', '100']\n",
      "\n",
      "\n",
      "KEYWORDS  PWD\n",
      "\n",
      "\n",
      "[['road', 'roads', 'bus', 'drivers', 'condition']]\n",
      "\n",
      "\n",
      " KSEB Freq newwwwwwwwww\n",
      "{'amount': 3, 'person': 1, 'town': 2, 'drivers': 11, 'rushy': 1, 'system': 1, 'great': 1, 'tea': 1, 'late': 3, 'cause': 3, 'public': 7, 'roads': 30, 'card': 2, 'hope': 2, 'immediatelythe': 1, '1': 2, 'bad': 3, 'right': 4, 'way': 2, 'notice': 2, 'lack': 4, 'karukaputhurpallipadamthichur': 1, 'problems': 3, 'impeding': 1, 'despite': 1, 'dear': 1, 'busy': 1, 'kindly': 4, 'urgent': 1, 'frequently': 1, 'lots': 2, 'road': 66, 'add': 1, 'worst': 1, 'today': 1, 'starting': 1, 'dug': 1, 'channels': 1, 'mathilakam': 1, 'provide': 2, 'completion': 1, 'politicians': 1, 'pregnant': 1, 'station': 1, 'carelessly': 1, 'corruption': 1, 'unpredictable': 1, 'came': 1, 'technology': 2, 'pathholes': 1, 'transport': 6, 'register': 1, 'accidents': 10, 'busses': 2, 'jam': 1, 'losses': 1, 'venjaramoodu': 1, 'include': 1, 'aggravates': 1, 'reimbursement': 1, 'vehicle': 2, 'tax': 3, 'necessary': 6, 'sir': 4, 'fall': 1, 'feet': 2, 'companies': 1, 'bothered': 2, 'nearby': 1, 'rules': 2, 'half': 1, '12th': 1, 'repair': 3, 'moreover': 1, 'tire': 1, 'streets': 1, 'emerge': 1, 'authorites': 1, 'crowed': 1, 'example': 1, 'lax': 1, 'collected': 2, 'minimum': 1, 'driver': 3, 'establishments': 3, 'idea': 1, 'issue': 1, 'make': 6, 'name': 1, 'valakom': 1, 'man': 1, 'cables': 1, 'office': 1, 'overspeeding': 2, 'limit': 2, 'ladies': 1, 'attention': 2, 'congestion': 3, 'facing': 1, 'convenient': 1, 'leads': 3, 'attached': 1, 'travelyesterday': 1, 'loose': 1, 'footpath': 2, 'class': 1, 'money': 2, 'muvattupuza': 1, 'phase': 1, 'meter': 1, 'nagar': 2, 'services': 4, 'parking': 1, 'masalas': 1, 'effective': 1, 'thadoli': 1, 'causing': 3, 'leveled': 1, 'booths': 1, 'clean': 2, 'steady': 1, 'repairs': 1, '100': 1, 'upon': 1, 'important': 1, 'vendors': 1, 'injury': 1, 'rescheduling': 1, 'reasonable': 1, 'worthy': 1, 'regular': 1, 'driven': 1, 'running': 3, 'male': 1, 'passengers': 5, 'bikers': 1, 'toll': 3, 'immediately': 1, 'citizens': 2, 'travelling': 3, 'distis': 1, 'tent': 2, 'pathanapurm': 1, 'would': 5, 'ksrtc': 8, 'pan': 1, 'damaged': 4, 'kl157912': 1, 'innocent': 1, 'drove': 1, 'resurfaced': 1, 'difficult': 4, 'stopped': 3, 'poovathumkadavu': 1, 'connecting': 1, 'females': 1, 'limited': 1, 'initiate': 1, '25': 1, 'duration': 1, 'hidden': 1, 'difficulty': 1, 'underlying': 1, 'also': 9, 'dashed': 1, 'shops': 3, 'footwalk': 1, 'carts': 1, 'restaurants': 1, 'rudely': 1, 'maintained': 4, 'serious': 1, '13th': 2, 'telephone': 1, 'date': 1, 'behave': 1, 'requested': 2, 'sign': 1, 'local': 1, 'laws': 1, 'thazha': 1, 'rising': 1, 'shortcut': 1, 'pity': 1, 'types': 1, 'areas': 4, 'pits': 1, 'heavily': 1, 'shattered': 1, 'kwh': 1, 'daily': 4, 'current': 1, 'always': 2, 'least': 2, 'retarring': 1, 'forget': 1, 'rural': 2, 'slippery': 1, 'safer': 1, 'lacs': 1, 'filled': 2, 'flooded': 1, '15': 2, 'intersection': 1, 'crew': 1, 'toyota': 1, 'tarring': 2, 'petty': 2, 'chithravila': 1, 'actions': 2, 'misbehaviour': 1, 'district': 3, 'illegal': 1, 'morning': 3, 'result': 2, 'consideration': 2, 'reaching': 1, 'hit': 2, 'place': 1, 'railway': 4, 'continue': 1, 'mukkam': 1, 'calicut': 1, 'timings': 1, 'nature': 1, 'handle': 1, 'light': 1, 'caused': 1, 'connection': 1, '300': 1, 'problem': 6, 'othukkungal': 1, '2': 1, 'biggest': 1, 'collectors': 1, 'effect': 1, 'season': 2, 'tar': 1, '500': 1, 'passenger': 2, 'aware': 1, 'shortcuts': 1, 'dangerous': 1, 'alloted': 1, 'attitude': 1, 'underground': 1, 'shoe': 1, 'build': 1, 'pathetic': 1, 'violation': 1, 'old': 1, 'hopefully': 1, 'solely': 1, 'us': 1, 'bribe': 1, 'employees': 2, 'know': 6, 'unauthorized': 2, 'cars': 2, 'took': 1, 'since': 1, 'businesses': 1, 'layman': 1, 'increases': 1, 'cant': 2, 'aid': 1, 'centers': 1, 'avoid': 2, 'shack': 1, 'mud': 1, 'going': 6, 'tired': 1, 'kerala': 3, 'little': 1, 'seat': 4, 'kulathurstudents': 1, 'visit': 1, 'barrier': 1, 'evict': 1, 'area': 6, 'cottton': 1, 'immediate': 1, 'digital': 1, 'rentals': 1, 'losing': 1, 'income': 1, 'advice': 1, 'needed': 1, 'plan': 1, 'last': 5, 'caring': 1, 'needful': 3, 'monthsafter': 1, 'arrange': 1, 'atleast': 2, 'consider': 1, 'isnt': 1, 'tear': 2, 'mr': 1, 'directly': 1, 'locations': 1, 'created': 2, 'condition': 10, 'kochi': 1, 'converted': 1, 'digged': 2, 'complexes': 1, 'conductors': 1, 'constructed': 2, 'argue': 1, 'bridge': 3, 'withing': 1, 'earlier': 1, 'usually': 1, 'stationso': 1, 'sirmadam': 1, 'increased': 2, 'student': 2, 'highspeed': 1, 'whole': 2, 'femalesthen': 1, 'find': 1, 'try': 1, 'water': 3, 'thodupuzha': 1, 'showrooms': 1, 'resulting': 1, 'schedule': 1, 'college': 4, 'equality': 1, 'fully': 2, 'attinkuzhy': 1, 'safe': 1, 'view': 1, 'work': 2, 'trivandrum': 3, 'passing': 1, 'predict': 1, 'two': 2, 'six': 1, 'good': 1, 'sudden': 1, 'saved': 1, 'offices': 1, 'got': 3, 'reserved': 2, 'lane': 1, 'stop': 6, 'muthambioorallur': 1, 'follow': 1, 'pedestrians': 3, 'indifferent': 1, 'controlled': 1, 'increasing': 1, 'media': 1, 'less': 1, 'compound': 3, 'physical': 1, 'still': 2, 'crossings': 1, 'via': 1, 'mangotu': 1, 'pitfalls': 1, 'entering': 1, 'brutally': 1, 'week': 1, 'please': 9, 'selling': 2, 'days': 2, 'create': 2, 'everybody': 1, 'hitting': 3, 'shed': 3, 'raised': 1, 'proper': 7, 'located': 1, 'kills': 1, 'totally': 1, 'effected': 1, 'related': 1, 'open': 1, 'around': 4, 'small': 1, 'low': 2, 'early': 3, 'street': 2, 'help': 1, 'months': 2, 'especially': 1, 'point': 1, 'cyclists': 1, 'pvc': 1, 'peruvammuzhy': 1, '23': 1, 'lady': 1, 'traveller': 1, 'sufficient': 2, 'process': 2, 'completely': 1, 'instead': 1, 'modernization': 1, 'ambadi': 2, 'keshavadasapuram': 1, 'safety': 3, 'situation': 1, 'years': 2, 'others': 2, 'reduce': 1, 'block': 1, 'dont': 4, 'latest': 1, 'health': 2, 'indiavision': 1, 'tender': 1, 'properly': 3, 'accident': 2, 'present': 1, 'inescapable': 1, 'diameter': 1, 'ask': 1, 'big': 1, 'steps': 1, 'threat': 1, 'next': 1, 'kottayam': 1, 'towards': 6, 'depending': 1, 'seats': 4, 'poor': 4, 'activity': 1, 'access': 1, 'destination': 1, 'construction': 2, 'time': 5, 'liability': 1, 'contributions': 1, 'kolenchery': 1, 'city': 8, 'constructing': 1, 'traders': 2, 'locality': 1, 'enforcement': 1, 'see': 4, 'fee': 1, 'alappuzha': 1, 'driving': 2, 'reason': 2, 'concreated': 1, 'arrive': 1, 'complaint': 1, 'recently': 3, 'every': 3, 'kattakada': 1, 'use': 2, 'regarding': 1, 'timeconsuming': 1, 'life': 1, 'route': 3, 'businessmen': 2, 'gutter': 2, '12m': 1, 'amenities': 1, 'extremly': 1, 'travelled': 1, 'may': 3, 'width': 2, 'authority': 1, 'busesplease': 1, 'cancelled': 1, 'illustrate': 1, 'estate': 1, 'reduced': 1, 'potential': 2, 'pattazhy': 1, 'unpaved': 1, 'sector': 1, 'kumar': 1, 'fuel': 2, 'liquiors': 1, 'miserable': 1, 'hours': 2, 'bikes': 1, 'choose': 1, 'give': 2, 'gst': 1, 'conductor': 1, 'negligence': 1, 'given': 3, 'mid': 1, 'etcetc': 1, 'large': 2, 'bus': 16, 'factors': 1, 'kottakkal': 1, 'number': 4, 'first': 1, 'venjaramood': 1, 'ran': 1, 'hazards': 2, 'nippol': 1, 'pasengers': 1, 'cocanuts': 1, 'retarr': 1, 'prone': 1, 'possible': 2, 'busiest': 1, 'day': 6, 'workers': 1, 'things': 2, 'intervention': 1, 'motorist': 1, 'living': 2, 'paved': 1, 'take': 7, 'kazhakkuttam': 1, 'constituency': 1, 'asianet': 1, 'behaving': 1, 'government': 4, 'transportation': 3, 'palakkad': 1, 'without': 2, 'thanks': 1, 'provision': 1, 'tared': 1, 'surprise': 1, 'heavy': 2, 'heavyweight': 1, 'bear': 1, 'increase': 3, 'tractors': 1, 'vayal': 1, 'responsible': 1, 'students': 3, 'walking': 1, 'implement': 1, 'photos': 1, 'retar': 1, 'kids': 2, 'part': 1, 'letting': 1, 'mtr': 2, 'speed': 2, 'muvattupzha': 1, 'go': 1, 'signal': 1, 'requires': 1, 'basic': 1, 'taskirequests': 1, '5': 1, 'chipping': 1, 'new': 1, 'base': 1, 'buildings': 1, 'behind': 1, 'houses': 1, 'major': 1, 'correct': 1, 'certain': 1, 'pot': 2, 'manorama': 1, 'times': 3, 'licence': 1, 'planning': 1, 'kottukunnam': 1, 'traffic': 9, 'wayside': 1, 'reach': 4, 'twowheelers': 1, 'left': 1, 'wants': 1, 'etcthe': 1, 'frequent': 1, 'unwary': 1, 'high': 4, 'done': 1, 'standing': 1, 'repaired': 2, 'koyilandy': 1, 'newly': 1, 'ymcacross': 1, 'aroor': 1, 'pala': 1, 'kotooli': 1, '730': 1, 'undue': 1, 'night': 1, 'suddenly': 1, 'school': 1, 'using': 1, 'beautification': 1, 'defects': 1, 'raining': 1, 'lake': 1, 'side': 3, 'pose': 1, 'permissions': 1, 'boarder': 1, 'lot': 3, 'inconvenience': 1, 'toilets': 1, 'hoping': 1, 'india': 3, 'required': 1, 'travel': 3, 'ss': 1, 'blocking': 1, 'facility': 1, 'various': 1, 'height': 3, 'business': 2, 'many': 7, 'like': 7, 'fix': 1, 'hill': 1, 'waiting': 2, 'violations': 1, 'well': 3, 'buses': 10, 'themgod': 1, '6': 1, 'pay': 1, 'length': 2, 'highway': 1, 'commute': 2, 'nadakkavu': 1, 'keep': 1, 'taking': 1, 'ordinary': 1, 'one': 4, 'roots': 1, 'existing': 2, 'sreekaryam': 4, 'seek': 1, 'spend': 1, 'junction': 1, 'thannippara': 1, 'long': 1, 'potholes': 5, 'something': 2, 'till': 1, 'outlet': 1, 'progressing': 1, 'rainy': 2, 'malappuram': 1, 'confirm': 1, 'claims': 1, 'vehicles': 9, 'common': 2, 'creating': 1, 'kind': 1, 'goes': 1, 'willing': 1, 'buseskindly': 1, 'found': 1, '3': 3, 'issues': 2, 'flow': 3, 'destroyed': 1, 'removed': 1, 'villages': 2, 'pwd': 3, 'busesatleast': 1, 'id': 1, 'mla': 1, 'melattumoozhy': 1, 'kattakkada': 1, 'stopping': 1, 'gate': 1, 'action': 7, 'feelplease': 1, 'knows': 1, 'wear': 2, 'risk': 2, 'pine': 1, 'nation': 1, 'pop': 1, 'size': 1, 'causes': 1, 'markings': 1, 'people': 7, 'super': 1, 'prices': 1, 'situations': 1, 'quality': 2, 'femalesas': 1, 'prevalent': 1, 'faster': 1, 'ultimately': 1, 'choondy': 1, 'due': 8, 'arookutty': 1, 'percent': 1, 'chances': 1, 'crossing': 3, 'experienced': 1, 'extent': 1, 'submitted': 1, 'law': 2, 'much': 3, 'thampanoor': 1, 'peakhour': 1, 'km': 1, 'miss': 1, 'snacks': 1, 'intended': 1, 'change': 1, 'travelplease': 1, 'back': 3, 'wall': 6, 'nayadan': 1, 'depend': 1, 'harsh': 1, 'continuing': 1, 'service': 5, 'resident': 1, 'charge': 1, 'taluk': 1, 'takes': 1, 'appeal': 1, 'earliest': 1, 'etc': 2, 'boards': 1, 'makes': 3, 'ernakulam': 2, 'puzha': 1, 'fish': 1, 'lines': 1, 'conditions': 2, 'contract': 1, 'full': 2, 'notnot': 1, 'trivandrumidukkikattappana': 1, 'canal': 1, 'broken': 2, 'solve': 1, 'holes': 2, 'value': 1, 'balance': 2, 'countless': 1, 'bothers': 1, 'used': 3, 'directed': 1, 'leave': 1, 'occupied': 1, 'trend': 1, 'past': 2, 'several': 2, 'delivery': 1, 'even': 7, 'year': 3, 'middle': 3, 'suitable': 1, 'onky': 1, 'ie': 1, 'fast': 2, 'recent': 1, 'kovil': 1, 'dependable': 1, 'helpful': 3, 'travellers': 1, '40': 1, 'ignoring': 1, 'news': 2, 'bottom': 1, 'never': 1, 'noticed': 1, 'damage': 6, 'technopark': 2, 'manathoor': 1, 'country': 2, 'inform': 1, 'evening': 1, 'sometimes': 2, 'suffering': 2, 'manually': 1, 'ramamangalam': 1, 'visibility': 1, 'kallingal': 2, 'permits': 1, 'making': 1, 'word': 1, 'huge': 1, 'edge': 1, 'shacks': 1, 'direction': 2, 'systems': 1, 'state': 1, 'chance': 1, 'actually': 1, 'kumarakam': 2, 'department': 3, 'reckless': 1, 'drainage': 2, 'almost': 1, 'works': 4, 'away': 1, 'maintenance': 5, 'real': 1, 'insurance': 1, 'maniykumpparakarimkunnam': 1, 'control': 2, 'landslide': 1, 'roadside': 1, 'get': 2, 'trucks': 1, 'none': 1, 'prior': 1, 'learnt': 1, 'rashly': 1, 'face': 1, 'unexpected': 1, 'growing': 2, 'repairing': 1, 'car': 5, 'changes': 1, 'per': 2, 'danger': 1, 'pothole': 2, 'maple': 1, 'request': 2, 'january': 1}\n",
      "['power', 'electricity', 'time', 'connection', 'working', 'wires', 'got', 'voltage', 'problem', 'please', 'issue', 'high', 'facing', 'even', 'due', 'cuts', 'without', 'using', 'us', 'transformer', 'supply', 'shedding', 'sector', 'repair', 'prior', 'phase', 'one', 'night', 'new', 'months', 'meter', 'many', 'make', 'locality', 'load', 'lights', 'last', 'house', 'home', 'failure', 'every', 'electric', 'day', 'bribe', 'bad', 'years', 'wrongly', 'well', 'values', 'use', 'unsocial', 'unnoticed', 'unavailability', 'unable', 'trouble', 'trivandrum', 'times', 'till', 'three', 'though', 'take', 'sure', 'summer', 'street', 'still', 'state', 'sound', 'since', 'showing', 'shortage', 'set', 'section', 'scenario', 'say', 'rs', 'robbery', 'result', 'request', 'replace', 'regular', 'rectified', 'recently', 'reason', 'raining', 'public', 'proper', 'procedure', 'platforms', 'phases', 'peoples', 'peak', 'past', 'particular', 'overhead', 'overall', 'old', 'occurring', 'notice', 'normalplease', 'needed', 'necessary', 'near', 'must', 'morning', 'month', 'money', 'misbehaved', 'makes', 'major', 'madavoor', 'low', 'lot', 'loss', 'look', 'lineman', 'left', 'large', 'knows', 'industries', 'houses', 'hot', 'highly', 'heavy', 'havent', 'grabbing', 'going', 'give', 'get', 'frequently', 'frequent', 'force', 'fix', 'first', 'find', 'fastly', 'fast', 'farming', 'failures', 'failed', 'exploded', 'experiences', 'examinations', 'everyone', 'evening', 'equipments', 'ensurde', 'employees', 'electronic', 'electrical', 'easily', 'ease', 'drunken', 'difficult', 'different', 'devices', 'daysremaining', 'daysplease', 'damaged', 'cut', 'current', 'crawl', 'corrupt', 'continues', 'connections', 'connectionplease', 'connected', 'condition', 'complaint', 'communication', 'comes', 'city', 'checking', 'came', 'burnt', 'big', 'avoid', 'applied', 'appliances', 'announcements', 'always', 'almost', 'affect', 'adjoining', 'activities', 'action', '700', '3', '15']\n",
      "\n",
      "\n",
      "KEYWORDS  KSEB\n",
      "\n",
      "\n",
      "[['power', 'electricity', 'time', 'connection', 'working']]\n",
      "\n",
      "\n",
      " KSRTC Freq newwwwwwwwww\n",
      "{'amount': 1, 'person': 1, 'town': 1, 'others': 1, 'drivers': 4, 'lady': 1, 'rural': 1, 'rushy': 1, 'safer': 1, 'kottayam': 1, 'like': 1, 'filled': 1, 'inconvenience': 1, 'late': 3, 'public': 3, 'hill': 1, 'busses': 2, 'necessary': 1, 'well': 1, 'buses': 10, 'right': 1, 'traveller': 1, 'needful': 1, 'lack': 2, 'commute': 2, 'keep': 1, 'one': 1, 'transportation': 1, 'busy': 1, 'kindly': 1, 'sreekaryam': 1, 'reaching': 1, 'present': 1, 'spend': 1, 'access': 1, 'control': 1, 'lots': 2, 'ask': 1, 'mukkam': 1, 'via': 1, 'kl157912': 1, 'timings': 1, 'frequently': 1, 'caused': 1, 'depending': 1, 'seats': 4, 'confirm': 1, '25': 1, 'hit': 1, 'destination': 1, 'provide': 2, 'time': 4, 'found': 1, 'city': 4, 'station': 1, 'buseskindly': 1, 'shortcuts': 1, 'came': 1, 'alloted': 1, 'got': 2, 'see': 2, 'transport': 2, 'reason': 1, 'accidents': 1, 'almost': 1, 'arrive': 1, 'busesatleast': 1, 'fast': 2, 'solely': 1, 'government': 1, 'kattakada': 1, 'use': 1, 'venjaramoodu': 1, 'kattakkada': 1, 'stopping': 1, 'life': 1, 'route': 3, 'week': 1, 'passenger': 2, 'action': 2, 'totally': 1, 'took': 1, 'feelplease': 1, 'cant': 1, 'risk': 1, 'bothered': 2, 'helpful': 2, 'going': 2, 'argue': 1, 'travelled': 1, 'causes': 1, 'equality': 1, 'people': 3, 'super': 1, 'recently': 3, 'busesplease': 1, 'femalesas': 1, 'seat': 4, 'kulathurstudents': 1, 'reduced': 1, 'authorites': 1, 'due': 3, 'hours': 2, 'percent': 1, 'area': 2, 'cottton': 1, 'around': 3, 'experienced': 1, 'driver': 2, 'effective': 1, 'cancelled': 1, 'much': 1, 'stopped': 1, 'choose': 1, 'give': 1, 'forget': 1, 'tired': 1, 'ran': 1, 'make': 1, 'miss': 1, 'advice': 1, 'intended': 1, 'change': 1, 'overspeeding': 2, 'bus': 14, 'back': 2, 'number': 2, 'venjaramood': 1, 'facing': 1, 'service': 5, 'convenient': 1, 'trivandrum': 1, 'arrange': 1, 'travel': 1, 'kills': 1, 'atleast': 2, 'travelyesterday': 1, '2': 1, 'crossing': 1, 'willing': 1, 'muvattupuza': 1, 'great': 1, 'local': 1, 'services': 4, 'workers': 1, 'locations': 1, 'ernakulam': 1, 'income': 1, 'class': 1, 'lines': 1, 'causing': 1, 'take': 2, 'kazhakkuttam': 1, 'behaving': 1, 'school': 1, 'upon': 1, 'value': 1, 'morning': 2, 'rescheduling': 1, 'leave': 1, 'given': 1, 'occupied': 1, 'running': 1, 'earlier': 1, 'passengers': 3, 'usually': 1, 'increase': 1, 'several': 1, 'even': 3, 'student': 1, 'students': 3, 'dont': 2, 'whole': 1, 'femalesthen': 1, 'travelling': 1, 'onky': 1, 'would': 4, 'ksrtc': 8, 'speed': 1, 'dependable': 1, 'schedule': 1, 'college': 4, 'innocent': 1, 'travellers': 1, 'fully': 1, 'ignoring': 1, 'balance': 1, 'drove': 1, 'never': 1, 'noticed': 1, 'difficult': 1, 'damage': 1, 'conductor': 1, 'day': 1, 'railway': 2, 'females': 1, 'inform': 1, 'six': 1, 'safety': 1, 'limited': 1, 'depend': 1, 'sometimes': 1, 'times': 1, 'reserved': 2, 'stop': 4, 'rudely': 1, 'kottukunnam': 1, 'word': 1, 'dashed': 1, 'reach': 4, 'vehicles': 1, 'carelessly': 1, 'man': 1, 'regular': 1, 'nadakkavu': 1, 'done': 1, 'standing': 1, 'kumarakam': 2, 'mid': 1, 'difficulty': 1, 'brutally': 1, 'please': 1, 'us': 1, 'behave': 1, '730': 1, 'male': 1, 'add': 1, 'proper': 1, 'pasengers': 1, 'night': 1, 'get': 1, 'conductors': 1, 'using': 1, 'none': 1, 'problem': 3, 'rashly': 1, 'face': 1, 'ymcacross': 1, 'sir': 1, 'work': 1, 'trivandrumidukkikattappana': 1, 'raining': 1, 'car': 4, 'areas': 1, 'low': 1, 'road': 2, 'heavily': 1, 'past': 1, 'hoping': 1, 'request': 2, 'daily': 1, 'stationso': 1, 'always': 1, 'least': 1, '23': 1}\n",
      "['bus', 'buses', 'ksrtc', 'service', 'would', 'time', 'stop', 'services', 'seats', 'seat', 'reach', 'drivers', 'college', 'city', 'car', 'students', 'route', 'recently', 'public', 'problem', 'people', 'passengers', 'late', 'even', 'due', 'around', 'transport', 'take', 'see', 'road', 'reserved', 'request', 'railway', 'provide', 'passenger', 'overspeeding', 'number', 'morning', 'lots', 'lack', 'kumarakam', 'hours', 'helpful', 'got', 'going', 'fast', 'driver', 'dont', 'commute', 'busses', 'bothered', 'back', 'atleast', 'area', 'action', 'ymcacross', 'workers', 'work', 'word', 'willing', 'whole', 'well', 'week', 'via', 'venjaramoodu', 'venjaramood', 'vehicles', 'value', 'usually', 'using', 'use', 'us', 'upon', 'trivandrumidukkikattappana', 'trivandrum', 'travelyesterday', 'travelling', 'travellers', 'traveller', 'travelled', 'travel', 'transportation', 'town', 'totally', 'took', 'tired', 'timings', 'times', 'super', 'student', 'stopping', 'stopped', 'stationso', 'station', 'standing', 'sreekaryam', 'spend', 'speed', 'sometimes', 'solely', 'six', 'sir', 'shortcuts', 'several', 'school', 'schedule', 'safety', 'safer', 'rushy', 'rural', 'running', 'rudely', 'risk', 'right', 'rescheduling', 'regular', 'reduced', 'reason', 'reaching', 'rashly', 'ran', 'raining', 'proper', 'present', 'please', 'person', 'percent', 'past', 'pasengers', 'others', 'onky', 'one', 'occupied', 'noticed', 'none', 'night', 'never', 'needful', 'necessary', 'nadakkavu', 'muvattupuza', 'mukkam', 'much', 'miss', 'mid', 'man', 'male', 'make', 'low', 'locations', 'local', 'lines', 'limited', 'like', 'life', 'leave', 'least', 'lady', 'kulathurstudents', 'kottukunnam', 'kottayam', 'kl157912', 'kindly', 'kills', 'keep', 'kazhakkuttam', 'kattakkada', 'kattakada', 'intended', 'innocent', 'inform', 'increase', 'inconvenience', 'income', 'ignoring', 'hoping', 'hit', 'hill', 'heavily', 'great', 'government', 'given', 'give', 'get', 'fully', 'frequently', 'found', 'forget', 'filled', 'femalesthen', 'femalesas', 'females', 'feelplease', 'facing', 'face', 'experienced', 'ernakulam', 'equality', 'effective', 'earlier', 'drove', 'done', 'difficulty', 'difficult', 'destination', 'depending', 'dependable', 'depend', 'day', 'dashed', 'damage', 'daily', 'crossing', 'cottton', 'convenient', 'control', 'confirm', 'conductors', 'conductor', 'class', 'choose', 'change', 'causing', 'causes', 'caused', 'carelessly', 'cant', 'cancelled', 'came', 'busy', 'busesplease', 'buseskindly', 'busesatleast', 'brutally', 'behaving', 'behave', 'balance', 'authorites', 'ask', 'arrive', 'arrange', 'argue', 'areas', 'amount', 'always', 'almost', 'alloted', 'advice', 'add', 'accidents', 'access', '730', '25', '23', '2']\n",
      "\n",
      "\n",
      "KEYWORDS  KSRTC\n",
      "\n",
      "\n",
      "[['bus', 'buses', 'ksrtc', 'service', 'would']]\n",
      "\n",
      "\n",
      " ENV Freq newwwwwwwwww\n",
      "{'amount': 1, 'air': 4, 'uncleaned': 1, 'activities': 3, 'potentially': 1, 'harder': 1, 'supplied': 1, 'concern': 1, 'public': 3, 'water': 9, 'necessary': 3, 'impact': 2, 'bad': 1, 'way': 2, 'disposed': 1, 'throwing': 1, 'facing': 1, 'electronics': 1, 'ph': 1, 'sources': 2, 'avoiding': 1, 'health': 4, 'abruptly': 1, 'properly': 1, 'fertile': 1, 'rhythms': 1, 'going': 1, 'beings': 2, 'ghats': 1, 'decreases': 1, 'biodiversity': 1, 'acid': 2, 'livelihood': 1, 'big': 1, 'steps': 2, 'hand': 1, 'today': 1, 'generation': 1, 'excessive': 1, 'kerala': 2, 'gods': 1, 'plants': 1, 'construction': 2, 'efficient': 1, 'hormone': 1, 'time': 4, 'epa': 1, 'river': 2, 'higher': 2, 'city': 2, 'attempt': 1, 'intense': 1, 'useful': 1, 'made': 1, 'switching': 1, 'overcome': 1, 'rapidly': 1, 'remain': 1, 'witnessing': 1, 'use': 2, 'premises': 1, 'environment': 2, 'life': 2, 'become': 1, 'temperature': 3, 'kumbhachoodu': 1, 'fall': 1, 'grownup': 1, 'parties': 1, 'space': 1, 'nearby': 1, 'oragansations': 1, 'dissolves': 1, 'hotel': 1, 'noise': 2, 'radiations': 1, 'toxics': 1, 'residential': 2, 'becomes': 1, 'authority': 1, 'inform': 1, 'collect': 1, 'emissions': 1, 'example': 1, 'contribute': 1, 'builders': 1, 'affects': 1, 'fuel': 1, 'acidification': 1, 'diversity': 1, 'changes': 1, 'issue': 1, 'chlorine': 1, 'depletion': 1, 'erosion': 1, 'constructiondevelopment': 1, 'cause': 4, 'respiratory': 1, 'marine': 1, 'lead': 1, 'bus': 1, 'factors': 1, 'household': 1, 'contaminate': 1, 'wastes': 7, 'spills': 1, 'climate': 1, 'hazards': 1, 'residents': 1, 'survival': 1, 'possible': 1, 'negative': 1, 'migration': 1, 'problems': 2, 'lung': 1, 'deposits': 1, 'living': 3, 'causing': 2, 'ocean': 2, 'soil': 2, 'take': 3, 'trees': 4, 'bacteria': 1, 'burning': 1, 'euphoric': 1, 'summer': 2, 'quarries': 1, 'officials': 1, 'thanks': 1, 'waste': 5, 'harm': 3, 'heavy': 1, 'formed': 1, 'overfishing': 1, 'preserving': 1, 'increase': 1, 'political': 1, 'landfills': 1, 'part': 1, 'forest': 1, 'ksrtc': 1, 'uncontrolled': 1, 'cutting': 1, 'considering': 1, 'ponds': 1, 'expectedair': 1, 'factor': 1, 'unprecedental': 1, 'new': 1, 'make': 3, 'domestic': 2, 'initiate': 1, 'deforestation': 1, 'mercury': 1, 'biosphere': 1, 'cancer': 1, 'breeding': 1, 'soon': 1, 'saving': 1, 'rivers': 3, 'awareness': 1, 'curb': 1, 'survelliance': 1, 'earth': 1, 'oil': 2, 'obvious': 1, 'surge': 1, 'mechanism': 1, 'food': 1, 'fields': 2, 'polution': 1, 'also': 4, 'chemicals': 1, 'oxygen': 2, 'industrial': 2, 'issuesalso': 1, 'smelling': 1, 'night': 2, 'end': 1, 'diseases': 1, 'moderating': 1, 'intolerable': 1, 'rising': 1, 'termed': 1, 'would': 1, 'areas': 2, 'inviting': 1, 'religious': 1, 'lot': 1, 'heavily': 1, 'continuity': 1, 'disposal': 2, 'open': 1, 'paddy': 2, 'pollution': 5, 'facility': 1, 'real': 2, 'commercial': 1, 'quarrying': 2, 'disinfectants': 2, 'many': 5, 'like': 4, 'fix': 1, 'deterioration': 1, 'contaminated': 1, 'disrupted': 1, 'extremes': 1, 'produced': 1, 'actions': 1, 'alappad': 1, 'ecosystem': 1, 'difficulties': 1, 'threatening': 1, 'one': 2, 'illegal': 1, 'sides': 1, 'enter': 1, 'plastic': 1, 'western': 1, 'artificial': 2, 'long': 1, 'skin': 1, 'high': 2, 'term': 1, 'level': 1, 'among': 1, 'influence': 1, 'light': 2, 'number': 1, 'caused': 2, 'creating': 1, 'factories': 1, 'huge': 1, 'problem': 1, 'vehicles': 1, 'dispersal': 1, 'runoff': 1, 'energy': 1, 'effect': 1, 'season': 1, 'deaths': 2, 'government': 4, 'agriculture': 1, 'polluted': 1, 'major': 4, 'investigate': 1, 'issues': 1, 'levels': 3, 'utilizing': 1, 'build': 2, 'purposes': 1, 'old': 1, 'hair': 1, 'variety': 1, 'cadmium': 1, 'cvd': 1, 'need': 2, 'patients': 1, 'great': 1, 'lakes': 1, 'centers': 1, 'projects': 2, 'rampant': 1, 'places': 2, 'road': 2, 'causes': 4, 'fishes': 1, 'people': 4, 'cut': 2, 'quality': 1, 'dried': 1, 'circadian': 1, 'due': 3, 'dust': 1, 'streams': 1, 'households': 1, 'area': 1, 'feed': 1, 'touched': 1, 'planting': 1, 'much': 1, 'mining': 3, 'harmful': 1, 'serious': 1, 'change': 1, 'hide': 1, 'impacting': 1, 'check': 1, 'reduces': 1, 'animals': 1, 'plastics': 1, 'regulations': 1, 'humans': 2, 'reconsidered': 1, 'crops': 1, 'disease': 3, 'consider': 1, 'vehicle': 1, 'punish': 1, 'carbonic': 1, 'mighty': 1, 'etc': 1, 'recycling': 1, 'dump': 2, 'co₂': 1, 'save': 2, 'rate': 1, 'strangers': 1, 'affect': 1, 'kochi': 1, 'eradicated': 1, 'increased': 1, 'foul': 1, 'dying': 1, 'holes': 2, 'used': 1, 'ears': 1, 'several': 1, 'ways': 1, 'hard': 1, 'sand': 1, 'rashes': 1, 'dont': 1, 'interrupt': 1, 'move': 1, 'shaped': 1, 'continues': 1, 'bodies': 1, 'resulting': 1, 'catch': 1, 'renewable': 1, 'massively': 1, 'human': 1, 'fishermen': 1, 'usage': 1, 'never': 1, 'reduction': 1, 'trivandrum': 1, 'low': 1, 'day': 2, 'changed': 1, 'country': 1, 'attributed': 1, 'industries': 1, 'stop': 1, 'dumping': 3, 'wastage': 2, 'humbly': 1, 'orientation': 1, 'th': 1, 'increasing': 1, 'physical': 1, 'help': 1, 'cardiovascular': 1, 'nspectors': 1, 'pampa': 1, 'scenario': 1, 'please': 2, 'days': 1, 'create': 2, 'farming': 1, 'request': 2, 'heat': 1, 'control': 1, 'proper': 1, 'leach': 1, 'camera': 1, 'sea': 2, 'bonding': 1, 'around': 1, 'twice': 1, 'content': 2, 'policies': 1, 'lives': 1, 'ozone': 2, 'severe': 1, 'electronic': 1, 'remedies': 1}\n",
      "['water', 'wastes', 'waste', 'pollution', 'many', 'trees', 'time', 'people', 'major', 'like', 'health', 'government', 'causes', 'cause', 'also', 'air', 'temperature', 'take', 'rivers', 'public', 'necessary', 'mining', 'make', 'living', 'levels', 'harm', 'dumping', 'due', 'disease', 'activities', 'way', 'wastage', 'use', 'summer', 'steps', 'sources', 'soil', 'sea', 'save', 'road', 'river', 'residential', 'request', 'real', 'quarrying', 'projects', 'problems', 'please', 'places', 'paddy', 'ozone', 'oxygen', 'one', 'oil', 'ocean', 'noise', 'night', 'need', 'light', 'life', 'kerala', 'industrial', 'impact', 'humans', 'holes', 'higher', 'high', 'fields', 'environment', 'dump', 'domestic', 'disposal', 'disinfectants', 'deaths', 'day', 'cut', 'create', 'content', 'construction', 'city', 'causing', 'caused', 'build', 'beings', 'artificial', 'areas', 'acid', 'would', 'witnessing', 'western', 'ways', 'vehicles', 'vehicle', 'variety', 'utilizing', 'useful', 'used', 'usage', 'unprecedental', 'uncontrolled', 'uncleaned', 'twice', 'trivandrum', 'toxics', 'touched', 'today', 'throwing', 'threatening', 'thanks', 'th', 'termed', 'term', 'switching', 'survival', 'survelliance', 'surge', 'supplied', 'streams', 'strangers', 'stop', 'spills', 'space', 'soon', 'smelling', 'skin', 'sides', 'shaped', 'severe', 'several', 'serious', 'season', 'scenario', 'saving', 'sand', 'runoff', 'rising', 'rhythms', 'resulting', 'respiratory', 'residents', 'renewable', 'remedies', 'remain', 'religious', 'regulations', 'reduction', 'reduces', 'recycling', 'reconsidered', 'rate', 'rashes', 'rapidly', 'rampant', 'radiations', 'quarries', 'quality', 'purposes', 'punish', 'properly', 'proper', 'produced', 'problem', 'preserving', 'premises', 'potentially', 'possible', 'ponds', 'polution', 'polluted', 'political', 'policies', 'plastics', 'plastic', 'plants', 'planting', 'physical', 'ph', 'patients', 'parties', 'part', 'pampa', 'overfishing', 'overcome', 'orientation', 'oragansations', 'open', 'old', 'officials', 'obvious', 'number', 'nspectors', 'new', 'never', 'negative', 'nearby', 'much', 'move', 'moderating', 'migration', 'mighty', 'mercury', 'mechanism', 'massively', 'marine', 'made', 'lung', 'low', 'lot', 'long', 'lives', 'livelihood', 'level', 'lead', 'leach', 'landfills', 'lakes', 'kumbhachoodu', 'ksrtc', 'kochi', 'issuesalso', 'issues', 'issue', 'inviting', 'investigate', 'intolerable', 'interrupt', 'intense', 'initiate', 'inform', 'influence', 'industries', 'increasing', 'increased', 'increase', 'impacting', 'illegal', 'humbly', 'human', 'huge', 'households', 'household', 'hotel', 'hormone', 'hide', 'help', 'heavy', 'heavily', 'heat', 'hazards', 'harmful', 'harder', 'hard', 'hand', 'hair', 'grownup', 'great', 'going', 'gods', 'ghats', 'generation', 'fuel', 'foul', 'formed', 'forest', 'food', 'fix', 'fishes', 'fishermen', 'fertile', 'feed', 'farming', 'fall', 'factors', 'factories', 'factor', 'facing', 'facility', 'extremes', 'expectedair', 'excessive', 'example', 'euphoric', 'etc', 'erosion', 'eradicated', 'epa', 'enter', 'energy', 'end', 'emissions', 'electronics', 'electronic', 'efficient', 'effect', 'ecosystem', 'earth', 'ears', 'dying', 'dust', 'dried', 'dont', 'diversity', 'dissolves', 'disrupted', 'disposed', 'dispersal', 'diseases', 'difficulties', 'deterioration', 'deposits', 'depletion', 'deforestation', 'decreases', 'days', 'cvd', 'cutting', 'curb', 'crops', 'creating', 'co₂', 'country', 'control', 'contribute', 'continuity', 'continues', 'contaminated', 'contaminate', 'constructiondevelopment', 'considering', 'consider', 'concern', 'commercial', 'collect', 'climate', 'circadian', 'chlorine', 'chemicals', 'check', 'changes', 'changed', 'change', 'centers', 'catch', 'cardiovascular', 'carbonic', 'cancer', 'camera', 'cadmium', 'bus', 'burning', 'builders', 'breeding', 'bonding', 'bodies', 'biosphere', 'biodiversity', 'big', 'becomes', 'become', 'bad', 'bacteria', 'awareness', 'avoiding', 'authority', 'attributed', 'attempt', 'around', 'area', 'animals', 'amount', 'among', 'alappad', 'agriculture', 'affects', 'affect', 'actions', 'acidification', 'abruptly']\n",
      "\n",
      "\n",
      "KEYWORDS  ENV \n",
      "\n",
      "\n",
      "[['water', 'wastes', 'waste', 'pollution', 'many']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter complaintPoor roads\t\"Sir, Please initiate a surprise visit to Kerala to know the conditions of the roads. Its been  more than 6 months(after rainy season) since the roads has been repaired. Also, if the roads  are broken, instead of chipping the existing roads, they are resurfaced again which increases  the height of the roads. The height of the roads can be increased but can the height of the  houses or office complexes increased? To know more about this, you can take the help of  our media channels like Asianet news, Manorama news, Indiavision etc. Also, here there is a  common trend ie once roads are repaired, they are broken again manually for underlying the  cables underground and left without repairing it. Sir/Madam, per day there are lacs of vehicles  entering the roads from showrooms. How much tax is collected from them? Isn't that  sufficient to repair the roads? If the roads are leveled properly, how much fuel can be  saved? The prices of this fuel can be controlled to a certain extent right? I hope you would  take these factors into consideration.\"\n",
      "poor roads\t sir  please initiate a surprise visit to kerala to know the conditions of the roads  its been  more than 6 months after rainy season  since the roads has been repaired  also  if the roads  are broken  instead of chipping the existing roads  they are resurfaced again which increases  the height of the roads  the height of the roads can be increased but can the height of the  houses or office complexes increased  to know more about this  you can take the help of  our media channels like asianet news  manorama news  indiavision etc  also  here there is a  common trend ie once roads are repaired  they are broken again manually for underlying the  cables underground and left without repairing it  sir madam  per day there are lacs of vehicles  entering the roads from showrooms  how much tax is collected from them  isn t that  sufficient to repair the roads  if the roads are leveled properly  how much fuel can be  saved  the prices of this fuel can be controlled to a certain extent right  i hope you would  take these factors into consideration  \n",
      "['poor', 'roads', 'sir', 'please', 'initiate', 'a', 'surprise', 'visit', 'to', 'kerala', 'to', 'know', 'the', 'conditions', 'of', 'the', 'roads', 'its', 'been', 'more', 'than', '6', 'months', 'after', 'rainy', 'season', 'since', 'the', 'roads', 'has', 'been', 'repaired', 'also', 'if', 'the', 'roads', 'are', 'broken', 'instead', 'of', 'chipping', 'the', 'existing', 'roads', 'they', 'are', 'resurfaced', 'again', 'which', 'increases', 'the', 'height', 'of', 'the', 'roads', 'the', 'height', 'of', 'the', 'roads', 'can', 'be', 'increased', 'but', 'can', 'the', 'height', 'of', 'the', 'houses', 'or', 'office', 'complexes', 'increased', 'to', 'know', 'more', 'about', 'this', 'you', 'can', 'take', 'the', 'help', 'of', 'our', 'media', 'channels', 'like', 'asianet', 'news', 'manorama', 'news', 'indiavision', 'etc', 'also', 'here', 'there', 'is', 'a', 'common', 'trend', 'ie', 'once', 'roads', 'are', 'repaired', 'they', 'are', 'broken', 'again', 'manually', 'for', 'underlying', 'the', 'cables', 'underground', 'and', 'left', 'without', 'repairing', 'it', 'sir', 'madam', 'per', 'day', 'there', 'are', 'lacs', 'of', 'vehicles', 'entering', 'the', 'roads', 'from', 'showrooms', 'how', 'much', 'tax', 'is', 'collected', 'from', 'them', 'isn', 't', 'that', 'sufficient', 'to', 'repair', 'the', 'roads', 'if', 'the', 'roads', 'are', 'leveled', 'properly', 'how', 'much', 'fuel', 'can', 'be', 'saved', 'the', 'prices', 'of', 'this', 'fuel', 'can', 'be', 'controlled', 'to', 'a', 'certain', 'extent', 'right', 'i', 'hope', 'you', 'would', 'take', 'these', 'factors', 'into', 'consideration']\n",
      "['poor', 'roads', 'sir', 'please', 'initiate', 'surprise', 'visit', 'kerala', 'know', 'conditions', 'roads', '6', 'months', 'rainy', 'season', 'since', 'roads', 'repaired', 'also', 'roads', 'broken', 'instead', 'chipping', 'existing', 'roads', 'resurfaced', 'increases', 'height', 'roads', 'height', 'roads', 'increased', 'height', 'houses', 'office', 'complexes', 'increased', 'know', 'take', 'help', 'media', 'channels', 'like', 'asianet', 'news', 'manorama', 'news', 'indiavision', 'etc', 'also', 'common', 'trend', 'ie', 'roads', 'repaired', 'broken', 'manually', 'underlying', 'cables', 'underground', 'left', 'without', 'repairing', 'sir', 'madam', 'per', 'day', 'lacs', 'vehicles', 'entering', 'roads', 'showrooms', 'much', 'tax', 'collected', 'sufficient', 'repair', 'roads', 'roads', 'leveled', 'properly', 'much', 'fuel', 'saved', 'prices', 'fuel', 'controlled', 'certain', 'extent', 'right', 'hope', 'would', 'take', 'factors', 'consideration']\n",
      "{'height': 3, 'asianet': 1, 'instead': 1, 'lacs': 1, 'like': 1, 'manorama': 1, 'roads': 11, 'hope': 1, 'etc': 1, 'right': 1, '6': 1, 'sufficient': 1, 'conditions': 1, 'leveled': 1, 'take': 2, 'existing': 1, 'indiavision': 1, 'increased': 2, 'consideration': 1, 'news': 2, 'without': 1, 'surprise': 1, 'broken': 2, 'rainy': 1, 'properly': 1, 'channels': 1, 'vehicles': 1, 'common': 1, 'would': 1, 'ie': 1, 'season': 1, 'showrooms': 1, 'trend': 1, 'underground': 1, 'resurfaced': 1, 'manually': 1, 'per': 1, 'day': 1, 'media': 1, 'houses': 1, 'certain': 1, 'saved': 1, 'initiate': 1, 'chipping': 1, 'madam': 1, 'know': 2, 'underlying': 1, 'also': 2, 'tax': 1, 'sir': 2, 'since': 1, 'left': 1, 'increases': 1, 'repaired': 2, 'kerala': 1, 'entering': 1, 'prices': 1, 'please': 1, 'repair': 1, 'office': 1, 'visit': 1, 'collected': 1, 'fuel': 2, 'extent': 1, 'controlled': 1, 'much': 2, 'repairing': 1, 'complexes': 1, 'help': 1, 'months': 1, 'cables': 1, 'poor': 1, 'factors': 1}\n",
      "['roads', 'height', 'take', 'sir', 'repaired', 'news', 'much', 'know', 'increased', 'fuel', 'broken', 'also', 'would', 'without', 'visit', 'vehicles', 'underlying', 'underground', 'trend', 'tax', 'surprise', 'sufficient', 'since', 'showrooms', 'season', 'saved', 'right', 'resurfaced', 'repairing', 'repair', 'rainy', 'properly', 'prices', 'poor', 'please', 'per', 'office', 'months', 'media', 'manually', 'manorama', 'madam', 'like', 'leveled', 'left', 'lacs', 'kerala', 'instead', 'initiate', 'indiavision', 'increases', 'ie', 'houses', 'hope', 'help', 'factors', 'extent', 'existing', 'etc', 'entering', 'day', 'controlled', 'consideration', 'conditions', 'complexes', 'common', 'collected', 'chipping', 'channels', 'certain', 'cables', 'asianet', '6']\n",
      "['roads', 'height', 'take', 'sir', 'repaired']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'water_lis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-adcb14c62642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0mdept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepartment_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwater_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpwd_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mksrtc_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkseb_lis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'water_lis' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "from gensim.summarization import keywords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "global dataset\n",
    "\n",
    "\n",
    "class Main:\n",
    "         \n",
    "    global departments\n",
    "    \n",
    "    \n",
    "    def __init__(self,dataset):\n",
    "        #/home/gayathri/project/MakeComplaint/data.csv\n",
    "        self.dataset=dataset\n",
    "        #print(self.dataset)\n",
    "        self.dataset= pd.read_csv(self.dataset)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def department_class(self):\n",
    "        departments=self.dataset['Departments'].unique() \n",
    "        return departments\n",
    "        \n",
    "    \n",
    "    def punctuate(self):\n",
    "        punctuations = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
    "        text=self.dataset['Subject']\n",
    "\n",
    "        # To take input from the user\n",
    "        # my_str = input(\"Enter a string: \")\n",
    "\n",
    "        # remove punctuation from the string\n",
    "        no_punct = \"\"\n",
    "        no_punctuate =[]\n",
    "        for char in  self.dataset['Subject']:\n",
    "\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "                no_punctuate.append(no_punct)\n",
    "\n",
    "        # display the unpunctuated string\n",
    "        #print(no_punctuate)\n",
    "        return(no_punctuate)\n",
    "\n",
    "        \n",
    "    def data_clean(self):\n",
    "        \n",
    "        \n",
    "       \n",
    "        print(self.dataset.head())\n",
    "        # unpunctuate and lower case\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "            # unpunctuate and lower case\n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint'].str.replace(',',' ').str.lower() \n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Complaint'] = self.dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\P{P}-]','').str.lower()\n",
    "        #print( self.dataset.head())\n",
    "\n",
    "\n",
    "\n",
    "        #rRemoving new lines in the subject field\n",
    "        self.dataset['Subject'] =  self.dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "        #removing Numeric \n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint']\n",
    "        print( self.dataset.head())\n",
    "        \n",
    "    def dataframing(self,dataset):\n",
    "        # creating dataframe for each departments\n",
    "        water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "        pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "        ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "        kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "        env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "        print(env.shape)    #(30, 4)\n",
    "        #print(water.shape)  #(39, 4)\n",
    "        #print(pwd.shape)    #(42, 4)\n",
    "        #print(ksrtc.shape)  #(17, 4)\n",
    "        #print(kseb.shape)   #(22, 4)\n",
    "        #dataset.head()\n",
    "        #print(pwd)\n",
    "\n",
    "  \n",
    "\n",
    "        #Filtering out Subjects and complaints from the dataframe\n",
    "        df_water = water[['Subject','Complaint']]\n",
    "        df_pwd   = pwd[['Subject','Complaint']]\n",
    "        df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "        df_kseb  = kseb[['Subject','Complaint']]\n",
    "        df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "        dfwater  = df_water[['Subject','Complaint']]\n",
    "        dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "        dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "        dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "        dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "        \n",
    "        dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "        dfwater=dfwater[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "        dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "        dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "        dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "        dfenv =dfenv [['Subject_and_Complaint']]\n",
    "        print(dfenv )\n",
    "        return (dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "        \n",
    "        \n",
    "    def tokenisation(self,dfwater,dfpwd,dfksrtc,dfkseb,dfenv):\n",
    "        water_token = []\n",
    "        water_list=[]\n",
    "            #Tokenising water data\n",
    "            \n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        #lemmatizer.lemmatize(\"corpora\")\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i, row in dfwater.iterrows():\n",
    "                #print(i,row['Subject'], row['Complaint'])\n",
    "                \n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in water_token if not i in stop_words]\n",
    "            #lemmatized_output = [i for i in lemmatizer.lemmatize(i) for i in result]\n",
    "        \n",
    "            water_list.append(result)\n",
    "        print(\"\\n\\nWater Tokens\\n\\n\")\n",
    "        print(water_list)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "        pwd_token = []\n",
    "\n",
    "        pwd_list = []\n",
    "        #Tokenising pwd data  \n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result1 = [i for i in pwd_token if not i in stop_words]\n",
    "            pwd_list.append(result1)\n",
    "            \n",
    "        print(\"\\n\\nPWD Tokens\\n\\n\")\n",
    "        print(pwd_list)\n",
    "            \n",
    "            #print( pwd_token)\n",
    "\n",
    "\n",
    "        ksrtc_token =[]\n",
    "        ksrtc_list =[]\n",
    "        #Tokenising ksrtc data    \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in ksrtc_token if not i in stop_words]\n",
    "            ksrtc_list.append(result)\n",
    "            #print(ksrtc_list)\n",
    "            #print( ksrtc_token)\n",
    "            \n",
    "            \n",
    "            \n",
    "        kseb_token = []\n",
    "        kseb_list= []\n",
    "        #Tokenising kseb data    \n",
    "        for i, row in dfkseb.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in kseb_token if not i in stop_words]\n",
    "            kseb_list.append(result)\n",
    "        #print(kseb_list)\n",
    "        #print(kseb_token)\n",
    "        \n",
    "        \n",
    "        env_token = []\n",
    "        env_list = []\n",
    "        #Tokenising env data  \n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in env_token if not i in stop_words]\n",
    "            env_list.append(result)\n",
    "        print(env_list)\n",
    "            #print(env_token)\n",
    "        return(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "\n",
    "\n",
    "   \n",
    "    def word_frequency(self,water_list,pwd_list,ksrtc_list,kseb_list,env_list):\n",
    "        \n",
    "        #word frequencies  Environment department\n",
    "\n",
    "        wordfreq = []\n",
    "       \n",
    "    \n",
    "        for word  in env_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        env_count =Counter(wordfreq)\n",
    "        env_count= dict(env_count)\n",
    "        print(\"\\n\\n Env Count \\n\\n\")\n",
    "        print(type(env_count))\n",
    "        \n",
    "    \n",
    "        #word frequencies  KSEB department\n",
    "        wordfreq = []\n",
    "        for word  in kseb_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        kseb_count = Counter(wordfreq)\n",
    "        kseb_count= dict(kseb_count) \n",
    "        print(\"\\n\\n KSEB Count \\n\\n\")\n",
    "        print(kseb_count)\n",
    "    \n",
    "\n",
    "        \n",
    "        #word frequencies  KSRTC department\n",
    "\n",
    "        wordfreq = []\n",
    "        \n",
    "        for word  in ksrtc_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        ksrtc_count =Counter(wordfreq)\n",
    "        ksrtc_count= dict(ksrtc_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(ksrtc_count)\n",
    "    \n",
    "        \n",
    "        #word frequencies  pwd department\n",
    "\n",
    "        for word  in pwd_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        pwd_count =Counter(wordfreq)\n",
    "        pwd_count = dict(pwd_count)\n",
    "        print(\"\\n\\n PWD Count \\n\\n\")\n",
    "        print(type(pwd_count))\n",
    "        \n",
    "        \n",
    "        #word frequencies  water department\n",
    "\n",
    "        wordfreq = []\n",
    "        for word  in water_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        water_count =Counter(wordfreq)\n",
    "        water_count= dict(water_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(type(water_count))\n",
    "        return(water_count,pwd_count,ksrtc_count,kseb_count,env_count)\n",
    "\n",
    "\n",
    "    def most_repeated_keywords(self,water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq ):\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n Water Freq newwwwwwwwww\")\n",
    "        print(water_freq)\n",
    "        \n",
    "        #print sorted(prices.iteritems(), lambda x, y : cmp(x[1], y[1]))\n",
    "\n",
    "        \n",
    "        water_lis =[]\n",
    "        water_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in water_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        water_dict=(items[:5])\n",
    "        water_lis.append(water_dict)\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        print(\"\\n\\nKEYWORDS  WATER\\n\\n\")\n",
    "        print(water_lis)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n PWD Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        pwd_lis =[]\n",
    "        pwd_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in pwd_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        pwd_dict=(items[:5])\n",
    "        pwd_lis.append(pwd_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  PWD\\n\\n\")\n",
    "        print(pwd_lis)\n",
    "        \n",
    "        \n",
    "        # Finding the most repeated words kseb\n",
    "        print(\"\\n\\n KSEB Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        kseb_lis =[]\n",
    "        kseb_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in kseb_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        kseb_dict=(items[:5])\n",
    "        kseb_lis.append(kseb_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSEB\\n\\n\")\n",
    "        print(kseb_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words ksrtc\n",
    "\n",
    "        print(\"\\n\\n KSRTC Freq newwwwwwwwww\")\n",
    "        print(ksrtc_freq)\n",
    "        \n",
    "        \n",
    "        ksrtc_lis =[]\n",
    "        ksrtc_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in ksrtc_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        ksrtc_dict=(items[:5])\n",
    "        ksrtc_lis.append(ksrtc_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSRTC\\n\\n\")\n",
    "        print(ksrtc_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words env\n",
    "        print(\"\\n\\n ENV Freq newwwwwwwwww\")\n",
    "        print(env_freq)\n",
    "        \n",
    "        \n",
    "        env_lis =[]\n",
    "        env_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in env_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        env_dict=(items[:5])\n",
    "        env_lis.append(env_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  ENV \\n\\n\")\n",
    "        print(env_lis)\n",
    "       \n",
    "        \n",
    "        \n",
    "        return(water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis )\n",
    "                \n",
    "        \n",
    "    def most_repeated_keyword_lib(self,dfenv,dfwater,dfpwd,dfksrtc,dfkseb):\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        env_keyword = []\n",
    "        env_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : ENV\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in env_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            env_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            env_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(env_summary)\n",
    "        \n",
    "        # water Keyword\n",
    "        \n",
    "        water_keyword = []\n",
    "        water_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : Water\\n\\n\")\n",
    "        \n",
    "        \n",
    "        for i, row in dfwater.iterrows():\n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in water_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            water_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            water_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(water_summary)\n",
    "        \n",
    "        \n",
    "        #pwd keyword\n",
    "        \n",
    "        pwd_keyword = []\n",
    "        pwd_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : PWD\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in pwd_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            pwd_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            pwd_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(pwd_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        ksrtc_keyword = []\n",
    "        ksrtc_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSRTC\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in ksrtc_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            ksrtc_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            ksrtc_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(ksrtc_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        kseb_keyword = []\n",
    "        kseb_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSEB\\n\\n\")\n",
    "        #print(dfkseb)\n",
    "        \n",
    "        for i, row in dfkseb.iterrows():\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in kseb_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            kseb_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            kseb_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(kseb_summary)\n",
    "        return(env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def jump(self,status):\n",
    "        if status == 1:\n",
    "            env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary=self.most_repeated_keyword_lib(dfenv,dfwater,dfpwd,dfksrtc,dfkseb)\n",
    "        else:\n",
    "            print('hai')\n",
    "            print(water_freq)\n",
    "            water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis = self.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq )\n",
    "        return(water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis)\n",
    "            \n",
    "    def test(self):\n",
    "        text_data = input(\"Enter complaint\")\n",
    "        text_data= text_data.replace('[^\\w\\s]','').lower()\n",
    "        \n",
    "        \n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "        for x in text_data.lower(): \n",
    "            if x in punctuations: \n",
    "                text_data = text_data.replace(x, \" \") \n",
    "  \n",
    "   \n",
    "        print(text_data) \n",
    "        \n",
    "            \n",
    "        test_token = word_tokenize(text_data)\n",
    "        print(test_token)\n",
    "        test_list =[]\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i in test_token:\n",
    "            \n",
    "            \n",
    "            if i not in stop_words:\n",
    "        \n",
    "                test_list.append(i)\n",
    "        print(test_list)\n",
    "        \n",
    "        #frequency : \n",
    "        \n",
    "\n",
    "        \n",
    "        counts = Counter(test_list)\n",
    "        count = dict(counts)\n",
    "        print(count)  # word frequency\n",
    "    \n",
    "        items = [(v, k) for k, v in counts.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)  # sorted high to low\n",
    "        test_dict=(items[0:5])\n",
    "        print(test_dict)  #key only\n",
    "        \n",
    "        return(test_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept):\n",
    "        #keyword matching \n",
    "        #water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis\n",
    "        print(\"\\n\\nTest Keywords \\n \\n\")\n",
    "        print(keywords)\n",
    "        \n",
    "        #pwd predictpwd_predict = sorted(list3,key = lambda k: )\n",
    "        i=0\n",
    "        print(type(pwd_lis))\n",
    "        \n",
    "        for i in pwd_lis:\n",
    "            if pwd_lis[i] in keywords[i]:\n",
    "                pwd_predict.append(pwd_lis[i])\n",
    "                    \n",
    "              \n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n PWD predict \\n\\n\")    \n",
    "        print(pwd_predict)\n",
    "        \n",
    "        #water predict\n",
    "        \n",
    "        \n",
    "        water_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in water_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                water_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n Water predict \\n\\n\")    \n",
    "        print(water_predict)\n",
    "        \n",
    "         #ksrtc predict\n",
    "        \n",
    "        \n",
    "        ksrtc_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in ksrtc_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                ksrtc_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n ksrtc predict \\n\\n\")    \n",
    "        print(ksrtc_predict)\n",
    "        \n",
    "        #kseb predict\n",
    "        \n",
    "        kseb_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in kseb_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                kseb_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n kseb predict \\n\\n\")    \n",
    "        print(kseb_predict)\n",
    "        \n",
    "        \n",
    "        #env predict\n",
    "        \n",
    "        env_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in env_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                env_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\nenv predict \\n\\n\")    \n",
    "        print(env_predict)\n",
    "        \n",
    "        department=dept\n",
    "        dept_values =[1,2,3,4,5]\n",
    "        depart_dict = dict(zip(dept_values,department))\n",
    "        print(depart_dict)\n",
    "        \n",
    "        if len(env_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[5])\n",
    "            \n",
    "        if len(pwd_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[2])\n",
    "            \n",
    "        if len(water_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[1])\n",
    "            \n",
    "        if len(kseb_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[3])\n",
    "            \n",
    "        if len(ksrtc_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[4])\n",
    "            \n",
    "            \n",
    "        \n",
    "                  \n",
    "        \n",
    "        \n",
    "file =   '/home/gayathri/project/MakeComplaint/data.csv'   \n",
    "\n",
    "x= Main(file)\n",
    "x.punctuate()\n",
    "x.data_clean()\n",
    "dfwater,dfpwd,dfksrtc,dfkseb,dfenv=x.dataframing(x.dataset)\n",
    "\n",
    "water_list,pwd_list,ksrtc_list,kseb_list,env_list = x.tokenisation(dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "\n",
    "water_count,pwd_count,ksrtc_count,kseb_count,env_count = x.word_frequency(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "x.most_repeated_keywords(water_count,pwd_count,ksrtc_count,kseb_count,env_count)\n",
    "#x.most_repeated_keyword_lib(dfenv) \n",
    "\n",
    "#water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis=x.jump(0)\n",
    "\n",
    "keywords=x.test()\n",
    "dept=x.department_class()\n",
    "x.evaluate(keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [2]:\n",
    "#using NLTK library, we can do lot of text preprocesing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#function to split text into word\n",
    "\n",
    "tokens = word_tokenize(\"The quick brown fox jumps over the lazy dog\")\n",
    "In [ ]:\n",
    "import nltk\n",
    "nltk.download()\n",
    "In [3]:\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "data = \"All work and no play makes jack a dull boy, all work and no play\"\n",
    "print(word_tokenize(data))\n",
    "['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', ',', 'all', 'work', 'and', 'no', 'play']\n",
    "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
    "[nltk_data]   Package punkt is already up-to-date!\n",
    "In [ ]:\n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english')) \n",
    "print(stopWords)\n",
    "phrases = sent_tokenize(data)\n",
    "words = word_tokenize(data)\n",
    " \n",
    "print(phrases)\n",
    "print(words)\n",
    "wordsFiltered = []\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "print(wordsFiltered)\n",
    "In [ ]:\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english'))\n",
    "In [ ]:\n",
    "#stopword removal\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "stopWords = set(stopwords.words('english')) \n",
    "print(stopWords)\n",
    "words = word_tokenize(data)\n",
    "wordsFiltered = []\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        wordsFiltered.append(w)\n",
    "print(wordsFiltered)\n",
    "print(len(stopWords))\n",
    "In [ ]:\n",
    "#stemming\n",
    "#3 stemmer alogirthms are used here\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "# went is not working\n",
    "words = [\"go\",\"went\",\"gone\",\"games\"]\n",
    "ps = PorterStemmer()\n",
    "lanca_stemmer = LancasterStemmer()\n",
    "sb_stemmer = SnowballStemmer(\"english\",)\n",
    "print(\"=========Porter Stemmer======\")\n",
    "for w in words:\n",
    "    print(w ,\" : \" ,ps.stem(w))\n",
    "    \n",
    "print(\"=========Lanca Stemmer======\")\n",
    "for w in words:\n",
    "\n",
    "    print(w ,\" : \" ,lanca_stemmer.stem(w))\n",
    "    \n",
    "print(\"=========Snowball Stemmer======\")\n",
    "for w in words:\n",
    "    \n",
    "    print(w ,\" : \" ,sb_stemmer.stem(w))\n",
    "    \n",
    "    \n",
    " #Porter stemmer and Snowball stemmer working in similar manner   \n",
    "#lanca is not so good\n",
    "In [ ]:\n",
    "#speech tagging\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "document = 'Whether you\\'re new to programming or an experienced developer, it\\'s easy to learn and use Python.'\n",
    "sentences = nltk.sent_tokenize(document) \n",
    "for sent in sentences:\n",
    "    print(nltk.pos_tag(nltk.word_tokenize(sent)))\n",
    "In [ ]:\n",
    "#filtering from Speech tagging\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "document = 'Today the Netherlands celebrates King\\'s Day. To honor this tradition, the Dutch embassy in San Francisco invited me to'\n",
    "sentences = nltk.sent_tokenize(document)  \n",
    "data = []\n",
    "for sent in sentences:\n",
    "    data = data + nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "for w in data:\n",
    "    if 'VB' in w[1]:\n",
    "        print(w)\n",
    "In [ ]:\n",
    "#natural language prediction\n",
    "import nltk\n",
    "\n",
    " \n",
    "from nltk.corpus import names\n",
    "\n",
    "def gender_features(word): \n",
    "    return {'last_letter': word[-1]}\n",
    "\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
    "train_set = featuresets\n",
    "classifier = nltk.MaxentClassifier.train(train_set) \n",
    "print(classifier.classify(gender_features('Frank')))\n",
    "name = input(\"Name: \")\n",
    "print(classifier.classify(gender_features(name)))\n",
    "In [ ]:\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import names\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    " \n",
    "positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]\n",
    "negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(' ]\n",
    "neutral_vocab = [ 'movie','the','sound','was','is','actors','did','know','words','not' ]\n",
    " \n",
    "positive_features = [(word_feats(pos), 'pos') for pos in positive_vocab]\n",
    "negative_features = [(word_feats(neg), 'neg') for neg in negative_vocab]\n",
    "neutral_features = [(word_feats(neu), 'neu') for neu in neutral_vocab]\n",
    " \n",
    "train_set = negative_features + positive_features + neutral_features\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set) \n",
    " \n",
    "# Predict\n",
    "neg = 0\n",
    "pos = 0\n",
    "sentence = \"Awesome movie, I liked it\"\n",
    "sentence = sentence.lower()\n",
    "words = sentence.split(' ')\n",
    "for word in words:\n",
    "    classResult = classifier.classify( word_feats(word))\n",
    "    if classResult == 'neg':\n",
    "        neg = neg + 1\n",
    "    if classResult == 'pos':\n",
    "        pos = pos + 1\n",
    " \n",
    "print('Positive: ' + str(float(pos)/len(words)))\n",
    "print('Negative: ' + str(float(neg)/len(words)))\n",
    "In [2]:\n",
    "import nltk\n",
    "\n",
    "#Tokenize using TreeBank Tokenizer\n",
    "\n",
    "text=\"This is Gayathri's book isn't it?\"\n",
    "\n",
    "tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "tokenizer1=nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "tokens=tokenizer.tokenize(text)\n",
    "tokens1=tokenizer1.tokenize(text) #wordPunct\n",
    "\n",
    "print(\"Tree\", tokens)\n",
    "print(\"WordPunct\" ,tokens1)\n",
    "\n",
    "#stemmer\n",
    "stemmer=nltk.stem.PorterStemmer()\n",
    "print(\"porter stemmer\")\n",
    "\" \".join(stemmer.stem(token)for token in tokens)\n",
    "Tree ['This', 'is', 'Gayathri', \"'s\", 'book', 'is', \"n't\", 'it', '?']\n",
    "WordPunct ['This', 'is', 'Gayathri', \"'\", 's', 'book', 'isn', \"'\", 't', 'it', '?']\n",
    "porter stemmer\n",
    "Lemmatizer\n",
    "In [5]:\n",
    "import nltk\n",
    "\n",
    "#Tokenzie using TreeBank Tokenizer\n",
    "\n",
    "text=\"This is Gayathri's book isn't it?\"\n",
    "\n",
    "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\" \".join(lemmatizer.lemmatize(token)for token in tokens)\n",
    "Out[5]:\n",
    "'The quick brown fox jump over the lazy dog'\n",
    "In [2]:\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "sentence= []\n",
    "def stopword_remove(tokens):\n",
    "      \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    print(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\n",
    "                     \n",
    "    \n",
    "    \n",
    "    \n",
    "example_sent = \"This is a sample sentence, showing off is was kay the stop words filtration.\"\n",
    "\n",
    "tokens = word_tokenize(example_sent)\n",
    "#print(type(tokens))\n",
    "stopword_remove(tokens)\n",
    "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'is', 'was', 'kay', 'the', 'stop', 'words', 'filtration', '.']\n",
    "Out[2]:\n",
    "['This',\n",
    " 'sample',\n",
    " 'sentence',\n",
    " ',',\n",
    " 'showing',\n",
    " 'kay',\n",
    " 'stop',\n",
    " 'words',\n",
    " 'filtration',\n",
    " '.']\n",
    "In [3]:\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "sentence= []\n",
    "def stopword_remove(tokens):\n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = list(stop_words)\n",
    "    print(stop_words)\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\n",
    "                     \n",
    "    \n",
    "    \n",
    "    \n",
    "example_sent = \"This is a sample sentence, showing off is was kay the stop words filtration.\"\n",
    "tokens = word_tokenize(example_sent)\n",
    "print(type(tokens))\n",
    "stopword_remove(tokens)\n",
    "<class 'list'>\n",
    "['a', 't', 'hers', 'do', 'above', 'any', 're', 'up', 'other', 'about', 'doing', 'further', 'then', 'if', 'when', 'myself', \"should've\", 'our', 'we', 'off', 'between', \"wouldn't\", 'because', 'don', 'my', 'being', 'himself', 'down', 'of', 'and', 'for', \"hasn't\", \"you'll\", 'against', 'each', 'them', 'their', 'ma', 'only', 'over', \"you're\", \"shan't\", 'y', 'are', 'o', 'very', 'all', 'your', 'wouldn', 'he', 'below', 'more', 'nor', 'mightn', 'by', 'once', 'while', 'wasn', 'as', \"weren't\", 'yourself', 'who', 'which', 'ourselves', 'ours', 'itself', 'yours', 'herself', 'no', \"won't\", 'haven', 'both', 'not', 'or', 'has', 'what', 'have', 'so', \"needn't\", 'm', 'didn', 'mustn', 'this', 'themselves', 'under', 'you', \"mustn't\", 'be', \"shouldn't\", \"didn't\", \"haven't\", 'same', 'doesn', 'am', 'with', \"wasn't\", 'until', 'she', 'had', 'him', 'it', 'that', 'into', 'shan', 'to', 'just', 'an', 'before', \"she's\", 'such', 'yourselves', 'theirs', 's', 'now', 'but', 'those', \"hadn't\", \"it's\", 'from', 'on', \"couldn't\", 'hadn', \"that'll\", \"don't\", 'is', 'the', 'having', 'out', 'd', 'during', 'at', 'won', 'was', 'here', 'were', 'me', \"isn't\", 'i', 'they', \"aren't\", 'his', 'too', 'there', \"you'd\", 'isn', 'been', \"you've\", 've', 'shouldn', 'again', 'most', 'did', 'should', 'its', 'how', \"doesn't\", 'whom', 'after', 'needn', 'weren', 'in', 'these', 'aren', 'does', 'ain', 'will', 'couldn', 'through', 'why', 'own', 'few', 'hasn', 'can', 'than', 'some', 'll', 'where', 'her', \"mightn't\"]\n",
    "Out[3]:\n",
    "['This',\n",
    " 'sample',\n",
    " 'sentence',\n",
    " ',',\n",
    " 'showing',\n",
    " 'kay',\n",
    " 'stop',\n",
    " 'words',\n",
    " 'filtration',\n",
    " '.']\n",
    "In [11]:\n",
    "import nltk\n",
    "input_str = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(input_str)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "print (result)\n",
    "['NLTK', 'leading', 'platform', 'building', 'Python', 'programs', 'work', 'human', 'language', 'data', '.']\n",
    "In [17]:\n",
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:10])\n",
    "doc = spacy_nlp('NLTK is a leading platform for building Python programs to work with human language data.')\n",
    "tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "print()\n",
    "print(tokens)\n",
    "Number of stop words: 305\n",
    "First ten stop words: ['everywhere', 'a', 'noone', 'hers', 'do', 'onto', 'another', 'above', 'any', 'somewhere']\n",
    "\n",
    "['NLTK', 'leading', 'platform', 'building', 'Python', 'programs', 'work', 'human', 'language', 'data', '.']\n",
    "In [30]:\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "#Data cleaning\n",
    "\n",
    "# 1. unpunctuate \n",
    "# 2. to lower\n",
    "# 3. Remove numerals\n",
    "# 4. Remove Newline for subject\n",
    "\n",
    "\n",
    "# Data loading\n",
    "dataset= pd.read_csv('/home/user/Complaint/MakeComplaint/data.csv')\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Subject'] = dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "# unpunctuate and lower case\n",
    "dataset['Complaint'] = dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower() \n",
    "\n",
    "\n",
    "#rRemoving new lines in the subject field\n",
    "dataset['Subject'] = dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "#removing Numeric \n",
    "dataset['Complaint'] = dataset['Complaint']\n",
    "\n",
    "\n",
    "# creating dataframe for each departments\n",
    "water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "\n",
    "#print(env.shape)    #(29, 4)\n",
    "#print(water.shape)  #(17, 4)\n",
    "#print(pwd.shape)    #(39, 4)\n",
    "#print(ksrtc.shape)  #(13, 4)\n",
    "#print(kseb.shape)   #(22, 4)\n",
    "#dataset.head()\n",
    "#print(pwd)\n",
    "\n",
    "#Filtering out Subjects and complaints from the dataframe\n",
    "df_water = water[['Subject','Complaint']]\n",
    "df_pwd   = pwd[['Subject','Complaint']]\n",
    "df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "df_kseb  = kseb[['Subject','Complaint']]\n",
    "df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "dfwater  = df_water[['Subject','Complaint']]\n",
    "dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = Water\n",
    "dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "dfwater=dfwater[['Subject_and_Complaint']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = PWD\n",
    "dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "#print(dfpwd)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = ksrtc\n",
    "dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "#print(dfksrtc)\n",
    "\n",
    "#Dataframe with complaint and subject as one column = kseb\n",
    "dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "#print(dfkseb)\n",
    "\n",
    "\n",
    "#Dataframe with complaint and subject as one column = env\n",
    "dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "dfenv =dfenv [['Subject_and_Complaint']]\n",
    "#print(dfenv )\n",
    "\n",
    "#==================================Tokenization Begins : =============================================\n",
    "\n",
    "\n",
    "print(type(doc ))\n",
    "#print(tokens)\n",
    "\n",
    "sentence= []\n",
    "\"\"\"def stopword_remove(tokens):\n",
    "  \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words = list(stop_words)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            sentence.append(token)\n",
    "    return sentence\"\"\"\n",
    "    \n",
    "                     \n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "water_token = []\n",
    "#Tokenising water data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i, row in dfwater.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    #tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "    tokens = [token.text for water_token in doc if not token.is_stop]\n",
    "    #result = [i for i in water_token if not i in stop_words]\n",
    "    print(result)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "\n",
    "  \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(type(tokens))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "pwd_token = []\n",
    "#Tokenising pwd data    \n",
    "for i, row in dfpwd.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    pwd_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( pwd_token)\n",
    "\n",
    "ksrtc_token =[]\n",
    "#Tokenising ksrtc data    \n",
    "for i, row in dfksrtc.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    ksrtc_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print( ksrtc_token)\n",
    "\n",
    "kseb_token = []\n",
    "#Tokenising kseb data    \n",
    "for i, row in dfkseb.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    kseb_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(kseb_token)\n",
    "\n",
    "env_token = []\n",
    "#Tokenising env data    \n",
    "for i, row in dfenv.iterrows():\n",
    "    #print(i,row['Subject'], row['Complaint'])\n",
    "    tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    env_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "#print(env_token)\n",
    "<class 'spacy.tokens.doc.Doc'>\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "<ipython-input-30-ea404cf1237f> in <module>\n",
    "    122     #tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    123     water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "--> 124     tokens = [token.text for water_token in doc if not token.is_stop]\n",
    "    125     #result = [i for i in water_token if not i in stop_words]\n",
    "    126     print(result)\n",
    "\n",
    "<ipython-input-30-ea404cf1237f> in <listcomp>(.0)\n",
    "    122     #tokenizer=nltk.tokenize.TreebankWordTokenizer()\n",
    "    123     water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "--> 124     tokens = [token.text for water_token in doc if not token.is_stop]\n",
    "    125     #result = [i for i in water_token if not i in stop_words]\n",
    "    126     print(result)\n",
    "\n",
    "NameError: name 'token' is not defined\n",
    "In [29]:\n",
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "text = \"There is a road going towards Trivandrum Technopark Phase 3 and it has a gate towards the \"+ \\\n",
    "\"Technopark buildings from this road. It is starting from Nippol Toyota and going towards \"+\\\n",
    "\"Kallingal . The road name is Kallingal - Attinkuzhy Road. This Road is damaged for last 1.5 \"+\\\n",
    "\"years and no one is caring about this. there are minimum 300 vehicles daily goes through it in \"+\\\n",
    "\"the morning and evening towards offices. Now it is like 1 meter gutter in the middle of the road \"+\\\n",
    " \"making health issues to the people. It is in very danger situation. URGENT action required.\"\n",
    "print(\"================================Original==================================================================\")\n",
    "print(text)\n",
    "\n",
    "text = text.strip().lower()\n",
    "\n",
    "#text=text.re.sub('[^a-zA-Z ]',\"\")\n",
    "\n",
    "#text = nltk.sent_tokenize(text)\n",
    "output = re.sub(r'\\d+', '', text)\n",
    "print(\"===================================Processed================================================================\")\n",
    "print(output)\n",
    "\n",
    "print(\"=========================================Summary==========================================================\")\n",
    "print(summarize(output, ratio = 0.5))\n",
    "print(\"==================================Keywords=================================================================\")\n",
    "\n",
    "print(keywords(output))\n",
    "================================Original==================================================================\n",
    "There is a road going towards Trivandrum Technopark Phase 3 and it has a gate towards the Technopark buildings from this road. It is starting from Nippol Toyota and going towards Kallingal . The road name is Kallingal - Attinkuzhy Road. This Road is damaged for last 1.5 years and no one is caring about this. there are minimum 300 vehicles daily goes through it in the morning and evening towards offices. Now it is like 1 meter gutter in the middle of the road making health issues to the people. It is in very danger situation. URGENT action required.\n",
    "===================================Processed================================================================\n",
    "there is a road going towards trivandrum technopark phase  and it has a gate towards the technopark buildings from this road. it is starting from nippol toyota and going towards kallingal . the road name is kallingal - attinkuzhy road. this road is damaged for last . years and no one is caring about this. there are minimum  vehicles daily goes through it in the morning and evening towards offices. now it is like  meter gutter in the middle of the road making health issues to the people. it is in very danger situation. urgent action required.\n",
    "=========================================Summary==========================================================\n",
    "it is starting from nippol toyota and going towards kallingal .\n",
    "the road name is kallingal - attinkuzhy road.\n",
    "this road is damaged for last .\n",
    "now it is like  meter gutter in the middle of the road making health issues to the people.\n",
    "==================================Keywords=================================================================\n",
    "technopark\n",
    "road\n",
    "meter\n",
    "vehicles daily\n",
    "In [48]:\n",
    "#method 2 summarisation\n",
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "article_text = \"There is a road going towards Trivandrum Technopark Phase 3 and it has a gate towards the \"+ \\\n",
    "\"Technopark buildings from this road. It is starting from Nippol Toyota and going towards \"+\\\n",
    "\"Kallingal . The road name is Kallingal - Attinkuzhy Road. This Road is damaged for last 1.5 \"+\\\n",
    "\"years and no one is caring about this. there are minimum 300 vehicles daily goes through it in \"+\\\n",
    "\"the morning and evening towards offices. Now it is like 1 meter gutter in the middle of the road \"+\\\n",
    " \"making health issues to the people. It is in very danger situation. URGENT action required.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)  \n",
    "article_text = re.sub(r'\\s+', ' ', article_text)  \n",
    "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )  \n",
    "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)  \n",
    "sentence_list = nltk.sent_tokenize(article_text)  \n",
    "word_frequencies = []\n",
    "tokenize = nltk.word_tokenize(formatted_article_text)\n",
    "\n",
    "tok =[]\n",
    "for word in tokenize:\n",
    "    result = [i for i in tokenize if not i in stop_words]\n",
    "print(result) \n",
    "\n",
    "word_frequencies = {}  \n",
    "for word in  tokenize:\n",
    "     if word not in stop_words:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "                \n",
    "maximum_frequncy = max(word_frequencies.values()) \n",
    "print(maximum_frequncy)\n",
    "for word in word_frequencies.keys(): \n",
    "     word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "        \n",
    "sentence_scores = {} \n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):if word in word_frequencies.keys():\n",
    "            \n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "['There', 'road', 'going', 'towards', 'Trivandrum', 'Technopark', 'Phase', 'gate', 'towards', 'Technopark', 'buildings', 'road', 'It', 'starting', 'Nippol', 'Toyota', 'going', 'towards', 'Kallingal', 'The', 'road', 'name', 'Kallingal', 'Attinkuzhy', 'Road', 'This', 'Road', 'damaged', 'last', 'years', 'one', 'caring', 'minimum', 'vehicles', 'daily', 'goes', 'morning', 'evening', 'towards', 'offices', 'Now', 'like', 'meter', 'gutter', 'middle', 'road', 'making', 'health', 'issues', 'people', 'It', 'danger', 'situation', 'URGENT', 'action', 'required']\n",
    "4\n",
    "In [ ]:\n",
    "hellomzcsdn,,m\n",
    "df\n",
    "v\n",
    "fd\n",
    "vjjd\n",
    "ds\n",
    "fsnhs\n",
    "In [1]:\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "documents = [\"The Saudis are preparing a report that will acknowledge that\", \n",
    "             \"Saudi journalist Jamal Khashoggi's death was the result of an\", \n",
    "             \"interrogation that went wrong, one that was intended to lead\", \n",
    "             \"to his abduction from Turkey, according to two sources.\"]\n",
    "\n",
    "documents_2 = [\"One source says the report will likely conclude that\", \n",
    "                \"the operation was carried out without clearance and\", \n",
    "                \"transparency and that those involved will be held\", \n",
    "                \"responsible. One of the sources acknowledged that the\", \n",
    "                \"report is still being prepared and cautioned that\", \n",
    "                \"things could change.\"]\n",
    "\n",
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in documents]\n",
    "\n",
    "print(texts)\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "print(dictionary)\n",
    "\n",
    "# Show the word to id map\n",
    "print(dictionary.token2id)\n",
    "\n",
    "# adding new doc to dictionary\n",
    "documents_2 = [\"The intersection graph of paths in trees\",\n",
    "               \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "               \"Graph minors A survey\"]\n",
    "\n",
    "texts_2 = [[text for text in doc.split()] for doc in documents_2]\n",
    "\n",
    "dictionary.add_documents(texts_2)\n",
    "\n",
    "\n",
    "print(dictionary)\n",
    "\n",
    "\n",
    "print(dictionary.token2id)\n",
    "[['The', 'Saudis', 'are', 'preparing', 'a', 'report', 'that', 'will', 'acknowledge', 'that'], ['Saudi', 'journalist', 'Jamal', \"Khashoggi's\", 'death', 'was', 'the', 'result', 'of', 'an'], ['interrogation', 'that', 'went', 'wrong,', 'one', 'that', 'was', 'intended', 'to', 'lead'], ['to', 'his', 'abduction', 'from', 'Turkey,', 'according', 'to', 'two', 'sources.']]\n",
    "Dictionary(33 unique tokens: ['Turkey,', 'his', 'that', 'interrogation', 'death']...)\n",
    "{'Turkey,': 26, 'his': 30, 'that': 7, 'interrogation': 20, 'death': 13, 'lead': 21, 'an': 12, 'of': 15, 'to': 23, 'abduction': 27, \"Khashoggi's\": 10, 'according': 28, 'one': 22, 'wrong,': 25, 'went': 24, 'sources.': 31, 'preparing': 5, 'journalist': 14, 'The': 1, 'a': 2, 'acknowledge': 3, 'two': 32, 'the': 17, 'from': 29, 'report': 6, 'Saudi': 11, 'Jamal': 9, 'intended': 19, 'will': 8, 'result': 16, 'was': 18, 'are': 4, 'Saudis': 0}\n",
    "Dictionary(48 unique tokens: ['his', 'that', 'paths', 'interrogation', 'acknowledge']...)\n",
    "{'his': 30, 'that': 7, 'paths': 36, 'interrogation': 20, 'acknowledge': 3, 'death': 13, 'to': 23, 'intended': 19, 'and': 41, 'A': 46, 'Saudi': 11, 'well': 45, 'in': 34, 'abduction': 27, 'IV': 39, 'according': 28, 'two': 32, 'report': 6, 'ordering': 43, 'result': 16, 'intersection': 35, 'are': 4, 'lead': 21, 'Turkey,': 26, 'of': 15, 'an': 12, 'trees': 37, \"Khashoggi's\": 10, 'survey': 47, 'minors': 42, 'one': 22, 'sources.': 31, 'journalist': 14, 'The': 1, 'a': 2, 'graph': 33, 'the': 17, 'from': 29, 'wrong,': 25, 'preparing': 5, 'Widths': 40, 'Graph': 38, 'went': 24, 'will': 8, 'Jamal': 9, 'quasi': 44, 'was': 18, 'Saudis': 0}\n",
    "In [1]:\n",
    "from collections import Counter\n",
    "list1=['apple','egg','apple','banana','egg','apple']\n",
    "counts = Counter(list1)\n",
    "print(counts)\n",
    "Counter({'apple': 3, 'egg': 2, 'banana': 1})\n",
    "In [32]:\n",
    "list1 = [['a','b','c'],['a','a','b']]\n",
    "wordfreq = []\n",
    "inner_list=[]\n",
    "for i in len(list1):\n",
    "    for j in len(:\n",
    "        inner_list.append(i.count(j))\n",
    "    wordfreq.append(inner_list)\n",
    "print(wordfreq)\n",
    "  File \"<ipython-input-32-440e5399e1f1>\", line 5\n",
    "    for j in len(:\n",
    "                 ^\n",
    "SyntaxError: invalid syntax\n",
    "In [34]:\n",
    "groups = [['Group1', 'A', 'B'], ['Group2', 'C', 'D']]\n",
    "\n",
    "result = {}\n",
    "for group in groups:\n",
    "    for item in group[1:]:\n",
    "        result[item] = group[0]\n",
    "print (result)\n",
    "{'C': 'Group2', 'A': 'Group1', 'D': 'Group2', 'B': 'Group1'}\n",
    "In [6]:\n",
    "a1 = {'a':1, 'b':13, 'd':4, 'c':2, 'e':30}\n",
    "a1_sorted_keys = sorted(a1, key=a1.get, reverse=True)\n",
    "for r in a1_sorted_keys:\n",
    "    print(r, a1[r])\n",
    "a1.update({'f':4})\n",
    "print(a1)\n",
    "e 30\n",
    "b 13\n",
    "d 4\n",
    "c 2\n",
    "a 1\n",
    "{'f': 4, 'd': 4, 'a': 1, 'c': 2, 'b': 13, 'e': 30}\n",
    "In [8]:\n",
    "d = {'a':2, 'b':23, 'c':5, 'd':17, 'e':1}\n",
    "items = [(v, k) for k, v in d.items()]\n",
    "items.sort()\n",
    "items.reverse()\n",
    "items = [(k, v) for v, k in items]\n",
    "print(items)\n",
    "[('b', 23), ('d', 17), ('c', 5), ('a', 2), ('e', 1)]\n",
    "In [ ]:\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "from gensim.summarization import keywords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "global dataset\n",
    "\n",
    "\n",
    "class Main:\n",
    "         \n",
    "    global departments\n",
    "    \n",
    "    \n",
    "    def __init__(self,dataset):\n",
    "        #/home/gayathri/project/MakeComplaint/data.csv\n",
    "        self.dataset=dataset\n",
    "        #print(self.dataset)\n",
    "        self.dataset= pd.read_csv(self.dataset)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def department_class(self):\n",
    "        departments=self.dataset['Departments'].unique() \n",
    "        return departments\n",
    "        \n",
    "    \n",
    "    def punctuate(self):\n",
    "        punctuations = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
    "        text=self.dataset['Subject']\n",
    "\n",
    "        # To take input from the user\n",
    "        # my_str = input(\"Enter a string: \")\n",
    "\n",
    "        # remove punctuation from the string\n",
    "        no_punct = \"\"\n",
    "        no_punctuate =[]\n",
    "        for char in  self.dataset['Subject']:\n",
    "\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "                no_punctuate.append(no_punct)\n",
    "\n",
    "        # display the unpunctuated string\n",
    "        #print(no_punctuate)\n",
    "        return(no_punctuate)\n",
    "\n",
    "        \n",
    "    def data_clean(self):\n",
    "        \n",
    "        \n",
    "       \n",
    "        print(self.dataset.head())\n",
    "        # unpunctuate and lower case\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "            # unpunctuate and lower case\n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint'].str.replace(',',' ').str.lower() \n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Complaint'] = self.dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\P{P}-]','').str.lower()\n",
    "        #print( self.dataset.head())\n",
    "\n",
    "\n",
    "\n",
    "        #rRemoving new lines in the subject field\n",
    "        self.dataset['Subject'] =  self.dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "        #removing Numeric \n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint']\n",
    "        print( self.dataset.head())\n",
    "        \n",
    "    def dataframing(self,dataset):\n",
    "        # creating dataframe for each departments\n",
    "        water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "        pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "        ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "        kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "        env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "        print(env.shape)    #(30, 4)\n",
    "        #print(water.shape)  #(39, 4)\n",
    "        #print(pwd.shape)    #(42, 4)\n",
    "        #print(ksrtc.shape)  #(17, 4)\n",
    "        #print(kseb.shape)   #(22, 4)\n",
    "        #dataset.head()\n",
    "        #print(pwd)\n",
    "\n",
    "  \n",
    "\n",
    "        #Filtering out Subjects and complaints from the dataframe\n",
    "        df_water = water[['Subject','Complaint']]\n",
    "        df_pwd   = pwd[['Subject','Complaint']]\n",
    "        df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "        df_kseb  = kseb[['Subject','Complaint']]\n",
    "        df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "        dfwater  = df_water[['Subject','Complaint']]\n",
    "        dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "        dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "        dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "        dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "        \n",
    "        dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "        dfwater=dfwater[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "        dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "        dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "        dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "        dfenv =dfenv [['Subject_and_Complaint']]\n",
    "        print(dfenv )\n",
    "        return (dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "        \n",
    "        \n",
    "    def tokenisation(self,dfwater,dfpwd,dfksrtc,dfkseb,dfenv):\n",
    "        water_token = []\n",
    "        water_list=[]\n",
    "            #Tokenising water data\n",
    "            \n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        #lemmatizer.lemmatize(\"corpora\")\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i, row in dfwater.iterrows():\n",
    "                #print(i,row['Subject'], row['Complaint'])\n",
    "                \n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in water_token if not i in stop_words]\n",
    "            #lemmatized_output = [i for i in lemmatizer.lemmatize(i) for i in result]\n",
    "        \n",
    "            water_list.append(result)\n",
    "        print(\"\\n\\nWater Tokens\\n\\n\")\n",
    "        print(water_list)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "        pwd_token = []\n",
    "\n",
    "        pwd_list = []\n",
    "        #Tokenising pwd data  \n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result1 = [i for i in pwd_token if not i in stop_words]\n",
    "            pwd_list.append(result1)\n",
    "            \n",
    "        print(\"\\n\\nPWD Tokens\\n\\n\")\n",
    "        print(pwd_list)\n",
    "            \n",
    "            #print( pwd_token)\n",
    "\n",
    "\n",
    "        ksrtc_token =[]\n",
    "        ksrtc_list =[]\n",
    "        #Tokenising ksrtc data    \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in ksrtc_token if not i in stop_words]\n",
    "            ksrtc_list.append(result)\n",
    "            #print(ksrtc_list)\n",
    "            #print( ksrtc_token)\n",
    "            \n",
    "            \n",
    "            \n",
    "        kseb_token = []\n",
    "        kseb_list= []\n",
    "        #Tokenising kseb data    \n",
    "        for i, row in dfkseb.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in kseb_token if not i in stop_words]\n",
    "            kseb_list.append(result)\n",
    "        #print(kseb_list)\n",
    "        #print(kseb_token)\n",
    "        \n",
    "        \n",
    "        env_token = []\n",
    "        env_list = []\n",
    "        #Tokenising env data  \n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in env_token if not i in stop_words]\n",
    "            env_list.append(result)\n",
    "        print(env_list)\n",
    "            #print(env_token)\n",
    "        return(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "\n",
    "\n",
    "   \n",
    "    def word_frequency(self,water_list,pwd_list,ksrtc_list,kseb_list,env_list):\n",
    "        \n",
    "        #word frequencies  Environment department\n",
    "\n",
    "        wordfreq = []\n",
    "       \n",
    "    \n",
    "        for word  in env_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        env_count =Counter(wordfreq)\n",
    "        env_count= dict(env_count)\n",
    "        print(\"\\n\\n Env Count \\n\\n\")\n",
    "        print(type(env_count))\n",
    "        \n",
    "    \n",
    "        #word frequencies  KSEB department\n",
    "        wordfreq = []\n",
    "        for word  in kseb_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        kseb_count = Counter(wordfreq)\n",
    "        kseb_count= dict(kseb_count) \n",
    "        print(\"\\n\\n KSEB Count \\n\\n\")\n",
    "        print(kseb_count)\n",
    "    \n",
    "\n",
    "        \n",
    "        #word frequencies  KSRTC department\n",
    "\n",
    "        wordfreq = []\n",
    "        \n",
    "        for word  in ksrtc_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        ksrtc_count =Counter(wordfreq)\n",
    "        ksrtc_count= dict(ksrtc_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(ksrtc_count)\n",
    "    \n",
    "        \n",
    "        #word frequencies  pwd department\n",
    "\n",
    "        for word  in pwd_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        pwd_count =Counter(wordfreq)\n",
    "        pwd_count = dict(pwd_count)\n",
    "        print(\"\\n\\n PWD Count \\n\\n\")\n",
    "        print(type(pwd_count))\n",
    "        \n",
    "        \n",
    "        #word frequencies  water department\n",
    "\n",
    "        wordfreq = []\n",
    "        for word  in water_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        water_count =Counter(wordfreq)\n",
    "        water_count= dict(water_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(type(water_count))\n",
    "        return(water_count,pwd_count,ksrtc_count,kseb_count,env_count)\n",
    "\n",
    "\n",
    "    def most_repeated_keywords(self,water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq ):\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n Water Freq newwwwwwwwww\")\n",
    "        print(water_freq)\n",
    "        \n",
    "        #print sorted(prices.iteritems(), lambda x, y : cmp(x[1], y[1]))\n",
    "\n",
    "        \n",
    "        water_lis =[]\n",
    "        water_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in water_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        water_dict=(items[:5])\n",
    "        water_lis.append(water_dict)\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        print(\"\\n\\nKEYWORDS  WATER\\n\\n\")\n",
    "        print(water_lis)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n PWD Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        pwd_lis =[]\n",
    "        pwd_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in pwd_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        pwd_dict=(items[:5])\n",
    "        pwd_lis.append(pwd_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  PWD\\n\\n\")\n",
    "        print(pwd_lis)\n",
    "        \n",
    "        \n",
    "        # Finding the most repeated words kseb\n",
    "        print(\"\\n\\n KSEB Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        kseb_lis =[]\n",
    "        kseb_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in kseb_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        kseb_dict=(items[:5])\n",
    "        kseb_lis.append(kseb_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSEB\\n\\n\")\n",
    "        print(kseb_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words ksrtc\n",
    "\n",
    "        print(\"\\n\\n KSRTC Freq newwwwwwwwww\")\n",
    "        print(ksrtc_freq)\n",
    "        \n",
    "        \n",
    "        ksrtc_lis =[]\n",
    "        ksrtc_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in ksrtc_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        ksrtc_dict=(items[:5])\n",
    "        ksrtc_lis.append(ksrtc_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSRTC\\n\\n\")\n",
    "        print(ksrtc_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words env\n",
    "        print(\"\\n\\n ENV Freq newwwwwwwwww\")\n",
    "        print(env_freq)\n",
    "        \n",
    "        \n",
    "        env_lis =[]\n",
    "        env_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in env_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [(k,v) for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        env_dict=(items[:5])\n",
    "        env_lis.append(env_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  ENV \\n\\n\")\n",
    "        print(env_lis)\n",
    "       \n",
    "        \n",
    "        \n",
    "        return(water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis )\n",
    "                \n",
    "        \n",
    "    def most_repeated_keyword_lib(self,dfenv,dfwater,dfpwd,dfksrtc,dfkseb):\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        env_keyword = []\n",
    "        env_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : ENV\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in env_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            env_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            env_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(env_summary)\n",
    "        \n",
    "        # water Keyword\n",
    "        \n",
    "        water_keyword = []\n",
    "        water_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : Water\\n\\n\")\n",
    "        \n",
    "        \n",
    "        for i, row in dfwater.iterrows():\n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in water_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            water_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            water_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(water_summary)\n",
    "        \n",
    "        \n",
    "        #pwd keyword\n",
    "        \n",
    "        pwd_keyword = []\n",
    "        pwd_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : PWD\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in pwd_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            pwd_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            pwd_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(pwd_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        ksrtc_keyword = []\n",
    "        ksrtc_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSRTC\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in ksrtc_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            ksrtc_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            ksrtc_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(ksrtc_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        kseb_keyword = []\n",
    "        kseb_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSEB\\n\\n\")\n",
    "        #print(dfkseb)\n",
    "        \n",
    "        for i, row in dfkseb.iterrows():\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in kseb_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            kseb_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            kseb_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(kseb_summary)\n",
    "        return(env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def jump(self,status):\n",
    "        if status == 1:\n",
    "            env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary=self.most_repeated_keyword_lib(dfenv,dfwater,dfpwd,dfksrtc,dfkseb)\n",
    "        else:\n",
    "            \n",
    "            water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis = self.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq )\n",
    "        return(water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis)\n",
    "            \n",
    "    def test(self):\n",
    "        text_data = input(\"Enter complaint\")\n",
    "        text_data= text_data.replace('[^\\w\\s]','').lower()\n",
    "        \n",
    "        \n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "        for x in text_data.lower(): \n",
    "            if x in punctuations: \n",
    "                text_data = text_data.replace(x, \" \") \n",
    "  \n",
    "   \n",
    "        print(text_data) \n",
    "        \n",
    "            \n",
    "        test_token = word_tokenize(text_data)\n",
    "        print(test_token)\n",
    "        test_list =[]\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i in test_token:\n",
    "            \n",
    "            \n",
    "            if i not in stop_words:\n",
    "        \n",
    "                test_list.append(i)\n",
    "        print(test_list)\n",
    "        \n",
    "        #frequency : \n",
    "        \n",
    "\n",
    "        \n",
    "        counts = Counter(test_list)\n",
    "        count = dict(counts)\n",
    "        print(count)  # word frequency\n",
    "    \n",
    "        items = [(v, k) for k, v in counts.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)  # sorted high to low\n",
    "        test_dict=(items[0:5])\n",
    "        print(test_dict)  #key only\n",
    "        \n",
    "        return(test_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept):\n",
    "        #keyword matching \n",
    "        #water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis\n",
    "        print(\"\\n\\nTest Keywords \\n \\n\")\n",
    "        print(keywords)\n",
    "        \n",
    "        \n",
    "        #pwd predict\n",
    "        pwd_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in pwd_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                pwd_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n PWD predict \\n\\n\")    \n",
    "        print(pwd_predict)\n",
    "        \n",
    "        #water predict\n",
    "        \n",
    "        \n",
    "        water_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in water_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                water_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n Water predict \\n\\n\")    \n",
    "        print(water_predict)\n",
    "        \n",
    "         #ksrtc predict\n",
    "        \n",
    "        \n",
    "        ksrtc_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in ksrtc_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                ksrtc_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n ksrtc predict \\n\\n\")    \n",
    "        print(ksrtc_predict)\n",
    "        \n",
    "        #kseb predict\n",
    "        \n",
    "        kseb_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in kseb_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                kseb_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\n kseb predict \\n\\n\")    \n",
    "        print(kseb_predict)\n",
    "        \n",
    "        \n",
    "        #env predict\n",
    "        \n",
    "        env_predict=[]\n",
    "        \n",
    "        i=0\n",
    "        \n",
    "        for ls in env_lis:\n",
    "            \n",
    "            if ls[i] in keywords[i]:\n",
    "                env_predict.append(ls[i])\n",
    "                i+=1\n",
    "                \n",
    "                \n",
    "        print(\"\\n\\nenv predict \\n\\n\")    \n",
    "        print(env_predict)\n",
    "        \n",
    "        department=dept\n",
    "        dept_values =[1,2,3,4,5]\n",
    "        depart_dict = dict(zip(dept_values,department))\n",
    "        print(depart_dict)\n",
    "        \n",
    "        if len(env_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[5])\n",
    "            \n",
    "        if len(pwd_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[2])\n",
    "            \n",
    "        if len(water_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[1])\n",
    "            \n",
    "        if len(kseb_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[3])\n",
    "            \n",
    "        if len(ksrtc_predict)==0:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Predicted Class = : \"+depart_dict[4])\n",
    "            \n",
    "            \n",
    "        \n",
    "                  \n",
    "        \n",
    "        \n",
    "file =   '/home/gayathri/project/MakeComplaint/data.csv'   \n",
    "\n",
    "x= Main(file)\n",
    "x.punctuate()\n",
    "x.data_clean()\n",
    "dfwater,dfpwd,dfksrtc,dfkseb,dfenv=x.dataframing(x.dataset)\n",
    "\n",
    "water_list,pwd_list,ksrtc_list,kseb_list,env_list = x.tokenisation(dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "\n",
    "water_count,pwd_count,ksrtc_count,kseb_count,env_count = x.word_frequency(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "#x.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq)\n",
    "#x.most_repeated_keyword_lib(dfenv) \n",
    "\n",
    "water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis=x.jump(0)\n",
    "\n",
    "keywords=x.test()\n",
    "dept=x.department_class()\n",
    "x.evaluate(keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                             Subject  \\\n",
      "0   1         No water supply connection.   \n",
      "1   2                  Road re tarring.\\n   \n",
      "2   3  Power cuts without a prior notice.   \n",
      "3   4     Scarcity of water in day time.    \n",
      "4   5                      Water scarcity   \n",
      "\n",
      "                                           Complaint      Departments  \n",
      "0  No water pipeline connection in amma gardens r...  Water Authority  \n",
      "1  I am a resident of sreekaryam  Ambadi Nagar la...              PWD  \n",
      "2  As everyone knows that electricity is the majo...             KSEB  \n",
      "3  There is scarcity of water in my area Vanchiyo...  Water Authority  \n",
      "4  There is a huge scarcity of water in remote ar...  Water Authority  \n",
      "   id Subject                                          Complaint  \\\n",
      "0   1          no water pipeline connection in amma gardens r...   \n",
      "1   2          i am a resident of sreekaryam  ambadi nagar la...   \n",
      "2   3          as everyone knows that electricity is the majo...   \n",
      "3   4          there is scarcity of water in my area vanchiyo...   \n",
      "4   5          there is a huge scarcity of water in remote ar...   \n",
      "\n",
      "       Departments  \n",
      "0  Water Authority  \n",
      "1              PWD  \n",
      "2             KSEB  \n",
      "3  Water Authority  \n",
      "4  Water Authority  \n",
      "(30, 4)\n",
      "                                 Subject_and_Complaint\n",
      "12    the number of deaths from cardiovascular dise...\n",
      "13    people make river water polluted by dumping h...\n",
      "19    due to the sand mining there is more of effec...\n",
      "20    in our areas during night some strangers are ...\n",
      "33    fishes in the river pampa are dying massively...\n",
      "40    construction is going on the trivandrum in th...\n",
      "42    many industries dump wastes into rivers  lake...\n",
      "43    burning of plastics in public places cause a ...\n",
      "44    dumping of wastes in the public places causes...\n",
      "45    activities like waste disposal from residenti...\n",
      "46    overfishing  which causes a reduction in dive...\n",
      "47    artificial light at night is one of the most ...\n",
      "48    the electronic waste problem is huge the elec...\n",
      "49    ocean acidification is caused when co₂ dissol...\n",
      "50    noise produced by vehicles  political parties...\n",
      "58    now a days many people are cutting down the t...\n",
      "62    polution by ksrtc bus is very heavy today so ...\n",
      "65    quarries are bad for the environment in sever...\n",
      "70                            save alappad stop mining\n",
      "72    i would like to inform you that city resident...\n",
      "74    preserving biodiversity  saving forest can he...\n",
      "100   intolerable temperature change in summer seas...\n",
      "103                         intense heat during summer\n",
      "110   one among the factors which shaped kerala as ...\n",
      "112   due to excessive use of chlorine and other di...\n",
      "113   we should have more projects on planting tree...\n",
      "114   need proper regulations to control the pollution\n",
      "116   increased deforestation  uncontrolled constru...\n",
      "118   the pollution levels in the kochi city is ris...\n",
      "120   waste disposal in public premises make life h...\n",
      "\n",
      "\n",
      "Water Tokens\n",
      "\n",
      "\n",
      "[['water', 'pipeline', 'connection', 'amma', 'gardens', 'residential', 'area', 'erattakalangu', 'malayinkeezhu'], ['scarcity', 'water', 'area', 'vanchiyoor', 'day', 'time', 'creates', 'great', 'trouble', 'people', 'getting', 'ready', 'work', 'schools', 'office', 'etc'], ['huge', 'scarcity', 'water', 'remote', 'areas', 'people', 'walk', 'large', 'distances', 'standing', 'queue', 'fetch', 'water', 'problem', 'exiss', 'hilly', 'areas', 'idukki', 'district', 'kerala', 'si', 'humbly', 'request', 'take', 'necessary', 'actions', 'tackle', 'problem', 'near', 'future'], ['frequent', 'scarcity', 'water', 'morning'], ['100', 'houses', 'area', 'water', 'supply', 'available', 'therepeople', 'get', 'water', 'needs', 'therefore', 'request', 'concerning', 'authorities', 'look', 'matter', 'seriously', 'take', 'necessary', 'steps', 'solving', 'problem', 'water', 'supply', 'may', 'kindly', 'made', 'daily', 'locality', 'people', 'may', 'get', 'rid', 'problem', 'water', 'supply'], ['stayed', 'hotel', 'kovalam', 'beach', 'called', 'palm', 'grove', 'second', 'beach', 'road', 'kovalam', 'near', 'kovalam', 'bus', 'stand', 'came', 'know', 'hotel', 'water', 'connection', 'without', 'water', 'supply', 'authority', 'sealed', 'pipe', 'big', 'dues', 'bill', 'stealing', 'water', 'sealed', 'pipe', 'last', 'year', 'huge', 'capacity', 'water', 'storage', 'building', 'approx', '20000', 'ilters', 'capacity', 'stayed', 'hotel', '3', 'nights', 'staff', 'told', 'things', 'regarding', 'please', 'take', 'immediate', 'action', 'fix', 'small', 'lengthy', 'pipe', 'two', 'side', 'thread', 'connector', 'connected', 'sealed', 'pipewhich', 'also', 'caped', 'glue', 'closed', 'thread', 'cap', 'usually', 'water', 'supply', 'hardly', '3', '4', 'days', 'per', 'week', 'day', 'steal', 'water', 'fill', '20000', 'liters', 'appox', 'filled', 'use', '1', 'week', 'please', 'take', 'necessary', 'action'], ['water', 'leakage', 'locality', 'still', 'unrepaired', 'causes', 'water', 'shortage', 'areas'], ['water', 'flowing', 'pipe', 'foul', 'smell', 'therefore', 'unfits', 'drinking', 'cooking', 'purposes'], ['amount', 'unauthorised', 'connection', 'water', 'mains', 'cause', 'huge', 'bills', 'authorised', 'consumer'], ['public', 'pipe', 'triivandrum', 'city', 'leaking', 'thus', 'leads', 'water', 'shortage'], ['drinking', 'water', 'pipe', 'near', 'puthoor', 'junction', 'broken', 'water', 'flowing', '2', 'days', 'please', 'take', 'necessary', 'action'], ['shortage', 'drinking', 'water'], ['scarcity', 'drinking', 'water', 'summer'], ['leakage', 'water', 'mg', 'road'], ['please', 'setup', 'enough', 'water', 'resource', 'rural', 'areas'], ['residing', 'edathua', 'panchayat', 'kuttanad', 'taluk', 'staying', 'rented', 'house', 'water', 'connection', 'meter', 'water', 'getting', 'waterour', 'house', 'consumer', 'number', '471eda', 'neighbouring', 'houseconsumer', 'no818eda', 'also', 'getting', 'water', 'well', 'also', 'waterwe', 'facing', 'great', 'difficulties', 'daytoday', 'needs', 'kindly', 'request', 'take', 'necessary', 'action'], ['totally', 'residing', 'attuparambil', 'eravipuram', 'kollam', 'locality', 'facing', 'severe', 'problem', 'growing', 'instances', 'insufficient', 'water', 'supply', 'last', '5', 'days', 'locality', 'already', 'given', 'many', 'complaints', 'kindly', 'requesting', 'look', 'matter', 'personally', 'needful', 'shall', 'much', 'thankful'], ['last', 'one', 'month', 'kochi', 'facing', 'acute', 'shortage', 'water', 'supply', 'kwa', 'supply', 'system', 'summer', 'getting', 'bad', 'worse', 'shortage', 'water', 'aggravating', 'condition'], ['writing', 'inform', 'residents', 'punnakunnam', 'pulinkunnu', 'kuttanadu', 'alappuzha', 'facing', 'shortage', 'drinking', 'water', 'last', '10', 'monthsin', 'fact', 'every', 'member', 'society', 'disturbed', 'account', 'unavailability', 'water', 'supply', 'basic', 'need', 'every', 'human'], ['new', 'water', 'pipe', 'connection', 'installed', 'front', 'house', 'leaking', 'water', 'leaking', 'great', 'force', 'getting', 'wasted'], ['please', 'note', 'informing', 'drinking', 'water', 'keep', 'flowing', 'road', 'always', 'wet', 'compound', 'fully', 'accumulated', 'meter', 'cabin'], ['may', 'one', 'two', 'week', 'dont', 'get', 'water', 'even', 'provide', 'water', 'supply', 'time', 'late', 'like', 'midnight', 'low', 'pressure'], ['please', 'issue', 'good', 'water', 'meter'], ['consumer', 'waterworks', 'sub', 'division', 'thrissur', 'per', 'mentioned', 'consumer', 'number', 'getting', 'water', 'past', 'four', 'months', 'house', 'leakage', 'tiled', 'portion', 'road', 'thrissur', 'corporation', 'noticed', 'reported', 'assistant', 'engineer', 'action', 'taken', 'rectify', 'leakage', 'restore', 'water', 'supply', 'house'], ['since', 'january', 'consuming', 'mudmix', 'water', 'every', 'supply', 'water', 'authority', 'storage', 'tank', 'destroy', 'mud', 'resulted', 'taps', 'bathroom', 'systems', 'also'], ['public', 'tap', 'remains', 'idle', 'past', 'couple', 'weeks', 'affected', 'lives', 'people', 'neighborhood', 'awkwardly'], ['recieved', 'bill', '792', 'rs', 'house', 'closed', 'state', '3', 'months', 'information', 'consumption', 'details', 'previous', 'reading', 'information', 'bill'], ['water', 'supply', 'vazhathope', 'pachayath', 'two', 'weeks', 'people', 'need', 'look', 'upon', 'water', 'sources', 'much', 'frustrating'], ['regular', 'water', 'supply', 'september', '2017', 'onwards', 'till', 'date'], ['water', 'loosing', 'distribution', 'line', 'every', 'day', 'pumping', 'progressthis', 'water', 'trapped', 'walk', 'way', 'public', 'useand', 'time', 'mosqitos', 'growingseveral', 'time', 'iform', 'water', 'athority', 'kochi', 'office'], ['domestic', 'water', 'supply', 'houses', 'situated', 'near', 'kunnathuvathucal', 'bridge', 'last', '3', 'days'], ['name', 'wrongly', 'recorded', 'water', 'connection', 'records'], ['able', 'complete', 'payment', 'transaction', 'water', 'authority', 'website'], ['pay', 'utility', 'bills', 'mostly', 'via', 'online', 'payment', 'services', 'water', 'bill', 'facing', 'problem', 'paying', 'bill', 'water', 'authority', 'website'], ['wastage', 'drinking', 'water', 'due', 'damaged', 'pipeline'], ['trying', 'make', 'bill', 'payment', 'entered', 'credentials', 'tried', 'login', 'account', 'everytime', 'try', 'login', 'get', 'error', 'message'], ['request', 'check', 'meter', 'replace', 'repair', 'early', 'possible'], ['location', 'water', 'connection', 'since', 'summer', 'facing', 'severe', 'water', 'scarcity', 'please', 'set', 'connection', 'loction'], ['pay', 'bill', 'e', 'payment', 'web', 'site', 'charge', 'additional', 'rupees', '10', 'transaction']]\n",
      "\n",
      "\n",
      "PWD Tokens\n",
      "\n",
      "\n",
      "[['resident', 'sreekaryam', 'ambadi', 'nagar', 'lane', '3', 'road', 'full', 'potholes', 'kindly', 'necessary', 'steps', 'maintenance', 'road'], ['condition', 'road', 'rural', 'areas', 'kerala', 'miserable', 'corruption', 'contract', 'maintenance', 'road', 'causing', 'problems', 'leads', 'frequent', 'damage', 'newly', 'constructed', 'tared', 'roads', 'potholes', 'road', 'leads', 'accidents', 'losing', 'balance', 'vehicles', 'paved', 'way', 'damage', 'road'], ['living', 'area', 'road', 'harsh', '500', 'people', 'living', 'area', 'travelling', 'unpaved', 'road', 'difficult', 'taskirequests', 'tar', 'road', 'early', 'possible'], ['due', 'recent', 'landslide', 'activity', 'roads', 'got', 'shattered', 'traffic', 'stopped', 'many', 'days', 'please', 'make', 'tarring', 'process', 'faster'], ['mr', 'kumar', 'locality', 'constructing', 'wall', 'taking', 'footpath', 'pwd'], ['road', 'works', 'without', 'prior', 'notice', 'day', 'time', 'cause', 'heavy', 'traffic', 'congestion'], ['melattumoozhy', 'thannippara', 'road', 'bad', 'condition', 'accidents', 'increasing', 'day', 'day', 'please', 'take', 'necessary', 'actions', 'retarring', 'process'], ['road', 'sreekaryam', 'proper', 'width', 'well', 'maintained'], ['id', 'like', 'make', 'public', 'works', 'department', 'aware', 'number', 'potholes', 'impeding', 'traffic', 'also', 'causing', 'undue', 'wear', 'tear', 'vehicles', 'hitting', 'pothole', 'even', 'speed', 'limit', 'pop', 'tire', 'damage', 'car', 'even', 'pose', 'physical', 'threat', 'drivers', 'pedestrians', 'know', 'state', 'law', 'permits', 'drivers', 'seek', 'reimbursement', 'losses', 'due', 'road', 'hazards', 'defects', 'result', 'negligence', 'potential', 'liability', 'claims', 'high', 'several', 'potholes', 'located', 'maple', 'street', '12th', '13th', 'streets', 'one', 'least', 'two', 'feet', 'diameter', 'intersection', '13th', 'pine', 'know', 'crew', 'cant', 'get', 'every', 'pothole', 'right', 'away', 'growing', 'many', 'months', 'attached', 'photos', 'illustrate', 'problem'], ['roads', 'safe', 'running', 'heavyweight', 'vehicle', 'poor', 'maintenance', 'problem', 'aggravates', 'especially', 'rainy', 'season', 'major', 'problem', 'india', 'roads', 'high', 'traffic', 'condition', 'road', 'used', 'various', 'types', 'vehicles', 'highspeed', 'trucks', 'cars', 'tractors', 'twowheelers', 'driven', 'carts', 'cyclists', 'etc', 'things', 'create', 'high', 'traffic', 'jam', 'congestion', 'road', 'accident', 'etcthe', 'roads', 'india', 'lack', 'wayside', 'amenities', 'like', 'first', 'aid', 'centers', 'telephone', 'booths', 'repair', 'shops', 'restaurants', 'clean', 'toilets', 'create', 'serious', 'problems', 'drivers', 'moreover', 'little', 'attention', 'given', 'road', 'safety', 'issues', 'also', 'road', 'safety', 'rules', 'violation', 'laws', 'road', 'transportation', 'system', 'country', 'requires', 'immediate', 'modernization', 'latest', 'technology', 'road', 'transport', 'sector', 'use', 'old', 'technology', 'vehicles', 'still', 'prevalent', 'ultimately', 'increase', 'number', 'road', 'accidents', 'due', 'bad', 'road', 'condition', 'transport', 'companies', 'bear', 'huge', 'amount', 'per', 'year', 'wear', 'tear', 'vehicles', 'important', 'point', 'proper', 'attention', 'given', 'road', 'direction', 'railway', 'department', 'always', 'indifferent', 'attitude', 'biggest', 'barrier', 'transport', 'india', 'railway', 'crossings', 'despite', 'government', 'permissions', 'government', 'employees', 'make', 'reasonable', 'contributions', 'even', 'bribe', 'timeconsuming', 'transport', 'traders', 'also', 'large', 'businessmen', 'businessmen', 'also', 'raised'], ['roads', 'many', 'pitfalls', 'sometimes', 'cause', 'accidents', 'unwary', 'drivers'], ['rising', 'peakhour', 'traffic', 'congestion', 'inescapable', 'condition', 'many', 'areas', 'trivandrum', 'city', 'sufficient', 'traffic', 'control', 'signal', 'systems', 'handle', 'situations'], ['roads', 'properly', 'maintained', 'repair', 'works', 'roads', 'last', 'days', 'proper', 'transportation', 'facility', 'basic', 'right', 'citizens'], ['actually', 'dont', 'good', 'roads', 'worthy', 'tax', 'pay', 'hopefully', 'government', 'find', 'way', 'fix', 'thanks'], ['pathholes', 'road', 'extremly', 'half', 'feet', 'size', 'accident', 'prone', 'today', 'effect', 'daily', 'travelling', 'student', 'employees', 'suffering', 'also', 'may', 'cause', 'health', 'problems'], ['drainage', 'work', 'muthambioorallur', 'road', 'thadoli', 'thazha', 'junction', 'koyilandy', 'taluk', 'calicut', 'district', 'length', '100', 'mtr', 'progressing', 'outlet', 'crossing', 'road', 'directed', 'towards', 'compound', 'wall', 'letting', 'water', 'flow', 'nayadan', 'puzha', 'lake', 'completion', 'water', 'flow', 'directly', 'bottom', 'compound', 'wall', 'hitting', 'compound', 'wall', 'changes', 'direction', 'flow', 'damage', 'wall', 'nature', 'place', 'loose', 'mud', 'learnt', 'provision', 'continue', 'drainage', 'limit', 'road', 'requested', 'kindly', 'needful', 'avoid', 'damage', 'wall', 'length', '15', 'mtr', 'early', 'action', 'requested', 'canal', 'water', 'open', 'last', 'january'], ['sir', 'please', 'initiate', 'surprise', 'visit', 'kerala', 'know', 'conditions', 'roads', '6', 'monthsafter', 'rainy', 'season', 'since', 'roads', 'repaired', 'also', 'roads', 'broken', 'instead', 'chipping', 'existing', 'roads', 'resurfaced', 'increases', 'height', 'roads', 'height', 'roads', 'increased', 'height', 'houses', 'office', 'complexes', 'increased', 'know', 'take', 'help', 'media', 'channels', 'like', 'asianet', 'news', 'manorama', 'news', 'indiavision', 'etc', 'also', 'common', 'trend', 'ie', 'roads', 'repaired', 'broken', 'manually', 'underlying', 'cables', 'underground', 'left', 'without', 'repairing', 'sirmadam', 'per', 'day', 'lacs', 'vehicles', 'entering', 'roads', 'showrooms', 'much', 'tax', 'collected', 'isnt', 'sufficient', 'repair', 'roads', 'roads', 'leveled', 'properly', 'much', 'fuel', 'saved', 'prices', 'fuel', 'controlled', 'certain', 'extent', 'right', 'hope', 'would', 'take', 'factors', 'consideration'], ['dear', 'sir', 'due', 'intervention', 'politicians', 'every', 'footpath', 'flooded', 'vendors', 'selling', 'tender', 'cocanuts', 'shoe', 'repairs', 'petty', 'shops', 'filled', 'pan', 'masalas', 'liquiors', 'tea', 'snacks', 'notnot', 'traders', 'blocking', 'view', 'side', 'roads', 'motorist', 'predict', 'see', 'going', 'emerge', 'side', 'roads', 'petty', 'shops', 'well', 'concreated', 'base', 'running', 'businesses', 'like', 'real', 'estate', 'rentals', 'etcetc', 'idea', 'growing', 'nation', 'city', 'clean', 'roads', 'responsible', 'pwd', 'authority', 'issue', 'notice', 'people', 'evict', 'themgod', 'bad', 'country', 'pity', 'consideration', 'appeal', 'something', 'stop'], ['heavy', 'traffic', 'ss', 'kovil', 'road', 'thampanoor', 'large', 'amount', 'vehicle', 'parking'], ['connection', 'othukkungal', 'town', 'malappuram', 'district', 'kerala', 'beautification', 'existing', 'bus', 'waiting', 'shed', 'towards', 'kottakkal', 'removed', 'last', 'year', 'till', 'date', 'new', 'shed', 'constructed', 'makes', 'difficult', 'common', 'passengers', 'kindly', 'take', 'necessary', 'action', 'construction', 'waiting', 'shed', 'helpful', 'layman'], ['road', 'sreekaryam', 'ambadi', 'nagar', 'chithravila', 'lot', 'gutter', 'please', 'necessary', 'action', 'retar', 'road'], ['road', 'kotooli', 'mangotu', 'vayal', 'road', 'completely', 'digged', 'middle', 'pregnant', 'ladies', 'may', 'give', 'delivery', 'go', 'road', 'slippery', 'chance', 'high', 'please', 'something', 'kind', 'accidents', 'lot', 'kids', 'also', 'passing', 'road', 'chances', 'hitting', 'kids', 'driver', 'try', 'avoid', 'digged', 'part', 'middle', 'road', 'make', 'pedestrians', 'edge', 'may', 'result', 'hit', 'fall', 'resulting', 'injury', 'please', 'consider', 'solve', 'early', 'possible'], ['road', 'going', 'towards', 'trivandrum', 'technopark', 'phase', '3', 'gate', 'towards', 'technopark', 'buildings', 'road', 'starting', 'nippol', 'toyota', 'going', 'towards', 'kallingal', 'road', 'name', 'kallingal', 'attinkuzhy', 'road', 'road', 'damaged', 'last', '15', 'years', 'one', 'caring', 'minimum', '300', 'vehicles', 'daily', 'goes', 'morning', 'evening', 'towards', 'offices', 'like', '1', 'meter', 'gutter', 'middle', 'road', 'making', 'health', 'issues', 'people', 'danger', 'situation', 'urgent', 'action', 'required'], ['current', 'driving', 'licence', 'poor', 'make', 'like', 'pvc', 'card', 'digital', 'card'], ['roads', 'villages', 'proper', 'condition', 'people', 'travelplease', 'take', 'necessary', 'action', 'regarding'], ['road', 'full', 'pits'], ['submitted', 'road', 'condition', 'karukaputhurpallipadamthichur', 'palakkad', 'distis', 'pathetic', 'condition', 'even', 'suitable', 'footwalk', 'due', 'boarder', 'villages', 'two', 'constituency', 'mla', 'bothers', 'area', 'please', 'needful', 'earliest'], ['sir', 'public', 'wants', 'know', 'pwd', 'still', 'continuing', 'toll', 'charge', 'poovathumkadavu', 'bridge', 'poor', 'maintenance', 'road', 'street', 'light', 'misbehaviour', 'toll', 'collectors', 'passengers', 'every', 'day', 'public', 'suffering', 'area', 'whole', 'money', 'bridge', 'collected', 'public', 'gst', 'road', 'tax', 'insurance', 'money', 'going', 'nearby', 'mathilakam', 'bridge', 'toll', 'fee', 'stopped', '1', 'year', 'back'], ['road', 'ramamangalam', 'choondy', 'dug', 'works', 'related', 'kwh', 'condition', 'travel', 'used', 'travel', 'around', '40', 'km', 'daily', 'include', 'road', 'also'], ['register', 'complaint', 'poor', 'road', 'conditions', 'big', 'pot', 'holes', 'arookutty', 'aroor', 'road', 'alappuzha', 'district'], ['damaged', 'long', 'duration', 'potholes', 'converted', 'hidden', 'hazards', 'bikers', 'potential', 'risk', 'road', 'accidents'], ['roads', 'city', 'damaged', 'quality', 'needed'], ['keshavadasapuram', 'traffic', 'block', 'lack', 'planning'], ['low', 'quality', 'roads'], ['drivers', 'dont', 'know', 'correct', 'times', 'roots', 'many', 'bus', 'times'], ['tarring', 'roads', 'damaged', 'suddenly', 'reason', 'behind'], ['road', 'maintained', 'properly'], ['many', 'drivers', 'reckless', 'follow', 'road', 'rules', 'law', 'enforcement', 'lax', 'violations', 'makes', 'things', 'difficult', 'drivers', 'unpredictable', 'driving', 'others', 'road', 'pedestrians', 'walking', 'roadside', 'crossing', 'roads', 'makes', 'roads', 'dangerous', 'ordinary', 'citizens'], ['proper', 'maintenance', 'roads', 'leads', 'pot', 'holes', 'roads'], ['everybody', 'knows', 'highway', 'connecting', 'kochi', 'muvattupzha', 'one', 'busiest', 'crowed', 'road', 'ernakulam', 'city', 'withing', 'last', '3', 'years', 'steady', 'increase', 'unauthorized', 'road', 'side', 'business', 'establishments', 'small', 'tent', 'establishments', 'unauthorized', 'illegal', 'creating', 'lot', 'accidents', 'past', 'months', 'cars', 'bikes', 'tent', 'stop', 'immediately', 'see', 'shacks', 'created', 'sudden', 'unexpected', 'accidents', 'build', 'road', 'reduce', 'road', 'visibility', 'example', 'shack', 'next', 'peruvammuzhy', 'selling', 'fish', 'created', 'countless', 'accidents', 'hope', 'department', 'takes', 'actions', 'business', 'establishments', 'immediatelythe', 'effected', 'areas', 'kolenchery', 'valakom'], ['pathanapurm', 'pattazhy', 'road', 'maintained', 'road', '12m', 'width', 'plan', 'less', '5'], ['manathoor', 'maniykumpparakarimkunnam', 'road', 'worst', 'condition', 'construction', 'pala', 'thodupuzha', 'road', 'many', 'vehicles', 'used', 'road', 'shortcut', 'road', 'fully', 'destroyed', 'please', 'retarr', 'road', 'implement', 'proper', 'sign', 'boards', 'road', 'markings']]\n",
      "[['number', 'deaths', 'cardiovascular', 'disease', 'attributed', 'air', 'pollution', 'much', 'higher', 'expectedair', 'pollution', 'caused', 'twice', 'many', 'deaths', 'cvd', 'respiratory', 'diseases'], ['people', 'make', 'river', 'water', 'polluted', 'dumping', 'household', 'wastage', 'industrial', 'wastage'], ['due', 'sand', 'mining', 'effect', 'ecosystem', 'severe', 'impact', 'plants', 'animals', 'rivers'], ['areas', 'night', 'strangers', 'dumping', 'hotel', 'waste', 'domestic', 'waste', 'foul', 'smelling', 'sides', 'road', 'wastes', 'remain', 'th', 'road', 'uncleaned', 'camera', 'survelliance', 'facility', 'catch', 'people', 'throwing', 'wastes'], ['fishes', 'river', 'pampa', 'dying', 'massively', 'due', 'deposits', 'oil', 'factories', 'nearby'], ['construction', 'going', 'trivandrum', 'paddy', 'fields', 'please', 'take', 'necessary', 'steps', 'save', 'farming'], ['many', 'industries', 'dump', 'wastes', 'rivers', 'lakes', 'ponds', 'streams', 'attempt', 'hide', 'wastes', 'epa', 'nspectors', 'water', 'sources', 'feed', 'major', 'crops', 'food', 'becomes', 'contaminated', 'variety', 'chemicals', 'bacteria', 'causing', 'rampant', 'health', 'problems'], ['burning', 'plastics', 'public', 'places', 'cause', 'major', 'health', 'concern', 'rate', 'lung', 'cancer', 'patients', 'increasing', 'day', 'day', 'high', 'time', 'check', 'activities'], ['dumping', 'wastes', 'public', 'places', 'causes', 'major', 'health', 'issues', 'inviting', 'eradicated', 'disease', 'mechanism', 'collect', 'wastes', 'households', 'disposed', 'properly'], ['activities', 'like', 'waste', 'disposal', 'residential', 'commercial', 'industrial', 'areas', 'oil', 'spills', 'runoff', 'agriculture', 'contaminate', 'bodies', 'water'], ['overfishing', 'causes', 'reduction', 'diversity', 'marine', 'life', 'fishermen', 'considering', 'breeding', 'time'], ['artificial', 'light', 'night', 'one', 'obvious', 'physical', 'changes', 'humans', 'made', 'biosphere', 'artificial', 'light', 'also', 'affects', 'dispersal', 'orientation', 'migration', 'hormone', 'levels', 'resulting', 'disrupted', 'circadian', 'rhythms'], ['electronic', 'waste', 'problem', 'huge', 'electronics', 'end', 'landfills', 'toxics', 'like', 'lead', 'mercury', 'cadmium', 'leach', 'soil', 'water'], ['ocean', 'acidification', 'caused', 'co₂', 'dissolves', 'ocean', 'bonding', 'sea', 'water', 'creating', 'carbonic', 'acid', 'acid', 'reduces', 'ph', 'levels', 'water'], ['noise', 'produced', 'vehicles', 'political', 'parties', 'religious', 'centers', 'causes', 'great', 'harm', 'human', 'ears'], ['days', 'many', 'people', 'cutting', 'trees', 'purposes', 'example', 'many', 'oragansations', 'builders', 'cut', 'trees', 'build', 'projects', 'cause', 'real', 'harm', 'humans', 'also', 'utilizing', 'fertile', 'paddy', 'fields', 'construction', 'affect', 'environment', 'oxygen', 'content', 'air', 'become', 'low', 'oxygen', 'content', 'level', 'decreases', 'air', 'survival', 'living', 'beings', 'move', 'harder', 'way', 'also', 'major', 'factor', 'ozone', 'depletion', 'ozone', 'holes', 'formed', 'harmful', 'radiations', 'enter', 'earth', 'holes', 'causes', 'real', 'harm', 'living', 'beings', 'continues', 'way', 'threatening', 'part', 'lives', 'please', 'take', 'serious', 'issue', 'make', 'necessary', 'useful', 'remedies'], ['polution', 'ksrtc', 'bus', 'heavy', 'today', 'government', 'fix', 'soon', 'possible'], ['quarries', 'bad', 'environment', 'several', 'ways', 'abruptly', 'interrupt', 'continuity', 'open', 'space', 'cause', 'soil', 'erosion', 'air', 'dust', 'pollution', 'deterioration', 'water', 'quality', 'residential', 'area', 'create', 'noise', 'hazards', 'request', 'higher', 'authority', 'investigate', 'punish', 'officials', 'hand', 'quarrying', 'illegal', 'mining', 'time', 'government', 'create', 'awareness', 'potentially', 'negative', 'impact', 'quarrying'], ['save', 'alappad', 'stop', 'mining'], ['would', 'like', 'inform', 'city', 'residents', 'facing', 'difficulties', 'dump', 'domestic', 'wastes', 'humbly', 'request', 'take', 'necessary', 'actions'], ['preserving', 'biodiversity', 'saving', 'forest', 'help', 'overcome', 'issuesalso', 'recycling', 'avoiding', 'usage', 'plastic', 'efficient', 'use', 'fuel'], ['intolerable', 'temperature', 'change', 'summer', 'season', 'cause', 'dried', 'rivers', 'skin', 'disease'], ['intense', 'heat', 'summer'], ['one', 'among', 'factors', 'shaped', 'kerala', 'gods', 'country', 'euphoric', 'climate', 'never', 'touched', 'extremes', 'thanks', 'moderating', 'influence', 'sea', 'mighty', 'western', 'ghats', 'scenario', 'changed', 'lot', 'kerala', 'witnessing', 'unprecedental', 'surge', 'temperature', 'kumbhachoodu', 'termed', 'old', 'generation', 'time', 'high', 'impacting', 'livelihood', 'many'], ['due', 'excessive', 'use', 'chlorine', 'disinfectants', 'water', 'causing', 'long', 'term', 'health', 'problems', 'like', 'hair', 'fall', 'rashes', 'etc', 'amount', 'disinfectants', 'used', 'water', 'supplied', 'need', 'reconsidered'], ['projects', 'planting', 'trees', 'dont', 'cut', 'big', 'grownup', 'trees'], ['need', 'proper', 'regulations', 'control', 'pollution'], ['increased', 'deforestation', 'uncontrolled', 'constructiondevelopment', 'activities', 'vehicle', 'emissions', 'heavily', 'contribute', 'increase', 'temperature', 'government', 'build', 'new', 'policies', 'also', 'consider', 'switching', 'renewable', 'energy', 'sources'], ['pollution', 'levels', 'kochi', 'city', 'rising', 'rapidly', 'government', 'initiate', 'steps', 'curb'], ['waste', 'disposal', 'public', 'premises', 'make', 'life', 'hard', 'people', 'living', 'around']]\n",
      "\n",
      "\n",
      " Env Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " KSEB Count \n",
      "\n",
      "\n",
      "{'phase': 2, 'take': 1, 'easily': 1, 'comes': 1, 'large': 1, 'month': 1, 'hot': 1, 'major': 1, 'even': 3, 'lights': 2, 'low': 1, '3': 1, 'complaint': 1, 'say': 1, 'farming': 1, 'heavy': 1, 'times': 1, 'necessary': 1, 'always': 1, 'robbery': 1, 'normalplease': 1, 'announcements': 1, 'phases': 1, 'condition': 1, 'find': 1, 'scenario': 1, 'showing': 1, 'make': 2, 'years': 1, 'ease': 1, 'transformer': 2, 'applied': 1, 'unsocial': 1, 'evening': 1, 'platforms': 1, 'rs': 1, 'difficult': 1, 'morning': 1, 'though': 1, 'communication': 1, 'meter': 2, 'came': 1, 'look': 1, 'raining': 1, 'day': 2, 'crawl': 1, 'fastly': 1, 'knows': 1, 'working': 4, 'recently': 1, 'sound': 1, 'different': 1, 'first': 1, 'equipments': 1, 'appliances': 1, 'failed': 1, 'overall': 1, 'regular': 1, 'set': 1, 'failures': 1, 'using': 2, 'almost': 1, 'houses': 1, 'fast': 1, 'one': 2, 'reason': 1, 'madavoor': 1, 'three': 1, 'experiences': 1, 'fix': 1, 'unnoticed': 1, 'proper': 1, 'big': 1, 'power': 9, 'daysplease': 1, 'high': 3, 'public': 1, 'sure': 1, 'past': 1, 'electrical': 1, 'repair': 2, 'house': 2, 'street': 1, 'action': 1, 'without': 2, 'daysremaining': 1, 'particular': 1, 'connections': 1, 'highly': 1, 'failure': 2, 'industries': 1, 'prior': 2, 'use': 1, 'avoid': 1, 'since': 1, '700': 1, 'till': 1, 'makes': 1, 'procedure': 1, 'peoples': 1, 'section': 1, 'wrongly': 1, 'needed': 1, 'many': 2, 'night': 2, 'connectionplease': 1, 'grabbing': 1, 'damaged': 1, 'near': 1, 'home': 2, 'frequently': 1, 'values': 1, 'activities': 1, 'notice': 1, 'summer': 1, 'checking': 1, 'trivandrum': 1, 'facing': 3, 'trouble': 1, 'drunken': 1, 'ensurde': 1, 'rectified': 1, 'connected': 1, 'get': 1, 'months': 2, 'locality': 2, 'lot': 1, 'problem': 3, 'exploded': 1, 'please': 3, 'wires': 4, 'issue': 3, 'going': 1, 'current': 1, 'examinations': 1, 'result': 1, 'corrupt': 1, 'cut': 1, 'replace': 1, 'every': 2, 'request': 1, 'electricity': 7, 'occurring': 1, 'adjoining': 1, 'affect': 1, 'electronic': 1, 'lineman': 1, 'cuts': 3, 'left': 1, 'give': 1, 'everyone': 1, 'load': 2, 'burnt': 1, 'peak': 1, 'devices': 1, 'must': 1, 'force': 1, 'us': 2, 'unable': 1, 'got': 4, 'due': 3, 'employees': 1, 'time': 6, 'old': 1, 'overhead': 1, 'well': 1, 'bribe': 2, 'sector': 2, 'unavailability': 1, 'shedding': 2, 'continues': 1, 'connection': 5, 'loss': 1, 'shortage': 1, 'havent': 1, '15': 1, 'money': 1, 'still': 1, 'city': 1, 'supply': 2, 'voltage': 3, 'electric': 2, 'new': 2, 'bad': 2, 'misbehaved': 1, 'last': 2, 'frequent': 1, 'state': 1}\n",
      "\n",
      "\n",
      " KSRTC Count \n",
      "\n",
      "\n",
      "{'take': 2, 'workers': 1, 'travel': 1, 'life': 1, 'occupied': 1, 'venjaramoodu': 1, 'drivers': 4, 'speed': 1, 'amount': 1, 'station': 1, 'back': 2, 'great': 1, 'dependable': 1, 'local': 1, 'balance': 1, 'rescheduling': 1, 'kazhakkuttam': 1, 'ran': 1, 'schedule': 1, 'buses': 10, 'low': 1, 'services': 4, 'increase': 1, 'causes': 1, 'took': 1, 'cottton': 1, 'arrange': 1, 'rushy': 1, 'alloted': 1, 'times': 1, 'necessary': 1, 'ask': 1, 'always': 1, 'busses': 2, 'reduced': 1, 'atleast': 2, 'depending': 1, 'sir': 1, 'none': 1, 'overspeeding': 2, 'value': 1, 'carelessly': 1, 'safety': 1, 'miss': 1, 'standing': 1, 'travelling': 1, 'equality': 1, 'even': 3, 'innocent': 1, 'running': 1, 'kills': 1, 'willing': 1, 'limited': 1, 'accidents': 1, 'fast': 2, 'heavily': 1, 'income': 1, 'conductors': 1, 'upon': 1, 'difficult': 1, 'morning': 2, 'causing': 1, 'earlier': 1, 'work': 1, 'shortcuts': 1, 'commute': 2, 'dashed': 1, 'spend': 1, 'noticed': 1, 'areas': 1, 'person': 1, 'day': 1, 'government': 1, 'late': 3, 'around': 3, 'daily': 1, 'timings': 1, 'students': 3, 'recently': 3, 'like': 1, 'brutally': 1, 'hill': 1, 'give': 1, 'least': 1, 'kattakkada': 1, 'reach': 4, 'filled': 1, 'transport': 2, 'busesatleast': 1, 'route': 3, 'femalesthen': 1, 'regular': 1, 'travelyesterday': 1, 'control': 1, 'due': 3, 'confirm': 1, 'road': 2, 'busesplease': 1, 'safer': 1, 'behaving': 1, 'done': 1, 'passenger': 2, 'lady': 1, 'inconvenience': 1, 'super': 1, 'bothered': 2, 'lines': 1, 'sreekaryam': 1, 'caused': 1, 'reason': 1, 'cant': 1, 'came': 1, 'man': 1, 'proper': 1, 'one': 1, 'forget': 1, '23': 1, 'service': 5, 'inform': 1, 'hoping': 1, 'travellers': 1, 'public': 3, 'past': 1, 'get': 1, 'advice': 1, 'railway': 2, 'mukkam': 1, 'face': 1, 'lack': 2, 'action': 2, 'conductor': 1, 'bus': 14, 'problem': 3, 'change': 1, 'kottukunnam': 1, 'destination': 1, 'kl157912': 1, 'area': 2, 'seat': 4, 'use': 1, 'kumarakam': 2, 'almost': 1, 'make': 1, 'class': 1, 'people': 3, 'needful': 1, 'six': 1, 'kindly': 1, 'arrive': 1, 'passengers': 3, 'found': 1, 'pasengers': 1, 'authorites': 1, 'never': 1, 'word': 1, '730': 1, 'reserved': 2, 'night': 1, 'venjaramood': 1, 'onky': 1, 'dont': 2, 'nadakkavu': 1, 'convenient': 1, 'college': 4, 'frequently': 1, 'cancelled': 1, 'via': 1, 'sometimes': 1, 'see': 2, 'school': 1, 'given': 1, 'others': 1, 'add': 1, 'trivandrum': 1, 'male': 1, 'town': 1, 'week': 1, 'would': 4, 'locations': 1, 'ksrtc': 8, 'depend': 1, 'crossing': 1, 'seats': 4, 'driver': 2, '2': 1, 'vehicles': 1, 'please': 1, 'lots': 2, 'argue': 1, 'going': 2, 'tired': 1, 'helpful': 2, 'damage': 1, 'hours': 2, 'kulathurstudents': 1, 'transportation': 1, 'request': 2, 'effective': 1, 'risk': 1, 'behave': 1, 'car': 4, 'provide': 2, 'several': 1, 'females': 1, 'usually': 1, '25': 1, 'buseskindly': 1, 'trivandrumidukkikattappana': 1, 'totally': 1, 'intended': 1, 'feelplease': 1, 'rudely': 1, 'ernakulam': 1, 'percent': 1, 'us': 1, 'kattakada': 1, 'choose': 1, 'hit': 1, 'got': 2, 'travelled': 1, 'stop': 4, 'fully': 1, 'ignoring': 1, 'number': 2, 'time': 4, 'stopping': 1, 'student': 1, 'experienced': 1, 'rashly': 1, 'well': 1, 'kottayam': 1, 'facing': 1, 'reaching': 1, 'rural': 1, 'drove': 1, 'muvattupuza': 1, 'using': 1, 'leave': 1, 'stopped': 1, 'raining': 1, 'traveller': 1, 'present': 1, 'stationso': 1, 'solely': 1, 'femalesas': 1, 'city': 4, 'right': 1, 'difficulty': 1, 'busy': 1, 'access': 1, 'much': 1, 'mid': 1, 'whole': 1, 'ymcacross': 1, 'keep': 1}\n",
      "\n",
      "\n",
      " PWD Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " KSRTC Count \n",
      "\n",
      "\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      " Water Freq newwwwwwwwww\n",
      "{'take': 6, 'second': 1, 'january': 1, 'pachayath': 1, 'erattakalangu': 1, 'large': 1, 'month': 1, 'leaking': 3, 'portion': 1, 'low': 1, 'sources': 1, '4': 1, 'also': 4, 'leakage': 4, 'progressthis': 1, 'error': 1, 'water': 58, 'trapped': 1, 'always': 1, 'difficulties': 1, 'therepeople': 1, 'pipeline': 2, 'resource': 1, 'huge': 3, 'setup': 1, 'awkwardly': 1, 'neighbouring': 1, 'condition': 1, 'hardly': 1, 'distances': 1, 'taps': 1, 'enough': 1, 'side': 1, 'kuttanad': 1, 'cabin': 1, 'rs': 1, 'neighborhood': 1, 'systems': 1, 'able': 1, 'authorised': 1, 'malayinkeezhu': 1, 'future': 1, 'meter': 4, 'si': 1, 'good': 1, 'useand': 1, 'additional': 1, 'frustrating': 1, 'flowing': 3, 'bill': 7, 'need': 2, 'authorities': 1, 'like': 1, 'system': 1, 'worse': 1, 'corporation': 1, 'human': 1, 'complaints': 1, 'liters': 1, 'regular': 1, 'pumping': 1, 'steal': 1, 'road': 4, 'remote': 1, 'mg': 1, 'weeks': 2, 'houses': 2, 'note': 1, 'bills': 2, 'fix': 1, 'disturbed': 1, 'remains': 1, 'big': 1, 'rupees': 1, 'concerning': 1, 'fetch': 1, 'affected': 1, 'inform': 1, 'gardens': 1, 'drinking': 7, 'public': 3, 'situated': 1, 'nights': 1, 'date': 1, 'action': 5, 'thankful': 1, 'two': 3, 'without': 1, 'taluk': 1, 'creates': 1, 'tiled': 1, 'vanchiyoor': 1, 'office': 2, 'loction': 1, 'area': 3, 'mains': 1, 'since': 2, 'available': 1, 'people': 5, 'credentials': 1, 'foul': 1, '20000': 2, 'kindly': 3, 'storage': 2, 'exiss': 1, 'kwa': 1, 'connector': 1, 'kerala': 1, 'many': 1, 'eravipuram': 1, 'humbly': 1, 'dont': 1, '2017': 1, 'amma': 1, 'instances': 1, 'kuttanadu': 1, 'near': 4, 'issue': 1, 'needs': 2, 'approx': 1, 'glue': 1, 'early': 1, 'made': 1, 'summer': 3, 'past': 2, 'district': 1, 'sub': 1, 'staying': 1, 'kochi': 2, 'try': 1, 'get': 4, 'months': 2, 'division': 1, 'distribution': 1, 'account': 2, 'problem': 6, 'aggravating': 1, 'information': 2, 'etc': 1, 'tank': 1, 'iform': 1, 'pipe': 7, '10': 2, 'damaged': 1, 'every': 4, 'building': 1, 'website': 2, 'paying': 1, 'stayed': 2, 'personally': 1, 'provide': 1, 'queue': 1, 'solving': 1, 'idle': 1, 'accumulated': 1, 'consumption': 1, 'walk': 2, 'residents': 1, 'fact': 1, 'smell': 1, 'front': 1, 'idukki': 1, 'tap': 1, '100': 1, 'mostly': 1, 'scarcity': 5, 'possible': 1, 'requesting': 1, 'edathua': 1, 'restore': 1, 'fully': 1, 'things': 1, 'pay': 2, 'palm': 1, 'number': 2, 'reading': 1, 'pressure': 1, 'facing': 6, 'house': 6, 'informing': 1, '5': 1, 'resulted': 1, 'connection': 8, 'shortage': 6, 'totally': 1, 'engineer': 1, 'given': 1, 'houseconsumer': 1, 'society': 1, 'supply': 15, 'new': 1, 'bad': 1, 'mentioned': 1, 'everytime': 1, 'onwards': 1, 'last': 5, 'frequent': 1, 'tackle': 1, 'severe': 2, 'mud': 1, 'staff': 1, 'may': 3, 'unrepaired': 1, 'way': 1, 'amount': 1, 'look': 3, 'thread': 2, 'wet': 1, 'use': 1, '792': 1, 'dues': 1, 'pipewhich': 1, 'tried': 1, 'login': 2, 'per': 2, '3': 4, 'causes': 1, 'lives': 1, 'residential': 1, 'necessary': 5, 'rented': 1, 'monthsin': 1, 'days': 4, 'consumer': 4, 'recorded': 1, 'standing': 1, 'make': 1, 'kollam': 1, 'even': 1, 'caped': 1, 'capacity': 2, 'entered': 1, 'insufficient': 1, 'services': 1, 'message': 1, 'rectify': 1, 'upon': 1, 'morning': 1, 'kovalam': 3, 'previous': 1, 'rid': 1, 'alappuzha': 1, 'actions': 1, 'came': 1, 'waterour': 1, 'noticed': 1, 'areas': 4, 'day': 3, 'unfits': 1, 'late': 1, 'residing': 2, 'payment': 4, 'closed': 2, 'daily': 1, 'compound': 1, 'time': 4, 'therefore': 2, 'domestic': 1, 'cooking': 1, 'panchayat': 1, 'appox': 1, 'junction': 1, 'small': 1, 'work': 1, 'due': 1, 'stealing': 1, 'charge': 1, 'well': 1, 'one': 2, 'line': 1, 'punnakunnam': 1, 'four': 1, 'thrissur': 2, 'fill': 1, 'attuparambil': 1, 'name': 1, 'mudmix': 1, 'repair': 1, 'told': 1, 'ilters': 1, 'already': 1, 'rural': 1, 'bus': 1, 'recieved': 1, 'thus': 1, 'no818eda': 1, 'online': 1, 'september': 1, 'called': 1, 'puthoor': 1, 'matter': 2, 'kunnathuvathucal': 1, 'till': 1, 'taken': 1, 'hotel': 3, 'waterwe': 1, 'ready': 1, 'wrongly': 1, 'member': 1, 'lengthy': 1, '471eda': 1, 'daytoday': 1, 'waterworks': 1, 'web': 1, 'consuming': 1, 'e': 1, 'writing': 1, 'records': 1, 'mosqitos': 1, 'via': 1, 'bathroom': 1, 'know': 1, 'sealed': 3, 'destroy': 1, 'basic': 1, 'trying': 1, 'wasted': 1, 'authority': 4, 'trouble': 1, 'assistant': 1, 'week': 3, 'connected': 1, 'unauthorised': 1, 'growing': 1, 'couple': 1, 'locality': 4, 'year': 1, 'vazhathope': 1, 'complete': 1, 'needful': 1, '2': 1, 'please': 7, 'beach': 2, 'leads': 1, 'hilly': 1, 'shall': 1, 'location': 1, 'acute': 1, 'broken': 1, 'keep': 1, 'replace': 1, 'request': 4, 'midnight': 1, 'site': 1, 'pulinkunnu': 1, 'unavailability': 1, 'usually': 1, 'cause': 1, 'stand': 1, 'reported': 1, 'check': 1, 'bridge': 1, 'transaction': 2, 'great': 3, 'force': 1, 'wastage': 1, 'cap': 1, 'set': 1, 'filled': 1, 'grove': 1, 'schools': 1, 'steps': 1, 'utility': 1, 'details': 1, 'installed': 1, 'growingseveral': 1, 'purposes': 1, 'loosing': 1, 'triivandrum': 1, 'immediate': 1, 'athority': 1, 'still': 1, 'seriously': 1, 'city': 1, '1': 1, 'much': 2, 'getting': 6, 'regarding': 1, 'state': 1}\n",
      "['water', 'supply', 'connection', 'please', 'pipe', 'drinking', 'bill', 'take', 'shortage', 'problem', 'house', 'getting', 'facing', 'scarcity', 'people', 'necessary', 'last', 'action', 'time', 'road', 'request', 'payment', 'near', 'meter', 'locality', 'leakage', 'get', 'every', 'days', 'consumer', 'authority', 'areas', 'also', '3', 'week', 'two', 'summer', 'sealed', 'public', 'may', 'look', 'leaking', 'kovalam', 'kindly', 'huge', 'hotel', 'great', 'flowing', 'day', 'area', 'weeks', 'website', 'walk', 'transaction', 'thrissur', 'thread', 'therefore', 'storage', 'stayed', 'since', 'severe', 'residing', 'pipeline', 'per', 'pay', 'past', 'one', 'office', 'number', 'needs', 'need', 'much', 'months', 'matter', 'login', 'kochi', 'information', 'houses', 'closed', 'capacity', 'bills', 'beach', 'account', '20000', '10', 'year', 'wrongly', 'writing', 'worse', 'work', 'without', 'wet', 'well', 'web', 'way', 'waterworks', 'waterwe', 'waterour', 'wasted', 'wastage', 'via', 'vazhathope', 'vanchiyoor', 'utility', 'usually', 'useand', 'use', 'upon', 'unrepaired', 'unfits', 'unavailability', 'unauthorised', 'trying', 'try', 'trouble', 'triivandrum', 'tried', 'trapped', 'totally', 'told', 'till', 'tiled', 'thus', 'things', 'therepeople', 'thankful', 'taps', 'tap', 'tank', 'taluk', 'taken', 'tackle', 'systems', 'system', 'sub', 'still', 'steps', 'stealing', 'steal', 'staying', 'state', 'standing', 'stand', 'staff', 'sources', 'solving', 'society', 'smell', 'small', 'situated', 'site', 'side', 'si', 'shall', 'setup', 'set', 'services', 'seriously', 'september', 'second', 'schools', 'rural', 'rupees', 'rs', 'rid', 'resulted', 'restore', 'resource', 'residents', 'residential', 'requesting', 'reported', 'replace', 'repair', 'rented', 'remote', 'remains', 'regular', 'regarding', 'rectify', 'records', 'recorded', 'recieved', 'ready', 'reading', 'queue', 'puthoor', 'purposes', 'punnakunnam', 'pumping', 'pulinkunnu', 'provide', 'progressthis', 'previous', 'pressure', 'possible', 'portion', 'pipewhich', 'personally', 'paying', 'panchayat', 'palm', 'pachayath', 'onwards', 'online', 'noticed', 'note', 'no818eda', 'nights', 'new', 'neighbouring', 'neighborhood', 'needful', 'name', 'mudmix', 'mud', 'mostly', 'mosqitos', 'morning', 'monthsin', 'month', 'midnight', 'mg', 'message', 'mentioned', 'member', 'many', 'malayinkeezhu', 'make', 'mains', 'made', 'low', 'loosing', 'loction', 'location', 'lives', 'liters', 'line', 'like', 'lengthy', 'leads', 'late', 'large', 'kwa', 'kuttanadu', 'kuttanad', 'kunnathuvathucal', 'kollam', 'know', 'kerala', 'keep', 'junction', 'january', 'issue', 'insufficient', 'instances', 'installed', 'informing', 'inform', 'immediate', 'ilters', 'iform', 'idukki', 'idle', 'humbly', 'human', 'houseconsumer', 'hilly', 'hardly', 'growingseveral', 'growing', 'grove', 'good', 'glue', 'given', 'gardens', 'future', 'fully', 'frustrating', 'front', 'frequent', 'four', 'foul', 'force', 'fix', 'filled', 'fill', 'fetch', 'fact', 'exiss', 'everytime', 'even', 'etc', 'error', 'eravipuram', 'erattakalangu', 'entered', 'enough', 'engineer', 'edathua', 'early', 'e', 'dues', 'due', 'dont', 'domestic', 'division', 'disturbed', 'district', 'distribution', 'distances', 'difficulties', 'details', 'destroy', 'daytoday', 'date', 'damaged', 'daily', 'credentials', 'creates', 'couple', 'corporation', 'cooking', 'consumption', 'consuming', 'connector', 'connected', 'condition', 'concerning', 'compound', 'complete', 'complaints', 'city', 'check', 'charge', 'causes', 'cause', 'caped', 'cap', 'came', 'called', 'cabin', 'bus', 'building', 'broken', 'bridge', 'big', 'bathroom', 'basic', 'bad', 'awkwardly', 'available', 'authorities', 'authorised', 'attuparambil', 'athority', 'assistant', 'approx', 'appox', 'amount', 'amma', 'always', 'already', 'alappuzha', 'aggravating', 'affected', 'additional', 'acute', 'actions', 'accumulated', 'able', '792', '5', '471eda', '4', '2017', '2', '100', '1']\n",
      "\n",
      "\n",
      "KEYWORDS  WATER\n",
      "\n",
      "\n",
      "[['water', 'supply', 'connection', 'please', 'pipe']]\n",
      "\n",
      "\n",
      " PWD Freq newwwwwwwwww\n",
      "{'take': 7, 'vayal': 1, 'occupied': 1, 'drivers': 11, 'claims': 1, 'activity': 1, 'january': 1, 'rescheduling': 1, 'height': 3, 'low': 2, 'situations': 1, 'something': 2, 'less': 1, 'cottton': 1, 'rushy': 1, 'water': 3, 'always': 2, 'resident': 1, 'process': 2, 'huge': 1, 'mathilakam': 1, 'handle': 1, 'taking': 1, 'condition': 10, 'find': 1, 'speed': 2, 'traveller': 1, 'almost': 1, 'health': 2, 'running': 3, 'repairing': 1, 'dependable': 1, 'accidents': 10, 'days': 2, 'kwh': 1, 'digged': 2, 'misbehaviour': 1, 'ultimately': 1, 'tire': 1, 'actually': 1, 'markings': 1, 'blocking': 1, 'earlier': 1, 'block': 1, 'etcthe': 1, 'thadoli': 1, 'complexes': 1, 'good': 1, 'students': 3, 'recently': 3, 'driver': 3, 'highway': 1, 'nation': 1, '23': 1, 'half': 1, 'kattakkada': 1, 'toilets': 1, 'walking': 1, 'hidden': 1, 'route': 3, 'femalesthen': 1, 'regular': 1, 'removed': 1, 'businesses': 1, 'control': 2, 'loose': 1, 'completely': 1, 'road': 66, 'sufficient': 2, 'telephone': 1, 'poovathumkadavu': 1, 'india': 3, 'lines': 1, 'register': 1, 'contract': 1, 'emerge': 1, 'potential': 2, 'reimbursement': 1, 'companies': 1, 'tax': 3, 'service': 5, 'manathoor': 1, 'inform': 1, 'thampanoor': 1, 'public': 7, 'existing': 2, 'amenities': 1, 'card': 2, 'two': 2, 'without': 2, 'taluk': 1, 'notnot': 1, 'making': 1, 'shops': 3, 'office': 1, 'schedule': 1, 'wants': 1, 'attitude': 1, 'retarring': 1, 'class': 1, 'aggravates': 1, 'roads': 30, 'consideration': 2, 'motorist': 1, 'biggest': 1, 'many': 7, 'reserved': 2, 'shack': 1, 'venjaramood': 1, 'dont': 4, 'created': 2, 'wear': 2, 'technopark': 2, 'shattered': 1, 'tender': 1, 'pwd': 3, 'mr': 1, 'maintenance': 5, 'gate': 1, 'cancelled': 1, 'aware': 1, 'steps': 1, 'holes': 2, 'trucks': 1, 'district': 3, 'sirmadam': 1, 'estate': 1, 'try': 1, 'ksrtc': 8, 'requires': 1, 'prone': 1, 'repair': 3, 'months': 2, 'landslide': 1, 'bothers': 1, 'vehicles': 9, 'transport': 6, 'km': 1, 'tear': 2, 'argue': 1, 'manorama': 1, 'miss': 1, 'recent': 1, 'boards': 1, 'pine': 1, 'kallingal': 2, 'ran': 1, 'risk': 2, 'defects': 1, 'valakom': 1, 'behaving': 1, 'provide': 2, 'converted': 1, 'long': 1, 'directly': 1, 'trivandrumidukkikattappana': 1, 'construction': 2, 'feelplease': 1, 'saved': 1, 'repairs': 1, 'create': 2, '100': 1, 'safer': 1, 'kattakada': 1, 'sir': 4, 'possible': 2, 'got': 3, 'bus': 16, 'length': 2, 'fully': 2, 'number': 4, 'rashly': 1, 'well': 3, 'facing': 1, 'innocent': 1, 'rural': 2, 'connection': 1, 'driven': 1, 'given': 3, 'drainage': 2, 'immediatelythe': 1, 'masalas': 1, 'restaurants': 1, 'raised': 1, 'fish': 1, 'snacks': 1, 'rudely': 1, 'ymcacross': 1, 'mud': 1, 'etcetc': 1, 'phase': 1, 'tractors': 1, 'way': 2, 'tarring': 2, 'pot': 2, 'rentals': 1, 'amount': 3, 'cars': 2, 'kovil': 1, 'major': 1, 'side': 3, 'traffic': 9, 'pvc': 1, 'suddenly': 1, 'evening': 1, 'taskirequests': 1, 'signal': 1, 'away': 1, 'kumarakam': 2, 'chances': 1, 'unauthorized': 2, 'conductor': 1, 'clean': 2, 'ask': 1, 'example': 1, 'suffering': 2, 'overspeeding': 2, 'shacks': 1, 'rainy': 2, 'carelessly': 1, 'lake': 1, 'things': 2, 'stopping': 1, 'miserable': 1, 'even': 7, 'pits': 1, 'limit': 2, '12m': 1, 'limited': 1, 'commute': 2, 'fast': 2, 'systems': 1, 'pity': 1, 'continuing': 1, 'difficult': 4, 'country': 2, 'fall': 1, 'tea': 1, 'ambadi': 2, 'lacs': 1, 'work': 2, 'charge': 1, 'thazha': 1, 'day': 6, 'late': 3, 'around': 4, 'visibility': 1, 'problems': 3, 'learnt': 1, 'till': 1, 'creating': 1, 'potholes': 5, 'impeding': 1, 'layman': 1, 'twowheelers': 1, 'shed': 3, 'implement': 1, 'light': 1, 'using': 1, 'technology': 2, 'done': 1, 'solve': 1, 'inconvenience': 1, 'super': 1, 'meter': 1, 'unexpected': 1, 'hazards': 2, 'caused': 1, 'busesatleast': 1, 'cant': 2, 'edge': 1, 'ramamangalam': 1, 'basic': 1, 'name': 1, 'harsh': 1, 'laws': 1, 'hoping': 1, 'high': 4, 'raining': 1, 'kochi': 1, 'get': 2, 'hitting': 3, 'lane': 1, 'media': 1, 'correct': 1, 'lack': 4, 'driving': 2, 'know': 6, 'slippery': 1, 'completion': 1, 'resurfaced': 1, 'bottom': 1, 'kl157912': 1, 'prior': 1, 'night': 1, 'leave': 1, 'faster': 1, 'six': 1, 'roots': 1, 'passengers': 5, 'petty': 2, 'today': 1, 'needed': 1, 'lots': 2, 'reckless': 1, 'maintained': 4, 'collected': 2, 'living': 2, 'convenient': 1, 'various': 1, 'threat': 1, 'compound': 3, 'constituency': 1, 'modernization': 1, 'wall': 6, 'via': 1, 'accident': 2, 'notice': 2, 'see': 4, 'buildings': 1, 'common': 2, 'prices': 1, 'others': 2, 'malappuram': 1, 'trivandrum': 3, 'canal': 1, 'congestion': 3, 'week': 1, 'channels': 1, 'selling': 2, 'outlet': 1, 'aid': 1, 'jam': 1, '2': 1, 'manually': 1, 'lady': 1, 'initiate': 1, 'tent': 2, 'helpful': 3, 'result': 2, 'damage': 6, 'hours': 2, 'kulathurstudents': 1, 'new': 1, 'related': 1, 'chipping': 1, 'timeconsuming': 1, 'arookutty': 1, 'car': 5, 'starting': 1, 'properly': 3, 'takes': 1, 'mtr': 2, 'minimum': 1, 'left': 1, 'pothole': 2, 'distis': 1, 'underground': 1, 'bridge': 3, 'mla': 1, 'ss': 1, 'great': 1, 'goes': 1, 'ie': 1, 'us': 1, 'took': 1, 'progressing': 1, 'hit': 2, 'nagar': 2, 'time': 5, 'help': 1, 'student': 2, 'last': 5, 'width': 2, 'nature': 1, 'bribe': 1, 'caring': 1, 'sometimes': 2, 'mid': 1, 'permissions': 1, 'requested': 2, 'peruvammuzhy': 1, 'stopped': 3, '300': 1, 'follow': 1, 'located': 1, 'money': 2, 'still': 2, '12th': 1, 'city': 8, 'right': 4, 'difficulty': 1, 'isnt': 1, 'crossings': 1, '1': 2, 'tar': 1, 'barrier': 1, 'much': 3, 'bear': 1, 'full': 2, 'ladies': 1, 'aroor': 1, 'dangerous': 1, 'negligence': 1, 'delivery': 1, 'vendors': 1, 'indiavision': 1, 'roadside': 1, 'busiest': 1, 'large': 2, 'station': 1, 'back': 3, 'photos': 1, 'access': 1, 'local': 1, 'passing': 1, 'cocanuts': 1, 'instead': 1, 'pedestrians': 3, 'base': 1, 'year': 3, 'chithravila': 1, 'increase': 3, 'licence': 1, 'also': 9, 'monthsafter': 1, 'arrange': 1, '15': 2, 'reduced': 1, 'towards': 6, 'atleast': 2, 'lax': 1, 'would': 5, 'none': 1, 'solely': 1, 'effected': 1, 'safety': 3, 'equality': 1, 'years': 2, 'kills': 1, 'willing': 1, 'corruption': 1, 'business': 2, 'unpaved': 1, 'causing': 3, 'rising': 1, 'shortcuts': 1, 'undue': 1, 'dashed': 1, 'flow': 3, 'resulting': 1, 'pregnant': 1, 'shoe': 1, 'used': 3, 'earliest': 1, 'repaired': 2, 'serious': 1, 'like': 7, 'brutally': 1, 'seek': 1, 'hill': 1, 'give': 2, 'suitable': 1, 'filled': 2, 'directed': 1, 'continue': 1, 'politicians': 1, 'idea': 1, 'news': 2, 'unwary': 1, 'reduce': 1, 'constructing': 1, 'shortcut': 1, 'confirm': 1, 'busesplease': 1, 'behind': 1, 'houses': 1, 'feet': 2, 'extent': 1, 'sreekaryam': 4, 'reason': 2, 'pose': 1, 'dear': 1, 'fix': 1, 'effect': 1, 'proper': 7, 'fuel': 2, 'big': 1, 'per': 2, 'types': 1, 'contributions': 1, 'reasonable': 1, 'real': 1, 'hope': 2, 'past': 2, 'conditions': 2, 'may': 3, 'transportation': 3, 'retar': 1, 'street': 2, 'face': 1, 'concreated': 1, 'action': 7, 'increases': 1, 'kottukunnam': 1, 'broken': 2, 'area': 6, 'seat': 4, 'attached': 1, 'showrooms': 1, 'make': 6, 'since': 1, 'physical': 1, 'bikers': 1, 'kindly': 4, 'arrive': 1, 'kottakkal': 1, 'pasengers': 1, '25': 1, 'kerala': 3, 'toll': 3, 'alloted': 1, 'thannippara': 1, 'onky': 1, 'railway': 4, 'times': 3, 'lot': 3, 'issue': 1, 'prevalent': 1, 'law': 2, 'attention': 2, 'permits': 1, 'school': 1, 'streets': 1, 'direction': 2, 'crew': 1, 'attinkuzhy': 1, 'male': 1, 'trend': 1, 'kind': 1, 'depend': 1, 'town': 2, 'seats': 4, 'advice': 1, 'puzha': 1, 'problem': 6, 'increasing': 1, 'etc': 2, 'going': 6, 'danger': 1, 'season': 2, 'damaged': 4, 'every': 3, 'underlying': 1, 'koyilandy': 1, 'rules': 2, 'issues': 2, 'locations': 1, 'sudden': 1, 'highspeed': 1, 'date': 1, 'calicut': 1, 'newly': 1, 'several': 2, 'important': 1, 'thanks': 1, 'buseskindly': 1, 'include': 1, 'intended': 1, 'usually': 1, 'retarr': 1, 'carts': 1, 'choose': 1, 'cause': 3, 'place': 1, 'nearby': 1, 'stop': 6, 'sign': 1, 'pay': 1, 'tared': 1, 'peakhour': 1, 'waiting': 2, 'old': 1, 'boarder': 1, 'kottayam': 1, 'view': 1, 'reaching': 1, 'part': 1, 'pathholes': 1, 'submitted': 1, 'provision': 1, 'villages': 2, 'present': 1, 'authority': 1, 'facility': 1, '730': 1, 'busy': 1, 'bad': 3, 'withing': 1, 'cyclists': 1, 'frequent': 1, 'whole': 2, 'muvattupzha': 1, 'liability': 1, 'workers': 1, 'travel': 3, 'connecting': 1, 'life': 1, 'chance': 1, 'venjaramoodu': 1, 'pan': 1, 'surprise': 1, 'use': 2, 'footpath': 2, 'balance': 2, 'constructed': 2, 'kazhakkuttam': 1, 'injury': 1, 'enforcement': 1, 'buses': 10, 'services': 4, 'factors': 1, '3': 3, 'complaint': 1, 'causes': 1, 'insurance': 1, 'heavy': 2, 'destroyed': 1, 'evict': 1, 'necessary': 6, 'vehicle': 2, 'nayadan': 1, 'busses': 2, 'urgent': 1, 'footwalk': 1, 'depending': 1, 'value': 1, 'moreover': 1, 'increased': 2, 'ignoring': 1, 'hopefully': 1, 'standing': 1, 'travelling': 3, 'drove': 1, 'establishments': 3, 'kumar': 1, 'growing': 2, 'id': 1, 'income': 1, 'thodupuzha': 1, 'little': 1, 'upon': 1, 'themgod': 1, '40': 1, 'kotooli': 1, 'wayside': 1, 'bothered': 2, 'came': 1, '13th': 2, 'worst': 1, 'noticed': 1, 'areas': 4, 'person': 1, 'ordinary': 1, 'businessmen': 2, 'daily': 4, 'nippol': 1, 'despite': 1, 'pitfalls': 1, 'karukaputhurpallipadamthichur': 1, 'size': 1, 'conductors': 1, 'first': 1, 'least': 2, 'reach': 4, 'controlled': 1, 'junction': 1, 'intersection': 1, 'offices': 1, 'travelyesterday': 1, 'due': 8, 'next': 1, 'flooded': 1, 'plan': 1, 'pattazhy': 1, 'cables': 1, 'passenger': 2, 'alappuzha': 1, 'actions': 2, 'heavyweight': 1, 'illustrate': 1, 'traders': 2, 'man': 1, 'travelplease': 1, 'build': 1, 'maniykumpparakarimkunnam': 1, 'liquiors': 1, 'forget': 1, 'spend': 1, 'predict': 1, '5': 1, 'citizens': 2, 'kids': 2, 'travellers': 1, 'latest': 1, 'crossing': 3, 'changes': 1, 'point': 1, 'worthy': 1, 'mukkam': 1, 'unpredictable': 1, 'beautification': 1, 'steady': 1, 'safe': 1, 'sector': 1, 'kolenchery': 1, 'change': 1, 'morning': 3, 'go': 1, 'avoid': 2, 'intervention': 1, 'choondy': 1, 'digital': 1, 'gst': 1, 'needful': 3, 'makes': 3, 'pathetic': 1, 'toyota': 1, 'visit': 1, 'found': 1, 'never': 1, 'word': 1, 'responsible': 1, 'indifferent': 1, 'paved': 1, 'knows': 1, 'entering': 1, '500': 1, 'mangotu': 1, 'violation': 1, 'nadakkavu': 1, 'consider': 1, '6': 1, 'losses': 1, 'parking': 1, 'everybody': 1, 'college': 4, 'duration': 1, 'frequently': 1, 'system': 1, 'timings': 1, 'especially': 1, 'planning': 1, 'melattumoozhy': 1, 'maple': 1, 'diameter': 1, 'pathanapurm': 1, 'add': 1, 'immediately': 1, 'asianet': 1, 'heavily': 1, 'othukkungal': 1, 'bikes': 1, 'pop': 1, 'appeal': 1, 'open': 1, 'locality': 1, 'countless': 1, 'one': 4, 'please': 9, 'government': 4, 'booths': 1, 'leads': 3, 'tired': 1, 'muthambioorallur': 1, 'destination': 1, 'keep': 1, 'people': 7, 'request': 2, 'centers': 1, 'effective': 1, 'behave': 1, 'certain': 1, 'females': 1, 'violations': 1, 'works': 4, 'collectors': 1, 'totally': 1, 'crowed': 1, 'ernakulam': 2, 'pala': 1, 'percent': 1, 'current': 1, 'gutter': 2, 'leveled': 1, 'travelled': 1, 'illegal': 1, 'employees': 2, 'quality': 2, 'dug': 1, 'experienced': 1, 'early': 3, 'fee': 1, 'letting': 1, 'poor': 4, 'inescapable': 1, 'muvattupuza': 1, 'extremly': 1, 'immediate': 1, 'authorites': 1, 'losing': 1, 'stationso': 1, 'femalesas': 1, 'palakkad': 1, 'situation': 1, 'small': 1, 'middle': 3, 'department': 3, 'keshavadasapuram': 1, 'required': 1, 'regarding': 1, 'state': 1}\n",
      "['road', 'roads', 'bus', 'drivers', 'condition', 'buses', 'accidents', 'vehicles', 'traffic', 'please', 'also', 'ksrtc', 'due', 'city', 'take', 'public', 'proper', 'people', 'many', 'like', 'even', 'action', 'wall', 'transport', 'towards', 'stop', 'problem', 'necessary', 'make', 'know', 'going', 'day', 'damage', 'area', 'would', 'time', 'service', 'potholes', 'passengers', 'maintenance', 'last', 'car', 'works', 'sreekaryam', 'sir', 'services', 'see', 'seats', 'seat', 'right', 'reach', 'railway', 'poor', 'one', 'number', 'maintained', 'lack', 'kindly', 'high', 'government', 'dont', 'difficult', 'damaged', 'daily', 'college', 'around', 'areas', 'year', 'well', 'water', 'used', 'trivandrum', 'travelling', 'travel', 'transportation', 'toll', 'times', 'tax', 'students', 'stopped', 'side', 'shops', 'shed', 'safety', 'running', 'route', 'repair', 'recently', 'pwd', 'properly', 'problems', 'pedestrians', 'needful', 'much', 'morning', 'middle', 'may', 'makes', 'lot', 'leads', 'late', 'kerala', 'india', 'increase', 'hitting', 'helpful', 'height', 'got', 'given', 'flow', 'every', 'establishments', 'early', 'driver', 'district', 'department', 'crossing', 'congestion', 'compound', 'causing', 'cause', 'bridge', 'bad', 'back', 'amount', '3', 'years', 'work', 'without', 'width', 'whole', 'wear', 'way', 'waiting', 'villages', 'vehicle', 'use', 'unauthorized', 'two', 'traders', 'town', 'things', 'tent', 'technopark', 'technology', 'tear', 'tarring', 'sufficient', 'suffering', 'student', 'street', 'still', 'speed', 'sometimes', 'something', 'several', 'selling', 'season', 'rural', 'rules', 'risk', 'result', 'reserved', 'requested', 'request', 'repaired', 'reason', 'rainy', 'quality', 'provide', 'process', 'pothole', 'potential', 'pot', 'possible', 'petty', 'per', 'past', 'passenger', 'overspeeding', 'others', 'notice', 'news', 'nagar', 'mtr', 'months', 'money', 'low', 'lots', 'living', 'limit', 'length', 'least', 'law', 'large', 'kumarakam', 'kids', 'kallingal', 'issues', 'increased', 'hours', 'hope', 'holes', 'hit', 'heavy', 'health', 'hazards', 'gutter', 'growing', 'give', 'get', 'fully', 'full', 'fuel', 'footpath', 'filled', 'feet', 'fast', 'existing', 'etc', 'ernakulam', 'employees', 'driving', 'drainage', 'direction', 'digged', 'days', 'created', 'create', 'country', 'control', 'construction', 'constructed', 'consideration', 'conditions', 'commute', 'common', 'collected', 'clean', 'citizens', 'cars', 'card', 'cant', 'busses', 'businessmen', 'business', 'broken', 'bothered', 'balance', 'avoid', 'attention', 'atleast', 'ambadi', 'always', 'actions', 'accident', '15', '13th', '1', 'ymcacross', 'worthy', 'worst', 'workers', 'word', 'withing', 'willing', 'week', 'wayside', 'wants', 'walking', 'visit', 'visibility', 'violations', 'violation', 'view', 'via', 'venjaramoodu', 'venjaramood', 'vendors', 'vayal', 'various', 'value', 'valakom', 'usually', 'using', 'us', 'urgent', 'upon', 'unwary', 'unpredictable', 'unpaved', 'unexpected', 'undue', 'underlying', 'underground', 'ultimately', 'types', 'twowheelers', 'try', 'trucks', 'trivandrumidukkikattappana', 'trend', 'travelyesterday', 'travelplease', 'travellers', 'traveller', 'travelled', 'tractors', 'toyota', 'totally', 'took', 'toilets', 'today', 'tired', 'tire', 'timings', 'timeconsuming', 'till', 'threat', 'thodupuzha', 'themgod', 'thazha', 'thannippara', 'thanks', 'thampanoor', 'thadoli', 'tender', 'telephone', 'tea', 'taskirequests', 'tared', 'tar', 'taluk', 'taking', 'takes', 'systems', 'system', 'surprise', 'super', 'suitable', 'suddenly', 'sudden', 'submitted', 'streets', 'stopping', 'steps', 'steady', 'stationso', 'station', 'state', 'starting', 'standing', 'ss', 'spend', 'solve', 'solely', 'snacks', 'small', 'slippery', 'size', 'six', 'situations', 'situation', 'sirmadam', 'since', 'signal', 'sign', 'showrooms', 'shortcuts', 'shortcut', 'shoe', 'shattered', 'shacks', 'shack', 'serious', 'seek', 'sector', 'school', 'schedule', 'saved', 'safer', 'safe', 'rushy', 'rudely', 'roots', 'roadside', 'rising', 'retarring', 'retarr', 'retar', 'resurfaced', 'resulting', 'restaurants', 'responsible', 'resident', 'rescheduling', 'requires', 'required', 'repairs', 'repairing', 'rentals', 'removed', 'related', 'reimbursement', 'regular', 'register', 'regarding', 'reduced', 'reduce', 'reckless', 'recent', 'reasonable', 'real', 'reaching', 'rashly', 'ran', 'ramamangalam', 'raised', 'raining', 'pvc', 'puzha', 'provision', 'prone', 'progressing', 'prior', 'prices', 'prevalent', 'present', 'pregnant', 'predict', 'pose', 'pop', 'poovathumkadavu', 'politicians', 'point', 'planning', 'plan', 'place', 'pity', 'pits', 'pitfalls', 'pine', 'physical', 'photos', 'phase', 'peruvammuzhy', 'person', 'permits', 'permissions', 'percent', 'peakhour', 'pay', 'paved', 'pattazhy', 'pathholes', 'pathetic', 'pathanapurm', 'passing', 'pasengers', 'part', 'parking', 'pan', 'palakkad', 'pala', 'outlet', 'othukkungal', 'ordinary', 'open', 'onky', 'old', 'offices', 'office', 'occupied', 'notnot', 'noticed', 'none', 'nippol', 'night', 'next', 'newly', 'new', 'never', 'negligence', 'needed', 'nearby', 'nayadan', 'nature', 'nation', 'name', 'nadakkavu', 'muvattupzha', 'muvattupuza', 'muthambioorallur', 'mukkam', 'mud', 'mr', 'motorist', 'moreover', 'monthsafter', 'modernization', 'mla', 'miss', 'miserable', 'misbehaviour', 'minimum', 'mid', 'meter', 'melattumoozhy', 'media', 'mathilakam', 'masalas', 'markings', 'maple', 'manually', 'manorama', 'maniykumpparakarimkunnam', 'mangotu', 'manathoor', 'man', 'male', 'malappuram', 'making', 'major', 'losses', 'losing', 'loose', 'long', 'locations', 'located', 'locality', 'local', 'little', 'liquiors', 'lines', 'limited', 'light', 'life', 'licence', 'liability', 'leveled', 'letting', 'less', 'left', 'leave', 'learnt', 'layman', 'lax', 'laws', 'latest', 'lane', 'landslide', 'lake', 'lady', 'ladies', 'lacs', 'kwh', 'kumar', 'kulathurstudents', 'koyilandy', 'kovil', 'kottukunnam', 'kottayam', 'kottakkal', 'kotooli', 'kolenchery', 'kochi', 'knows', 'km', 'kl157912', 'kind', 'kills', 'keshavadasapuram', 'keep', 'kazhakkuttam', 'kattakkada', 'kattakada', 'karukaputhurpallipadamthichur', 'junction', 'january', 'jam', 'issue', 'isnt', 'intervention', 'intersection', 'intended', 'insurance', 'instead', 'innocent', 'injury', 'initiate', 'inform', 'inescapable', 'indifferent', 'indiavision', 'increasing', 'increases', 'inconvenience', 'income', 'include', 'important', 'implement', 'impeding', 'immediatelythe', 'immediately', 'immediate', 'illustrate', 'illegal', 'ignoring', 'ie', 'idea', 'id', 'huge', 'houses', 'hoping', 'hopefully', 'hill', 'highway', 'highspeed', 'hidden', 'help', 'heavyweight', 'heavily', 'harsh', 'handle', 'half', 'gst', 'great', 'good', 'goes', 'go', 'gate', 'frequently', 'frequent', 'found', 'forget', 'footwalk', 'follow', 'flooded', 'fix', 'fish', 'first', 'find', 'femalesthen', 'femalesas', 'females', 'feelplease', 'fee', 'faster', 'fall', 'factors', 'facing', 'facility', 'face', 'extremly', 'extent', 'experienced', 'example', 'evict', 'everybody', 'evening', 'etcthe', 'etcetc', 'estate', 'especially', 'equality', 'entering', 'enforcement', 'emerge', 'effective', 'effected', 'effect', 'edge', 'earliest', 'earlier', 'duration', 'dug', 'drove', 'driven', 'done', 'distis', 'directly', 'directed', 'digital', 'difficulty', 'diameter', 'destroyed', 'destination', 'despite', 'depending', 'dependable', 'depend', 'delivery', 'defects', 'dear', 'date', 'dashed', 'dangerous', 'danger', 'cyclists', 'current', 'crowed', 'crossings', 'crew', 'creating', 'countless', 'cottton', 'corruption', 'correct', 'converted', 'convenient', 'controlled', 'contributions', 'contract', 'continuing', 'continue', 'constructing', 'constituency', 'consider', 'connection', 'connecting', 'confirm', 'conductors', 'conductor', 'concreated', 'complexes', 'completion', 'completely', 'complaint', 'companies', 'collectors', 'cocanuts', 'class', 'claims', 'choose', 'choondy', 'chithravila', 'chipping', 'charge', 'channels', 'changes', 'change', 'chances', 'chance', 'certain', 'centers', 'causes', 'caused', 'carts', 'caring', 'carelessly', 'cancelled', 'canal', 'came', 'calicut', 'cables', 'busy', 'businesses', 'busiest', 'busesplease', 'buseskindly', 'busesatleast', 'buildings', 'build', 'brutally', 'bribe', 'bottom', 'bothers', 'booths', 'boards', 'boarder', 'blocking', 'block', 'bikes', 'bikers', 'biggest', 'big', 'behind', 'behaving', 'behave', 'beautification', 'bear', 'basic', 'base', 'barrier', 'away', 'aware', 'authority', 'authorites', 'attitude', 'attinkuzhy', 'attached', 'ask', 'asianet', 'arrive', 'arrange', 'aroor', 'arookutty', 'argue', 'appeal', 'amenities', 'almost', 'alloted', 'alappuzha', 'aid', 'aggravates', 'advice', 'add', 'actually', 'activity', 'access', '730', '6', '500', '5', '40', '300', '25', '23', '2', '12th', '12m', '100']\n",
      "\n",
      "\n",
      "KEYWORDS  PWD\n",
      "\n",
      "\n",
      "[['road', 'roads', 'bus', 'drivers', 'condition']]\n",
      "\n",
      "\n",
      " KSEB Freq newwwwwwwwww\n",
      "{'take': 7, 'vayal': 1, 'occupied': 1, 'drivers': 11, 'claims': 1, 'activity': 1, 'january': 1, 'rescheduling': 1, 'height': 3, 'low': 2, 'situations': 1, 'something': 2, 'less': 1, 'cottton': 1, 'rushy': 1, 'water': 3, 'always': 2, 'resident': 1, 'process': 2, 'huge': 1, 'mathilakam': 1, 'handle': 1, 'taking': 1, 'condition': 10, 'find': 1, 'speed': 2, 'traveller': 1, 'almost': 1, 'health': 2, 'running': 3, 'repairing': 1, 'dependable': 1, 'accidents': 10, 'days': 2, 'kwh': 1, 'digged': 2, 'misbehaviour': 1, 'ultimately': 1, 'tire': 1, 'actually': 1, 'markings': 1, 'blocking': 1, 'earlier': 1, 'block': 1, 'etcthe': 1, 'thadoli': 1, 'complexes': 1, 'good': 1, 'students': 3, 'recently': 3, 'driver': 3, 'highway': 1, 'nation': 1, '23': 1, 'half': 1, 'kattakkada': 1, 'toilets': 1, 'walking': 1, 'hidden': 1, 'route': 3, 'femalesthen': 1, 'regular': 1, 'removed': 1, 'businesses': 1, 'control': 2, 'loose': 1, 'completely': 1, 'road': 66, 'sufficient': 2, 'telephone': 1, 'poovathumkadavu': 1, 'india': 3, 'lines': 1, 'register': 1, 'contract': 1, 'emerge': 1, 'potential': 2, 'reimbursement': 1, 'companies': 1, 'tax': 3, 'service': 5, 'manathoor': 1, 'inform': 1, 'thampanoor': 1, 'public': 7, 'existing': 2, 'amenities': 1, 'card': 2, 'two': 2, 'without': 2, 'taluk': 1, 'notnot': 1, 'making': 1, 'shops': 3, 'office': 1, 'schedule': 1, 'wants': 1, 'attitude': 1, 'retarring': 1, 'class': 1, 'aggravates': 1, 'roads': 30, 'consideration': 2, 'motorist': 1, 'biggest': 1, 'many': 7, 'reserved': 2, 'shack': 1, 'venjaramood': 1, 'dont': 4, 'created': 2, 'wear': 2, 'technopark': 2, 'shattered': 1, 'tender': 1, 'pwd': 3, 'mr': 1, 'maintenance': 5, 'gate': 1, 'cancelled': 1, 'aware': 1, 'steps': 1, 'holes': 2, 'trucks': 1, 'district': 3, 'sirmadam': 1, 'estate': 1, 'try': 1, 'ksrtc': 8, 'requires': 1, 'prone': 1, 'repair': 3, 'months': 2, 'landslide': 1, 'bothers': 1, 'vehicles': 9, 'transport': 6, 'km': 1, 'tear': 2, 'argue': 1, 'manorama': 1, 'miss': 1, 'recent': 1, 'boards': 1, 'pine': 1, 'kallingal': 2, 'ran': 1, 'risk': 2, 'defects': 1, 'valakom': 1, 'behaving': 1, 'provide': 2, 'converted': 1, 'long': 1, 'directly': 1, 'trivandrumidukkikattappana': 1, 'construction': 2, 'feelplease': 1, 'saved': 1, 'repairs': 1, 'create': 2, '100': 1, 'safer': 1, 'kattakada': 1, 'sir': 4, 'possible': 2, 'got': 3, 'bus': 16, 'length': 2, 'fully': 2, 'number': 4, 'rashly': 1, 'well': 3, 'facing': 1, 'innocent': 1, 'rural': 2, 'connection': 1, 'driven': 1, 'given': 3, 'drainage': 2, 'immediatelythe': 1, 'masalas': 1, 'restaurants': 1, 'raised': 1, 'fish': 1, 'snacks': 1, 'rudely': 1, 'ymcacross': 1, 'mud': 1, 'etcetc': 1, 'phase': 1, 'tractors': 1, 'way': 2, 'tarring': 2, 'pot': 2, 'rentals': 1, 'amount': 3, 'cars': 2, 'kovil': 1, 'major': 1, 'side': 3, 'traffic': 9, 'pvc': 1, 'suddenly': 1, 'evening': 1, 'taskirequests': 1, 'signal': 1, 'away': 1, 'kumarakam': 2, 'chances': 1, 'unauthorized': 2, 'conductor': 1, 'clean': 2, 'ask': 1, 'example': 1, 'suffering': 2, 'overspeeding': 2, 'shacks': 1, 'rainy': 2, 'carelessly': 1, 'lake': 1, 'things': 2, 'stopping': 1, 'miserable': 1, 'even': 7, 'pits': 1, 'limit': 2, '12m': 1, 'limited': 1, 'commute': 2, 'fast': 2, 'systems': 1, 'pity': 1, 'continuing': 1, 'difficult': 4, 'country': 2, 'fall': 1, 'tea': 1, 'ambadi': 2, 'lacs': 1, 'work': 2, 'charge': 1, 'thazha': 1, 'day': 6, 'late': 3, 'around': 4, 'visibility': 1, 'problems': 3, 'learnt': 1, 'till': 1, 'creating': 1, 'potholes': 5, 'impeding': 1, 'layman': 1, 'twowheelers': 1, 'shed': 3, 'implement': 1, 'light': 1, 'using': 1, 'technology': 2, 'done': 1, 'solve': 1, 'inconvenience': 1, 'super': 1, 'meter': 1, 'unexpected': 1, 'hazards': 2, 'caused': 1, 'busesatleast': 1, 'cant': 2, 'edge': 1, 'ramamangalam': 1, 'basic': 1, 'name': 1, 'harsh': 1, 'laws': 1, 'hoping': 1, 'high': 4, 'raining': 1, 'kochi': 1, 'get': 2, 'hitting': 3, 'lane': 1, 'media': 1, 'correct': 1, 'lack': 4, 'driving': 2, 'know': 6, 'slippery': 1, 'completion': 1, 'resurfaced': 1, 'bottom': 1, 'kl157912': 1, 'prior': 1, 'night': 1, 'leave': 1, 'faster': 1, 'six': 1, 'roots': 1, 'passengers': 5, 'petty': 2, 'today': 1, 'needed': 1, 'lots': 2, 'reckless': 1, 'maintained': 4, 'collected': 2, 'living': 2, 'convenient': 1, 'various': 1, 'threat': 1, 'compound': 3, 'constituency': 1, 'modernization': 1, 'wall': 6, 'via': 1, 'accident': 2, 'notice': 2, 'see': 4, 'buildings': 1, 'common': 2, 'prices': 1, 'others': 2, 'malappuram': 1, 'trivandrum': 3, 'canal': 1, 'congestion': 3, 'week': 1, 'channels': 1, 'selling': 2, 'outlet': 1, 'aid': 1, 'jam': 1, '2': 1, 'manually': 1, 'lady': 1, 'initiate': 1, 'tent': 2, 'helpful': 3, 'result': 2, 'damage': 6, 'hours': 2, 'kulathurstudents': 1, 'new': 1, 'related': 1, 'chipping': 1, 'timeconsuming': 1, 'arookutty': 1, 'car': 5, 'starting': 1, 'properly': 3, 'takes': 1, 'mtr': 2, 'minimum': 1, 'left': 1, 'pothole': 2, 'distis': 1, 'underground': 1, 'bridge': 3, 'mla': 1, 'ss': 1, 'great': 1, 'goes': 1, 'ie': 1, 'us': 1, 'took': 1, 'progressing': 1, 'hit': 2, 'nagar': 2, 'time': 5, 'help': 1, 'student': 2, 'last': 5, 'width': 2, 'nature': 1, 'bribe': 1, 'caring': 1, 'sometimes': 2, 'mid': 1, 'permissions': 1, 'requested': 2, 'peruvammuzhy': 1, 'stopped': 3, '300': 1, 'follow': 1, 'located': 1, 'money': 2, 'still': 2, '12th': 1, 'city': 8, 'right': 4, 'difficulty': 1, 'isnt': 1, 'crossings': 1, '1': 2, 'tar': 1, 'barrier': 1, 'much': 3, 'bear': 1, 'full': 2, 'ladies': 1, 'aroor': 1, 'dangerous': 1, 'negligence': 1, 'delivery': 1, 'vendors': 1, 'indiavision': 1, 'roadside': 1, 'busiest': 1, 'large': 2, 'station': 1, 'back': 3, 'photos': 1, 'access': 1, 'local': 1, 'passing': 1, 'cocanuts': 1, 'instead': 1, 'pedestrians': 3, 'base': 1, 'year': 3, 'chithravila': 1, 'increase': 3, 'licence': 1, 'also': 9, 'monthsafter': 1, 'arrange': 1, '15': 2, 'reduced': 1, 'towards': 6, 'atleast': 2, 'lax': 1, 'would': 5, 'none': 1, 'solely': 1, 'effected': 1, 'safety': 3, 'equality': 1, 'years': 2, 'kills': 1, 'willing': 1, 'corruption': 1, 'business': 2, 'unpaved': 1, 'causing': 3, 'rising': 1, 'shortcuts': 1, 'undue': 1, 'dashed': 1, 'flow': 3, 'resulting': 1, 'pregnant': 1, 'shoe': 1, 'used': 3, 'earliest': 1, 'repaired': 2, 'serious': 1, 'like': 7, 'brutally': 1, 'seek': 1, 'hill': 1, 'give': 2, 'suitable': 1, 'filled': 2, 'directed': 1, 'continue': 1, 'politicians': 1, 'idea': 1, 'news': 2, 'unwary': 1, 'reduce': 1, 'constructing': 1, 'shortcut': 1, 'confirm': 1, 'busesplease': 1, 'behind': 1, 'houses': 1, 'feet': 2, 'extent': 1, 'sreekaryam': 4, 'reason': 2, 'pose': 1, 'dear': 1, 'fix': 1, 'effect': 1, 'proper': 7, 'fuel': 2, 'big': 1, 'per': 2, 'types': 1, 'contributions': 1, 'reasonable': 1, 'real': 1, 'hope': 2, 'past': 2, 'conditions': 2, 'may': 3, 'transportation': 3, 'retar': 1, 'street': 2, 'face': 1, 'concreated': 1, 'action': 7, 'increases': 1, 'kottukunnam': 1, 'broken': 2, 'area': 6, 'seat': 4, 'attached': 1, 'showrooms': 1, 'make': 6, 'since': 1, 'physical': 1, 'bikers': 1, 'kindly': 4, 'arrive': 1, 'kottakkal': 1, 'pasengers': 1, '25': 1, 'kerala': 3, 'toll': 3, 'alloted': 1, 'thannippara': 1, 'onky': 1, 'railway': 4, 'times': 3, 'lot': 3, 'issue': 1, 'prevalent': 1, 'law': 2, 'attention': 2, 'permits': 1, 'school': 1, 'streets': 1, 'direction': 2, 'crew': 1, 'attinkuzhy': 1, 'male': 1, 'trend': 1, 'kind': 1, 'depend': 1, 'town': 2, 'seats': 4, 'advice': 1, 'puzha': 1, 'problem': 6, 'increasing': 1, 'etc': 2, 'going': 6, 'danger': 1, 'season': 2, 'damaged': 4, 'every': 3, 'underlying': 1, 'koyilandy': 1, 'rules': 2, 'issues': 2, 'locations': 1, 'sudden': 1, 'highspeed': 1, 'date': 1, 'calicut': 1, 'newly': 1, 'several': 2, 'important': 1, 'thanks': 1, 'buseskindly': 1, 'include': 1, 'intended': 1, 'usually': 1, 'retarr': 1, 'carts': 1, 'choose': 1, 'cause': 3, 'place': 1, 'nearby': 1, 'stop': 6, 'sign': 1, 'pay': 1, 'tared': 1, 'peakhour': 1, 'waiting': 2, 'old': 1, 'boarder': 1, 'kottayam': 1, 'view': 1, 'reaching': 1, 'part': 1, 'pathholes': 1, 'submitted': 1, 'provision': 1, 'villages': 2, 'present': 1, 'authority': 1, 'facility': 1, '730': 1, 'busy': 1, 'bad': 3, 'withing': 1, 'cyclists': 1, 'frequent': 1, 'whole': 2, 'muvattupzha': 1, 'liability': 1, 'workers': 1, 'travel': 3, 'connecting': 1, 'life': 1, 'chance': 1, 'venjaramoodu': 1, 'pan': 1, 'surprise': 1, 'use': 2, 'footpath': 2, 'balance': 2, 'constructed': 2, 'kazhakkuttam': 1, 'injury': 1, 'enforcement': 1, 'buses': 10, 'services': 4, 'factors': 1, '3': 3, 'complaint': 1, 'causes': 1, 'insurance': 1, 'heavy': 2, 'destroyed': 1, 'evict': 1, 'necessary': 6, 'vehicle': 2, 'nayadan': 1, 'busses': 2, 'urgent': 1, 'footwalk': 1, 'depending': 1, 'value': 1, 'moreover': 1, 'increased': 2, 'ignoring': 1, 'hopefully': 1, 'standing': 1, 'travelling': 3, 'drove': 1, 'establishments': 3, 'kumar': 1, 'growing': 2, 'id': 1, 'income': 1, 'thodupuzha': 1, 'little': 1, 'upon': 1, 'themgod': 1, '40': 1, 'kotooli': 1, 'wayside': 1, 'bothered': 2, 'came': 1, '13th': 2, 'worst': 1, 'noticed': 1, 'areas': 4, 'person': 1, 'ordinary': 1, 'businessmen': 2, 'daily': 4, 'nippol': 1, 'despite': 1, 'pitfalls': 1, 'karukaputhurpallipadamthichur': 1, 'size': 1, 'conductors': 1, 'first': 1, 'least': 2, 'reach': 4, 'controlled': 1, 'junction': 1, 'intersection': 1, 'offices': 1, 'travelyesterday': 1, 'due': 8, 'next': 1, 'flooded': 1, 'plan': 1, 'pattazhy': 1, 'cables': 1, 'passenger': 2, 'alappuzha': 1, 'actions': 2, 'heavyweight': 1, 'illustrate': 1, 'traders': 2, 'man': 1, 'travelplease': 1, 'build': 1, 'maniykumpparakarimkunnam': 1, 'liquiors': 1, 'forget': 1, 'spend': 1, 'predict': 1, '5': 1, 'citizens': 2, 'kids': 2, 'travellers': 1, 'latest': 1, 'crossing': 3, 'changes': 1, 'point': 1, 'worthy': 1, 'mukkam': 1, 'unpredictable': 1, 'beautification': 1, 'steady': 1, 'safe': 1, 'sector': 1, 'kolenchery': 1, 'change': 1, 'morning': 3, 'go': 1, 'avoid': 2, 'intervention': 1, 'choondy': 1, 'digital': 1, 'gst': 1, 'needful': 3, 'makes': 3, 'pathetic': 1, 'toyota': 1, 'visit': 1, 'found': 1, 'never': 1, 'word': 1, 'responsible': 1, 'indifferent': 1, 'paved': 1, 'knows': 1, 'entering': 1, '500': 1, 'mangotu': 1, 'violation': 1, 'nadakkavu': 1, 'consider': 1, '6': 1, 'losses': 1, 'parking': 1, 'everybody': 1, 'college': 4, 'duration': 1, 'frequently': 1, 'system': 1, 'timings': 1, 'especially': 1, 'planning': 1, 'melattumoozhy': 1, 'maple': 1, 'diameter': 1, 'pathanapurm': 1, 'add': 1, 'immediately': 1, 'asianet': 1, 'heavily': 1, 'othukkungal': 1, 'bikes': 1, 'pop': 1, 'appeal': 1, 'open': 1, 'locality': 1, 'countless': 1, 'one': 4, 'please': 9, 'government': 4, 'booths': 1, 'leads': 3, 'tired': 1, 'muthambioorallur': 1, 'destination': 1, 'keep': 1, 'people': 7, 'request': 2, 'centers': 1, 'effective': 1, 'behave': 1, 'certain': 1, 'females': 1, 'violations': 1, 'works': 4, 'collectors': 1, 'totally': 1, 'crowed': 1, 'ernakulam': 2, 'pala': 1, 'percent': 1, 'current': 1, 'gutter': 2, 'leveled': 1, 'travelled': 1, 'illegal': 1, 'employees': 2, 'quality': 2, 'dug': 1, 'experienced': 1, 'early': 3, 'fee': 1, 'letting': 1, 'poor': 4, 'inescapable': 1, 'muvattupuza': 1, 'extremly': 1, 'immediate': 1, 'authorites': 1, 'losing': 1, 'stationso': 1, 'femalesas': 1, 'palakkad': 1, 'situation': 1, 'small': 1, 'middle': 3, 'department': 3, 'keshavadasapuram': 1, 'required': 1, 'regarding': 1, 'state': 1}\n",
      "['power', 'electricity', 'time', 'connection', 'working', 'wires', 'got', 'voltage', 'problem', 'please', 'issue', 'high', 'facing', 'even', 'due', 'cuts', 'without', 'using', 'us', 'transformer', 'supply', 'shedding', 'sector', 'repair', 'prior', 'phase', 'one', 'night', 'new', 'months', 'meter', 'many', 'make', 'locality', 'load', 'lights', 'last', 'house', 'home', 'failure', 'every', 'electric', 'day', 'bribe', 'bad', 'years', 'wrongly', 'well', 'values', 'use', 'unsocial', 'unnoticed', 'unavailability', 'unable', 'trouble', 'trivandrum', 'times', 'till', 'three', 'though', 'take', 'sure', 'summer', 'street', 'still', 'state', 'sound', 'since', 'showing', 'shortage', 'set', 'section', 'scenario', 'say', 'rs', 'robbery', 'result', 'request', 'replace', 'regular', 'rectified', 'recently', 'reason', 'raining', 'public', 'proper', 'procedure', 'platforms', 'phases', 'peoples', 'peak', 'past', 'particular', 'overhead', 'overall', 'old', 'occurring', 'notice', 'normalplease', 'needed', 'necessary', 'near', 'must', 'morning', 'month', 'money', 'misbehaved', 'makes', 'major', 'madavoor', 'low', 'lot', 'loss', 'look', 'lineman', 'left', 'large', 'knows', 'industries', 'houses', 'hot', 'highly', 'heavy', 'havent', 'grabbing', 'going', 'give', 'get', 'frequently', 'frequent', 'force', 'fix', 'first', 'find', 'fastly', 'fast', 'farming', 'failures', 'failed', 'exploded', 'experiences', 'examinations', 'everyone', 'evening', 'equipments', 'ensurde', 'employees', 'electronic', 'electrical', 'easily', 'ease', 'drunken', 'difficult', 'different', 'devices', 'daysremaining', 'daysplease', 'damaged', 'cut', 'current', 'crawl', 'corrupt', 'continues', 'connections', 'connectionplease', 'connected', 'condition', 'complaint', 'communication', 'comes', 'city', 'checking', 'came', 'burnt', 'big', 'avoid', 'applied', 'appliances', 'announcements', 'always', 'almost', 'affect', 'adjoining', 'activities', 'action', '700', '3', '15']\n",
      "\n",
      "\n",
      "KEYWORDS  KSEB\n",
      "\n",
      "\n",
      "[['power', 'electricity', 'time', 'connection', 'working']]\n",
      "\n",
      "\n",
      " KSRTC Freq newwwwwwwwww\n",
      "{'take': 2, 'workers': 1, 'travel': 1, 'life': 1, 'occupied': 1, 'venjaramoodu': 1, 'drivers': 4, 'speed': 1, 'amount': 1, 'station': 1, 'back': 2, 'great': 1, 'dependable': 1, 'local': 1, 'balance': 1, 'rescheduling': 1, 'kazhakkuttam': 1, 'ran': 1, 'schedule': 1, 'buses': 10, 'low': 1, 'services': 4, 'increase': 1, 'causes': 1, 'took': 1, 'cottton': 1, 'arrange': 1, 'rushy': 1, 'alloted': 1, 'times': 1, 'necessary': 1, 'ask': 1, 'always': 1, 'busses': 2, 'reduced': 1, 'atleast': 2, 'depending': 1, 'sir': 1, 'none': 1, 'overspeeding': 2, 'value': 1, 'carelessly': 1, 'safety': 1, 'miss': 1, 'standing': 1, 'travelling': 1, 'equality': 1, 'even': 3, 'innocent': 1, 'running': 1, 'kills': 1, 'willing': 1, 'limited': 1, 'accidents': 1, 'fast': 2, 'heavily': 1, 'income': 1, 'conductors': 1, 'upon': 1, 'difficult': 1, 'morning': 2, 'causing': 1, 'earlier': 1, 'work': 1, 'shortcuts': 1, 'commute': 2, 'dashed': 1, 'spend': 1, 'noticed': 1, 'areas': 1, 'person': 1, 'day': 1, 'government': 1, 'late': 3, 'around': 3, 'daily': 1, 'timings': 1, 'students': 3, 'recently': 3, 'like': 1, 'brutally': 1, 'hill': 1, 'give': 1, 'least': 1, 'kattakkada': 1, 'reach': 4, 'filled': 1, 'transport': 2, 'busesatleast': 1, 'route': 3, 'femalesthen': 1, 'regular': 1, 'travelyesterday': 1, 'control': 1, 'due': 3, 'confirm': 1, 'road': 2, 'busesplease': 1, 'safer': 1, 'behaving': 1, 'done': 1, 'passenger': 2, 'lady': 1, 'inconvenience': 1, 'super': 1, 'bothered': 2, 'lines': 1, 'sreekaryam': 1, 'caused': 1, 'reason': 1, 'cant': 1, 'came': 1, 'man': 1, 'proper': 1, 'one': 1, 'forget': 1, '23': 1, 'service': 5, 'inform': 1, 'hoping': 1, 'travellers': 1, 'public': 3, 'past': 1, 'get': 1, 'advice': 1, 'railway': 2, 'mukkam': 1, 'face': 1, 'lack': 2, 'action': 2, 'conductor': 1, 'bus': 14, 'problem': 3, 'change': 1, 'kottukunnam': 1, 'destination': 1, 'kl157912': 1, 'area': 2, 'seat': 4, 'use': 1, 'kumarakam': 2, 'almost': 1, 'make': 1, 'class': 1, 'people': 3, 'needful': 1, 'six': 1, 'kindly': 1, 'arrive': 1, 'passengers': 3, 'found': 1, 'pasengers': 1, 'authorites': 1, 'never': 1, 'word': 1, '730': 1, 'reserved': 2, 'night': 1, 'venjaramood': 1, 'onky': 1, 'dont': 2, 'nadakkavu': 1, 'convenient': 1, 'college': 4, 'frequently': 1, 'cancelled': 1, 'via': 1, 'sometimes': 1, 'see': 2, 'school': 1, 'given': 1, 'others': 1, 'add': 1, 'trivandrum': 1, 'male': 1, 'town': 1, 'week': 1, 'would': 4, 'locations': 1, 'ksrtc': 8, 'depend': 1, 'crossing': 1, 'seats': 4, 'driver': 2, '2': 1, 'vehicles': 1, 'please': 1, 'lots': 2, 'argue': 1, 'going': 2, 'tired': 1, 'helpful': 2, 'damage': 1, 'hours': 2, 'kulathurstudents': 1, 'transportation': 1, 'request': 2, 'effective': 1, 'risk': 1, 'behave': 1, 'car': 4, 'provide': 2, 'several': 1, 'females': 1, 'usually': 1, '25': 1, 'buseskindly': 1, 'trivandrumidukkikattappana': 1, 'totally': 1, 'intended': 1, 'feelplease': 1, 'rudely': 1, 'ernakulam': 1, 'percent': 1, 'us': 1, 'kattakada': 1, 'choose': 1, 'hit': 1, 'got': 2, 'travelled': 1, 'stop': 4, 'fully': 1, 'ignoring': 1, 'number': 2, 'time': 4, 'stopping': 1, 'student': 1, 'experienced': 1, 'rashly': 1, 'well': 1, 'kottayam': 1, 'facing': 1, 'reaching': 1, 'rural': 1, 'drove': 1, 'muvattupuza': 1, 'using': 1, 'leave': 1, 'stopped': 1, 'raining': 1, 'traveller': 1, 'present': 1, 'stationso': 1, 'solely': 1, 'femalesas': 1, 'city': 4, 'right': 1, 'difficulty': 1, 'busy': 1, 'access': 1, 'much': 1, 'mid': 1, 'whole': 1, 'ymcacross': 1, 'keep': 1}\n",
      "['bus', 'buses', 'ksrtc', 'service', 'would', 'time', 'stop', 'services', 'seats', 'seat', 'reach', 'drivers', 'college', 'city', 'car', 'students', 'route', 'recently', 'public', 'problem', 'people', 'passengers', 'late', 'even', 'due', 'around', 'transport', 'take', 'see', 'road', 'reserved', 'request', 'railway', 'provide', 'passenger', 'overspeeding', 'number', 'morning', 'lots', 'lack', 'kumarakam', 'hours', 'helpful', 'got', 'going', 'fast', 'driver', 'dont', 'commute', 'busses', 'bothered', 'back', 'atleast', 'area', 'action', 'ymcacross', 'workers', 'work', 'word', 'willing', 'whole', 'well', 'week', 'via', 'venjaramoodu', 'venjaramood', 'vehicles', 'value', 'usually', 'using', 'use', 'us', 'upon', 'trivandrumidukkikattappana', 'trivandrum', 'travelyesterday', 'travelling', 'travellers', 'traveller', 'travelled', 'travel', 'transportation', 'town', 'totally', 'took', 'tired', 'timings', 'times', 'super', 'student', 'stopping', 'stopped', 'stationso', 'station', 'standing', 'sreekaryam', 'spend', 'speed', 'sometimes', 'solely', 'six', 'sir', 'shortcuts', 'several', 'school', 'schedule', 'safety', 'safer', 'rushy', 'rural', 'running', 'rudely', 'risk', 'right', 'rescheduling', 'regular', 'reduced', 'reason', 'reaching', 'rashly', 'ran', 'raining', 'proper', 'present', 'please', 'person', 'percent', 'past', 'pasengers', 'others', 'onky', 'one', 'occupied', 'noticed', 'none', 'night', 'never', 'needful', 'necessary', 'nadakkavu', 'muvattupuza', 'mukkam', 'much', 'miss', 'mid', 'man', 'male', 'make', 'low', 'locations', 'local', 'lines', 'limited', 'like', 'life', 'leave', 'least', 'lady', 'kulathurstudents', 'kottukunnam', 'kottayam', 'kl157912', 'kindly', 'kills', 'keep', 'kazhakkuttam', 'kattakkada', 'kattakada', 'intended', 'innocent', 'inform', 'increase', 'inconvenience', 'income', 'ignoring', 'hoping', 'hit', 'hill', 'heavily', 'great', 'government', 'given', 'give', 'get', 'fully', 'frequently', 'found', 'forget', 'filled', 'femalesthen', 'femalesas', 'females', 'feelplease', 'facing', 'face', 'experienced', 'ernakulam', 'equality', 'effective', 'earlier', 'drove', 'done', 'difficulty', 'difficult', 'destination', 'depending', 'dependable', 'depend', 'day', 'dashed', 'damage', 'daily', 'crossing', 'cottton', 'convenient', 'control', 'confirm', 'conductors', 'conductor', 'class', 'choose', 'change', 'causing', 'causes', 'caused', 'carelessly', 'cant', 'cancelled', 'came', 'busy', 'busesplease', 'buseskindly', 'busesatleast', 'brutally', 'behaving', 'behave', 'balance', 'authorites', 'ask', 'arrive', 'arrange', 'argue', 'areas', 'amount', 'always', 'almost', 'alloted', 'advice', 'add', 'accidents', 'access', '730', '25', '23', '2']\n",
      "\n",
      "\n",
      "KEYWORDS  KSRTC\n",
      "\n",
      "\n",
      "[['bus', 'buses', 'ksrtc', 'service', 'would']]\n",
      "\n",
      "\n",
      " ENV Freq newwwwwwwwww\n",
      "{'take': 3, 'punish': 1, 'gods': 1, 'activities': 3, 'intense': 1, 'effect': 1, 'attributed': 1, 'carbonic': 1, 'ways': 1, 'oxygen': 2, 'trivandrum': 1, 'breeding': 1, 'co₂': 1, 'low': 1, 'sources': 2, 'political': 1, 'sand': 1, 'influence': 1, 'increase': 1, 'also': 4, 'soil': 2, 'water': 9, 'agriculture': 1, 'preserving': 1, 'pollution': 5, 'difficulties': 1, 'higher': 2, 'rapidly': 1, 'huge': 1, 'animals': 1, 'acidification': 1, 'health': 4, 'parties': 1, 'lakes': 1, 'landfills': 1, 'lives': 1, 'days': 1, 'quarrying': 2, 'spills': 1, 'household': 1, 'diversity': 1, 'awareness': 1, 'causing': 2, 'contaminated': 1, 'soon': 1, 'mining': 3, 'toxics': 1, 'ponds': 1, 'resulting': 1, 'uncontrolled': 1, 'end': 1, 'oil': 2, 'used': 1, 'need': 2, 'humans': 2, 'inviting': 1, 'serious': 1, 'like': 4, 'fishermen': 1, 'circadian': 1, 'human': 1, 'control': 1, 'fishes': 1, 'road': 2, 'cadmium': 1, 'deterioration': 1, 'bonding': 1, 'projects': 2, 'skin': 1, 'migration': 1, 'dried': 1, 'depletion': 1, 'fuel': 1, 'among': 1, 'move': 1, 'river': 2, 'real': 2, 'proper': 1, 'inform': 1, 'public': 3, 'electronic': 1, 'continuity': 1, 'concern': 1, 'big': 1, 'moderating': 1, 'fix': 1, 'policies': 1, 'content': 2, 'efficient': 1, 'area': 1, 'levels': 3, 'harder': 1, 'make': 3, 'variety': 1, 'heat': 1, 'space': 1, 'request': 2, 'catch': 1, 'rhythms': 1, 'impact': 2, 'kerala': 2, 'many': 5, 'humbly': 1, 'plastic': 1, 'crops': 1, 'useful': 1, 'builders': 1, 'remain': 1, 'cardiovascular': 1, 'issue': 1, 'air': 4, 'streams': 1, 'paddy': 2, 'steps': 2, 'alappad': 1, 'made': 1, 'summer': 2, 'level': 1, 'hide': 1, 'dust': 1, 'example': 1, 'produced': 1, 'usage': 1, 'ksrtc': 1, 'diseases': 1, 'respiratory': 1, 'extremes': 1, 'sea': 2, 'witnessing': 1, 'problem': 1, 'vehicles': 1, 'increasing': 1, 'beings': 2, 'etc': 1, 'going': 1, 'massively': 1, 'ecosystem': 1, 'artificial': 2, 'oragansations': 1, 'ghats': 1, 'issues': 1, 'affect': 1, 'constructiondevelopment': 1, 'save': 2, 'several': 1, 'ocean': 2, 'switching': 1, 'create': 2, 'thanks': 1, 'noise': 2, 'residents': 1, 'enter': 1, 'orientation': 1, 'earth': 1, 'contaminate': 1, 'quarries': 1, 'cancer': 1, 'possible': 1, 'nearby': 1, 'stop': 1, 'country': 1, 'cvd': 1, 'reduces': 1, 'number': 1, 'properly': 1, 'old': 1, 'excessive': 1, 'factor': 1, 'facing': 1, 'twice': 1, 'threatening': 1, 'construction': 2, 'part': 1, 'attempt': 1, 'strangers': 1, 'disinfectants': 2, 'survelliance': 1, 'plants': 1, 'livelihood': 1, 'epa': 1, 'potentially': 1, 'rampant': 1, 'factories': 1, 'holes': 2, 'dissolves': 1, 'hormone': 1, 'severe': 1, 'remedies': 1, 'life': 2, 'rivers': 3, 'way': 2, 'formed': 1, 'environment': 2, 'amount': 1, 'rising': 1, 'major': 4, 'industrial': 2, 'hand': 1, 'factors': 1, 'plastics': 1, 'harmful': 1, 'causes': 4, 'farming': 1, 'heavy': 1, 'residential': 2, 'necessary': 3, 'vehicle': 1, 'reconsidered': 1, 'dump': 2, 'season': 1, 'negative': 1, 'th': 1, 'harm': 3, 'patients': 1, 'disposal': 2, 'disposed': 1, 'scenario': 1, 'burning': 1, 'heavily': 1, 'kumbhachoodu': 1, 'deaths': 2, 'contribute': 1, 'dispersal': 1, 'renewable': 1, 'shaped': 1, 'increased': 1, 'households': 1, 'intolerable': 1, 'fall': 1, 'wastes': 7, 'marine': 1, 'cutting': 1, 'officials': 1, 'radiations': 1, 'deposits': 1, 'one': 2, 'areas': 2, 'day': 2, 'forest': 1, 'around': 1, 'foul': 1, 'bodies': 1, 'polluted': 1, 'problems': 2, 'quality': 1, 'generation': 1, 'dumping': 3, 'domestic': 2, 'changed': 1, 'eradicated': 1, 'curb': 1, 'runoff': 1, 'termed': 1, 'ph': 1, 'waste': 5, 'term': 1, 'lead': 1, 'due': 3, 'light': 2, 'chlorine': 1, 'climate': 1, 'reduction': 1, 'uncleaned': 1, 'hair': 1, 'actions': 1, 'hazards': 1, 'caused': 2, 'feed': 1, 'lung': 1, 'build': 2, 'euphoric': 1, 'food': 1, 'obvious': 1, 'mechanism': 1, 'electronics': 1, 'bacteria': 1, 'high': 2, 'decreases': 1, 'kochi': 1, 'changes': 1, 'hard': 1, 'interrupt': 1, 'purposes': 1, 'unprecedental': 1, 'become': 1, 'bus': 1, 'avoiding': 1, 'rate': 1, 'mercury': 1, 'change': 1, 'industries': 1, 'use': 2, 'living': 3, 'disease': 3, 'erosion': 1, 'recycling': 1, 'hotel': 1, 'regulations': 1, 'today': 1, 'never': 1, 'touched': 1, 'mighty': 1, 'dont': 1, 'nspectors': 1, 'night': 2, 'temperature': 3, 'ozone': 2, 'acid': 2, 'biosphere': 1, 'smelling': 1, 'emissions': 1, 'dying': 1, 'camera': 1, 'authority': 1, 'affects': 1, 'would': 1, 'long': 1, 'biodiversity': 1, 'open': 1, 'lot': 1, 'city': 2, 'disrupted': 1, 'planting': 1, 'please': 2, 'government': 4, 'initiate': 1, 'impacting': 1, 'utilizing': 1, 'commercial': 1, 'creating': 1, 'cut': 2, 'people': 4, 'grownup': 1, 'centers': 1, 'bad': 1, 'abruptly': 1, 'collect': 1, 'trees': 4, 'premises': 1, 'cause': 4, 'saving': 1, 'check': 1, 'expectedair': 1, 'rashes': 1, 'consider': 1, 'fields': 2, 'great': 1, 'overfishing': 1, 'wastage': 2, 'chemicals': 1, 'leach': 1, 'illegal': 1, 'overcome': 1, 'sides': 1, 'investigate': 1, 'time': 4, 'help': 1, 'polution': 1, 'survival': 1, 'western': 1, 'deforestation': 1, 'becomes': 1, 'continues': 1, 'energy': 1, 'new': 1, 'issuesalso': 1, 'supplied': 1, 'surge': 1, 'pampa': 1, 'physical': 1, 'places': 2, 'much': 1, 'considering': 1, 'ears': 1, 'fertile': 1, 'throwing': 1, 'religious': 1, 'facility': 1}\n",
      "['water', 'wastes', 'waste', 'pollution', 'many', 'trees', 'time', 'people', 'major', 'like', 'health', 'government', 'causes', 'cause', 'also', 'air', 'temperature', 'take', 'rivers', 'public', 'necessary', 'mining', 'make', 'living', 'levels', 'harm', 'dumping', 'due', 'disease', 'activities', 'way', 'wastage', 'use', 'summer', 'steps', 'sources', 'soil', 'sea', 'save', 'road', 'river', 'residential', 'request', 'real', 'quarrying', 'projects', 'problems', 'please', 'places', 'paddy', 'ozone', 'oxygen', 'one', 'oil', 'ocean', 'noise', 'night', 'need', 'light', 'life', 'kerala', 'industrial', 'impact', 'humans', 'holes', 'higher', 'high', 'fields', 'environment', 'dump', 'domestic', 'disposal', 'disinfectants', 'deaths', 'day', 'cut', 'create', 'content', 'construction', 'city', 'causing', 'caused', 'build', 'beings', 'artificial', 'areas', 'acid', 'would', 'witnessing', 'western', 'ways', 'vehicles', 'vehicle', 'variety', 'utilizing', 'useful', 'used', 'usage', 'unprecedental', 'uncontrolled', 'uncleaned', 'twice', 'trivandrum', 'toxics', 'touched', 'today', 'throwing', 'threatening', 'thanks', 'th', 'termed', 'term', 'switching', 'survival', 'survelliance', 'surge', 'supplied', 'streams', 'strangers', 'stop', 'spills', 'space', 'soon', 'smelling', 'skin', 'sides', 'shaped', 'severe', 'several', 'serious', 'season', 'scenario', 'saving', 'sand', 'runoff', 'rising', 'rhythms', 'resulting', 'respiratory', 'residents', 'renewable', 'remedies', 'remain', 'religious', 'regulations', 'reduction', 'reduces', 'recycling', 'reconsidered', 'rate', 'rashes', 'rapidly', 'rampant', 'radiations', 'quarries', 'quality', 'purposes', 'punish', 'properly', 'proper', 'produced', 'problem', 'preserving', 'premises', 'potentially', 'possible', 'ponds', 'polution', 'polluted', 'political', 'policies', 'plastics', 'plastic', 'plants', 'planting', 'physical', 'ph', 'patients', 'parties', 'part', 'pampa', 'overfishing', 'overcome', 'orientation', 'oragansations', 'open', 'old', 'officials', 'obvious', 'number', 'nspectors', 'new', 'never', 'negative', 'nearby', 'much', 'move', 'moderating', 'migration', 'mighty', 'mercury', 'mechanism', 'massively', 'marine', 'made', 'lung', 'low', 'lot', 'long', 'lives', 'livelihood', 'level', 'lead', 'leach', 'landfills', 'lakes', 'kumbhachoodu', 'ksrtc', 'kochi', 'issuesalso', 'issues', 'issue', 'inviting', 'investigate', 'intolerable', 'interrupt', 'intense', 'initiate', 'inform', 'influence', 'industries', 'increasing', 'increased', 'increase', 'impacting', 'illegal', 'humbly', 'human', 'huge', 'households', 'household', 'hotel', 'hormone', 'hide', 'help', 'heavy', 'heavily', 'heat', 'hazards', 'harmful', 'harder', 'hard', 'hand', 'hair', 'grownup', 'great', 'going', 'gods', 'ghats', 'generation', 'fuel', 'foul', 'formed', 'forest', 'food', 'fix', 'fishes', 'fishermen', 'fertile', 'feed', 'farming', 'fall', 'factors', 'factories', 'factor', 'facing', 'facility', 'extremes', 'expectedair', 'excessive', 'example', 'euphoric', 'etc', 'erosion', 'eradicated', 'epa', 'enter', 'energy', 'end', 'emissions', 'electronics', 'electronic', 'efficient', 'effect', 'ecosystem', 'earth', 'ears', 'dying', 'dust', 'dried', 'dont', 'diversity', 'dissolves', 'disrupted', 'disposed', 'dispersal', 'diseases', 'difficulties', 'deterioration', 'deposits', 'depletion', 'deforestation', 'decreases', 'days', 'cvd', 'cutting', 'curb', 'crops', 'creating', 'co₂', 'country', 'control', 'contribute', 'continuity', 'continues', 'contaminated', 'contaminate', 'constructiondevelopment', 'considering', 'consider', 'concern', 'commercial', 'collect', 'climate', 'circadian', 'chlorine', 'chemicals', 'check', 'changes', 'changed', 'change', 'centers', 'catch', 'cardiovascular', 'carbonic', 'cancer', 'camera', 'cadmium', 'bus', 'burning', 'builders', 'breeding', 'bonding', 'bodies', 'biosphere', 'biodiversity', 'big', 'becomes', 'become', 'bad', 'bacteria', 'awareness', 'avoiding', 'authority', 'attributed', 'attempt', 'around', 'area', 'animals', 'amount', 'among', 'alappad', 'agriculture', 'affects', 'affect', 'actions', 'acidification', 'abruptly']\n",
      "\n",
      "\n",
      "KEYWORDS  ENV \n",
      "\n",
      "\n",
      "[['water', 'wastes', 'waste', 'pollution', 'many']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter complaintBus service has been stopped.\t\"I am a student travelling from Kattakada to Sreekaryam. Recently,  bus service has been reduced  and we can't reach college on time. And have to choose other buses to reach the college at late hours.  Earlier we had 2-3 buses from Kattakkada. Now, the service has been stopped due to low income which causes the college students to miss the class. Hoping that you will do the needful to arrange the bus to  reach to college at right time. \"\n",
      "bus service has been stopped \t i am a student travelling from kattakada to sreekaryam  recently   bus service has been reduced  and we can t reach college on time  and have to choose other buses to reach the college at late hours   earlier we had 2 3 buses from kattakkada  now  the service has been stopped due to low income which causes the college students to miss the class  hoping that you will do the needful to arrange the bus to  reach to college at right time   \n",
      "['bus', 'service', 'has', 'been', 'stopped', 'i', 'am', 'a', 'student', 'travelling', 'from', 'kattakada', 'to', 'sreekaryam', 'recently', 'bus', 'service', 'has', 'been', 'reduced', 'and', 'we', 'can', 't', 'reach', 'college', 'on', 'time', 'and', 'have', 'to', 'choose', 'other', 'buses', 'to', 'reach', 'the', 'college', 'at', 'late', 'hours', 'earlier', 'we', 'had', '2', '3', 'buses', 'from', 'kattakkada', 'now', 'the', 'service', 'has', 'been', 'stopped', 'due', 'to', 'low', 'income', 'which', 'causes', 'the', 'college', 'students', 'to', 'miss', 'the', 'class', 'hoping', 'that', 'you', 'will', 'do', 'the', 'needful', 'to', 'arrange', 'the', 'bus', 'to', 'reach', 'to', 'college', 'at', 'right', 'time']\n",
      "['bus', 'service', 'stopped', 'student', 'travelling', 'kattakada', 'sreekaryam', 'recently', 'bus', 'service', 'reduced', 'reach', 'college', 'time', 'choose', 'buses', 'reach', 'college', 'late', 'hours', 'earlier', '2', '3', 'buses', 'kattakkada', 'service', 'stopped', 'due', 'low', 'income', 'causes', 'college', 'students', 'miss', 'class', 'hoping', 'needful', 'arrange', 'bus', 'reach', 'college', 'right', 'time']\n",
      "{'hours': 1, 'time': 2, 'sreekaryam': 1, 'student': 1, 'late': 1, 'earlier': 1, 'miss': 1, 'students': 1, 'recently': 1, 'travelling': 1, 'class': 1, 'service': 3, 'stopped': 2, 'kattakkada': 1, 'reach': 3, 'hoping': 1, 'income': 1, 'buses': 2, 'low': 1, '3': 1, 'right': 1, 'causes': 1, 'needful': 1, '2': 1, 'due': 1, 'arrange': 1, 'kattakada': 1, 'choose': 1, 'bus': 3, 'reduced': 1, 'college': 4}\n",
      "['college', 'service', 'reach', 'bus', 'time', 'stopped', 'buses', 'travelling', 'students', 'student', 'sreekaryam', 'right', 'reduced', 'recently', 'needful', 'miss', 'low', 'late', 'kattakkada', 'kattakada', 'income', 'hours', 'hoping', 'earlier', 'due', 'class', 'choose', 'causes', 'arrange', '3', '2']\n",
      "['college', 'service', 'reach', 'bus', 'time']\n",
      "\n",
      "\n",
      "Test Keywords \n",
      " \n",
      "\n",
      "['college', 'service', 'reach', 'bus', 'time']\n",
      "[['road', 'roads', 'bus', 'drivers', 'condition']]\n",
      "\n",
      "\n",
      " PWD predict \n",
      "\n",
      "\n",
      "['bus']\n",
      "[['road', 'roads', 'bus', 'drivers', 'condition']]\n",
      "\n",
      "\n",
      " WATER predict \n",
      "\n",
      "\n",
      "[]\n",
      "[['water', 'wastes', 'waste', 'pollution', 'many']]\n",
      "\n",
      "\n",
      " ENV predict \n",
      "\n",
      "\n",
      "[]\n",
      "{1: 'Water Authority', 2: 'PWD', 3: 'KSEB', 4: 'KSRTC', 5: 'Environment and climate change'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "from gensim.summarization import keywords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "global dataset\n",
    "\n",
    "\n",
    "class Main:\n",
    "         \n",
    "    global departments\n",
    "    \n",
    "    \n",
    "    def __init__(self,dataset):\n",
    "        #/home/gayathri/project/MakeComplaint/data.csv\n",
    "        self.dataset=dataset\n",
    "        #print(self.dataset)\n",
    "        self.dataset= pd.read_csv(self.dataset)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def department_class(self):\n",
    "        departments=self.dataset['Departments'].unique() \n",
    "        return departments\n",
    "        \n",
    "    \n",
    "    def punctuate(self):\n",
    "        punctuations = '''!()-[]{};:'\"\\,.<>/?@#$%^&*_~'''\n",
    "        text=self.dataset['Subject']\n",
    "\n",
    "        # To take input from the user\n",
    "        # my_str = input(\"Enter a string: \")\n",
    "\n",
    "        # remove punctuation from the string\n",
    "        no_punct = \"\"\n",
    "        no_punctuate =[]\n",
    "        for char in  self.dataset['Subject']:\n",
    "\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "                no_punctuate.append(no_punct)\n",
    "\n",
    "        # display the unpunctuated string\n",
    "        #print(no_punctuate)\n",
    "        return(no_punctuate)\n",
    "\n",
    "        \n",
    "    def data_clean(self):\n",
    "        \n",
    "        \n",
    "       \n",
    "        print(self.dataset.head())\n",
    "        # unpunctuate and lower case\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "\n",
    "\n",
    "            # unpunctuate and lower case\n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint'].str.replace(',',' ').str.lower() \n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Complaint'] = self.dataset['Complaint'].str.replace('[^\\w\\s]','').str.lower()\n",
    "        self.dataset['Subject'] = self.dataset['Subject'].str.replace('[^\\P{P}-]','').str.lower()\n",
    "        #print( self.dataset.head())\n",
    "\n",
    "\n",
    "\n",
    "        #rRemoving new lines in the subject field\n",
    "        self.dataset['Subject'] =  self.dataset['Subject'].str.rstrip('\\n')\n",
    "\n",
    "        #removing Numeric \n",
    "        self.dataset['Complaint'] =  self.dataset['Complaint']\n",
    "        print( self.dataset.head())\n",
    "        \n",
    "    def dataframing(self,dataset):\n",
    "        # creating dataframe for each departments\n",
    "        water = dataset.loc[dataset['Departments'] == 'Water Authority']\n",
    "        pwd = dataset.loc[dataset['Departments'] == 'PWD']\n",
    "        ksrtc = dataset.loc[dataset['Departments'] == 'KSRTC']\n",
    "        kseb = dataset.loc[dataset['Departments'] == 'KSEB']\n",
    "        env = dataset.loc[dataset['Departments'] == 'Environment and climate change']\n",
    "        print(env.shape)    #(30, 4)\n",
    "        #print(water.shape)  #(39, 4)\n",
    "        #print(pwd.shape)    #(42, 4)\n",
    "        #print(ksrtc.shape)  #(17, 4)\n",
    "        #print(kseb.shape)   #(22, 4)\n",
    "        #dataset.head()\n",
    "        #print(pwd)\n",
    "\n",
    "  \n",
    "\n",
    "        #Filtering out Subjects and complaints from the dataframe\n",
    "        df_water = water[['Subject','Complaint']]\n",
    "        df_pwd   = pwd[['Subject','Complaint']]\n",
    "        df_ksrtc = ksrtc[['Subject','Complaint']]\n",
    "        df_kseb  = kseb[['Subject','Complaint']]\n",
    "        df_env   = env[['Subject','Complaint']]\n",
    "\n",
    "        dfwater  = df_water[['Subject','Complaint']]\n",
    "        dfpwd    = df_pwd[['Subject','Complaint']]\n",
    "        dfksrtc  = df_ksrtc[['Subject','Complaint']]\n",
    "        dfkseb   = df_kseb[['Subject','Complaint']]\n",
    "        dfenv    = df_env[['Subject','Complaint']]\n",
    "\n",
    "        \n",
    "        dfwater['Subject_and_Complaint'] = df_water['Subject'] + \" \"+ df_water['Complaint']\n",
    "        dfwater=dfwater[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfpwd['Subject_and_Complaint'] = df_pwd['Subject'] + \" \"+ df_pwd['Complaint']\n",
    "        dfpwd=dfpwd[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfksrtc['Subject_and_Complaint'] = df_ksrtc['Subject'] + \" \"+ df_ksrtc['Complaint']\n",
    "        dfksrtc=dfksrtc[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfkseb['Subject_and_Complaint'] = df_kseb['Subject'] + \" \"+ df_kseb['Complaint']\n",
    "        dfkseb=dfkseb[['Subject_and_Complaint']]\n",
    "        \n",
    "        dfenv ['Subject_and_Complaint'] = df_env['Subject'] + \" \"+ df_env['Complaint']\n",
    "        dfenv =dfenv [['Subject_and_Complaint']]\n",
    "        print(dfenv )\n",
    "        return (dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "        \n",
    "        \n",
    "    def tokenisation(self,dfwater,dfpwd,dfksrtc,dfkseb,dfenv):\n",
    "        water_token = []\n",
    "        water_list=[]\n",
    "            #Tokenising water data\n",
    "            \n",
    "        #lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        #lemmatizer.lemmatize(\"corpora\")\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i, row in dfwater.iterrows():\n",
    "                #print(i,row['Subject'], row['Complaint'])\n",
    "                \n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in water_token if not i in stop_words]\n",
    "            #lemmatized_output = [i for i in lemmatizer.lemmatize(i) for i in result]\n",
    "        \n",
    "            water_list.append(result)\n",
    "        print(\"\\n\\nWater Tokens\\n\\n\")\n",
    "        print(water_list)\n",
    "    #water_token.append(tokenizer.tokenize(row['Subject_and_Complaint']))\n",
    "        pwd_token = []\n",
    "\n",
    "        pwd_list = []\n",
    "        #Tokenising pwd data  \n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result1 = [i for i in pwd_token if not i in stop_words]\n",
    "            pwd_list.append(result1)\n",
    "            \n",
    "        print(\"\\n\\nPWD Tokens\\n\\n\")\n",
    "        print(pwd_list)\n",
    "            \n",
    "            #print( pwd_token)\n",
    "\n",
    "\n",
    "        ksrtc_token =[]\n",
    "        ksrtc_list =[]\n",
    "        #Tokenising ksrtc data    \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in ksrtc_token if not i in stop_words]\n",
    "            ksrtc_list.append(result)\n",
    "            #print(ksrtc_list)\n",
    "            #print( ksrtc_token)\n",
    "            \n",
    "            \n",
    "            \n",
    "        kseb_token = []\n",
    "        kseb_list= []\n",
    "        #Tokenising kseb data    \n",
    "        for i, row in dfkseb.iterrows():\n",
    "        #print(i,row['Subject'], row['Complaint'])\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in kseb_token if not i in stop_words]\n",
    "            kseb_list.append(result)\n",
    "        #print(kseb_list)\n",
    "        #print(kseb_token)\n",
    "        \n",
    "        \n",
    "        env_token = []\n",
    "        env_list = []\n",
    "        #Tokenising env data  \n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            #print(i,row['Subject'], row['Complaint'])\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "            result = [i for i in env_token if not i in stop_words]\n",
    "            env_list.append(result)\n",
    "        print(env_list)\n",
    "            #print(env_token)\n",
    "        return(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "\n",
    "\n",
    "   \n",
    "    def word_frequency(self,water_list,pwd_list,ksrtc_list,kseb_list,env_list):\n",
    "        \n",
    "        #word frequencies  Environment department\n",
    "\n",
    "        wordfreq = []\n",
    "       \n",
    "    \n",
    "        for word  in env_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        env_count =Counter(wordfreq)\n",
    "        env_count= dict(env_count)\n",
    "        print(\"\\n\\n Env Count \\n\\n\")\n",
    "        print(type(env_count))\n",
    "        \n",
    "    \n",
    "        #word frequencies  KSEB department\n",
    "        wordfreq = []\n",
    "        for word  in kseb_list:\n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        kseb_count = Counter(wordfreq)\n",
    "        kseb_count= dict(kseb_count) \n",
    "        print(\"\\n\\n KSEB Count \\n\\n\")\n",
    "        print(kseb_count)\n",
    "    \n",
    "\n",
    "        \n",
    "        #word frequencies  KSRTC department\n",
    "\n",
    "        wordfreq = []\n",
    "        \n",
    "        for word  in ksrtc_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        ksrtc_count =Counter(wordfreq)\n",
    "        ksrtc_count= dict(ksrtc_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(ksrtc_count)\n",
    "    \n",
    "        \n",
    "        #word frequencies  pwd department\n",
    "\n",
    "        for word  in pwd_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        pwd_count =Counter(wordfreq)\n",
    "        pwd_count = dict(pwd_count)\n",
    "        print(\"\\n\\n PWD Count \\n\\n\")\n",
    "        print(type(pwd_count))\n",
    "        \n",
    "        \n",
    "        #word frequencies  water department\n",
    "\n",
    "        wordfreq = []\n",
    "        for word  in water_list:\n",
    "            \n",
    "            for i in word:\n",
    "                wordfreq.append(i)\n",
    "        water_count =Counter(wordfreq)\n",
    "        water_count= dict(water_count)\n",
    "        print(\"\\n\\n KSRTC Count \\n\\n\")\n",
    "        print(type(water_count))\n",
    "        return(water_count,pwd_count,ksrtc_count,kseb_count,env_count)\n",
    "\n",
    "\n",
    "    def most_repeated_keywords(self,water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq ):\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n Water Freq newwwwwwwwww\")\n",
    "        print(water_freq)\n",
    "        \n",
    "        #print sorted(prices.iteritems(), lambda x, y : cmp(x[1], y[1]))\n",
    "\n",
    "        \n",
    "        water_lis =[]\n",
    "        water_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in water_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        water_dict=(items[:5])\n",
    "        water_lis.append(water_dict)\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        print(\"\\n\\nKEYWORDS  WATER\\n\\n\")\n",
    "        print(water_lis)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\n\\n PWD Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        pwd_lis =[]\n",
    "        pwd_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in pwd_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        pwd_dict=(items[:5])\n",
    "        pwd_lis.append(pwd_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  PWD\\n\\n\")\n",
    "        print(pwd_lis)\n",
    "        \n",
    "        \n",
    "        # Finding the most repeated words kseb\n",
    "        print(\"\\n\\n KSEB Freq newwwwwwwwww\")\n",
    "        print(pwd_freq)\n",
    "        \n",
    "        \n",
    "        kseb_lis =[]\n",
    "        kseb_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in kseb_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        kseb_dict=(items[:5])\n",
    "        kseb_lis.append(kseb_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSEB\\n\\n\")\n",
    "        print(kseb_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words ksrtc\n",
    "\n",
    "        print(\"\\n\\n KSRTC Freq newwwwwwwwww\")\n",
    "        print(ksrtc_freq)\n",
    "        \n",
    "        \n",
    "        ksrtc_lis =[]\n",
    "        ksrtc_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in ksrtc_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        \n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        ksrtc_dict=(items[:5])\n",
    "        ksrtc_lis.append(ksrtc_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  KSRTC\\n\\n\")\n",
    "        print(ksrtc_lis)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Finding the most repeated words env\n",
    "        print(\"\\n\\n ENV Freq newwwwwwwwww\")\n",
    "        print(env_freq)\n",
    "        \n",
    "        \n",
    "        env_lis =[]\n",
    "        env_freq_list = { }\n",
    "        \n",
    "        items = [(v, k) for k, v in env_freq.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)\n",
    "\n",
    "\n",
    "\n",
    "        env_dict=(items[:5])\n",
    "        env_lis.append(env_dict)\n",
    "\n",
    "        print(\"\\n\\nKEYWORDS  ENV \\n\\n\")\n",
    "        print(env_lis)\n",
    "       \n",
    "        \n",
    "        \n",
    "        return(water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis )\n",
    "                \n",
    "        \n",
    "    def most_repeated_keyword_lib(self,dfenv,dfwater,dfpwd,dfksrtc,dfkseb):\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        env_keyword = []\n",
    "        env_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : ENV\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfenv.iterrows():\n",
    "            env_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in env_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            env_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            env_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(env_summary)\n",
    "        \n",
    "        # water Keyword\n",
    "        \n",
    "        water_keyword = []\n",
    "        water_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : Water\\n\\n\")\n",
    "        \n",
    "        \n",
    "        for i, row in dfwater.iterrows():\n",
    "            water_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in water_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            water_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            water_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(water_summary)\n",
    "        \n",
    "        \n",
    "        #pwd keyword\n",
    "        \n",
    "        pwd_keyword = []\n",
    "        pwd_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : PWD\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfpwd.iterrows():\n",
    "            pwd_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in pwd_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            pwd_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            pwd_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(pwd_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        ksrtc_keyword = []\n",
    "        ksrtc_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSRTC\\n\\n\")\n",
    "        #print(dfenv)\n",
    "        \n",
    "        for i, row in dfksrtc.iterrows():\n",
    "            ksrtc_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in ksrtc_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            ksrtc_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            ksrtc_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(ksrtc_summary)\n",
    "        \n",
    "        #env keyword\n",
    "        \n",
    "        kseb_keyword = []\n",
    "        kseb_summary = []\n",
    "        \n",
    "        stopwords = list(STOP_WORDS)\n",
    "        \n",
    "        print(\"\\n\\nKEYWORD : LIB : KSEB\\n\\n\")\n",
    "        #print(dfkseb)\n",
    "        \n",
    "        for i, row in dfkseb.iterrows():\n",
    "            kseb_token = word_tokenize(row['Subject_and_Complaint'])\n",
    "\n",
    "            result = [i for i in kseb_token if not i in stopwords]\n",
    "            #print(result)\n",
    "            kseb_keyword.append(result)\n",
    "            \n",
    "            str1 = ' '.join(result)\n",
    "            #map(bytes,env_keyword)\n",
    "            #print(str1)\n",
    "            #break\n",
    "        #print(type(env_token))\n",
    "            kseb_summary.append(keywords(str1).split('\\n'))\n",
    "               \n",
    "        #print(type(env_token[0][0]))\n",
    "        print(kseb_summary)\n",
    "        return(env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def jump(self,status):\n",
    "        if status == 1:\n",
    "            env_summary,water_summary,pwd_summary,ksrtc_summary,kseb_summary=self.most_repeated_keyword_lib(dfenv,dfwater,dfpwd,dfksrtc,dfkseb)\n",
    "        else:\n",
    "            \n",
    "            water_lis,pwd_lis,ksrtc_lis,kseb_lis,env_lis = self.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq )\n",
    "        return(water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis)\n",
    "            \n",
    "    def test(self):\n",
    "        text_data = input(\"Enter complaint\")\n",
    "        text_data= text_data.replace('[^\\w\\s]','').lower()\n",
    "        \n",
    "        \n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "  \n",
    "        for x in text_data.lower(): \n",
    "            if x in punctuations: \n",
    "                text_data = text_data.replace(x, \" \") \n",
    "  \n",
    "   \n",
    "        print(text_data) \n",
    "        \n",
    "            \n",
    "        test_token = word_tokenize(text_data)\n",
    "        print(test_token)\n",
    "        test_list =[]\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        for i in test_token:\n",
    "            \n",
    "            \n",
    "            if i not in stop_words:\n",
    "        \n",
    "                test_list.append(i)\n",
    "        print(test_list)\n",
    "        \n",
    "        #frequency : \n",
    "        \n",
    "\n",
    "        \n",
    "        counts = Counter(test_list)\n",
    "        count = dict(counts)\n",
    "        print(count)  # word frequency\n",
    "    \n",
    "        items = [(v, k) for k, v in counts.items()]\n",
    "        items.sort()\n",
    "        items.reverse()\n",
    "        items = [k for v, k in items]\n",
    "        print(items)  # sorted high to low\n",
    "        test_dict=(items[0:5])\n",
    "        print(test_dict)  #key only\n",
    "        \n",
    "        return(test_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept):\n",
    "        #keyword matching \n",
    "        #water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis\n",
    "        print(\"\\n\\nTest Keywords \\n \\n\")\n",
    "        print(keywords)\n",
    "        #items = [k for v, k in water_lis]\n",
    "        \n",
    "        #pwd_lis=dict(pwd_lis)\n",
    "        #pwd predict\n",
    "        pwd_predict=[]\n",
    "        pwd_list = []\n",
    "        print(pwd_lis)\n",
    "        for li in pwd_lis:\n",
    "            for i in li:\n",
    "                \n",
    "                pwd_list.append(i)\n",
    "        keywords = set(keywords)\n",
    "        pwd_list = set(pwd_list)\n",
    "        pwd_predict = keywords & pwd_list\n",
    "        pwd_predict = list(pwd_predict)\n",
    "                            \n",
    "        print(\"\\n\\n PWD predict \\n\\n\")    \n",
    "        print(pwd_predict)\n",
    "        \n",
    "        #water predict\n",
    "        \n",
    "        water_predict=[]\n",
    "        water_list = []\n",
    "        print(pwd_lis)\n",
    "        for li in water_lis:\n",
    "            for i in li:\n",
    "                \n",
    "                water_list.append(i)\n",
    "        keywords = set(keywords)\n",
    "        water_list = set(water_list)\n",
    "        water_predict = keywords & water_list\n",
    "        water_predict = list(water_predict)\n",
    "                            \n",
    "        print(\"\\n\\n WATER predict \\n\\n\")    \n",
    "        print(water_predict)\n",
    "        \n",
    "        #env predict\n",
    "        \n",
    "        env_predict=[]\n",
    "        env_list = []\n",
    "        print(env_lis)\n",
    "        for li in env_lis:\n",
    "            for i in li:\n",
    "                \n",
    "                \n",
    "                env_list.append(i)\n",
    "        env_list = set(env_list)\n",
    "        env_predict = keywords & env_list\n",
    "        env_predict = list(env_predict)\n",
    "                            \n",
    "        print(\"\\n\\n ENV predict \\n\\n\")    \n",
    "        print(env_predict)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        department=dept\n",
    "        dept_values =[1,2,3,4,5]\n",
    "        depart_dict = dict(zip(dept_values,department))\n",
    "        print(depart_dict)\n",
    "        \n",
    "        \n",
    "  \n",
    "            \n",
    "        \n",
    "                  \n",
    "        \n",
    "        \n",
    "file =   '/home/gayathri/project/MakeComplaint/data.csv'   \n",
    "\n",
    "x= Main(file)\n",
    "x.punctuate()\n",
    "x.data_clean()\n",
    "dfwater,dfpwd,dfksrtc,dfkseb,dfenv=x.dataframing(x.dataset)\n",
    "\n",
    "water_list,pwd_list,ksrtc_list,kseb_list,env_list = x.tokenisation(dfwater,dfpwd,dfksrtc,dfkseb,dfenv)\n",
    "\n",
    "water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq = x.word_frequency(water_list,pwd_list,ksrtc_list,kseb_list,env_list)\n",
    "#x.most_repeated_keywords(water_freq,pwd_freq,ksrtc_freq,kseb_freq,env_freq)\n",
    "#x.most_repeated_keyword_lib(dfenv) \n",
    "\n",
    "water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis=x.jump(0)\n",
    "\n",
    "keywords=x.test()\n",
    "dept=x.department_class()\n",
    "x.evaluate(keywords,water_lis,env_lis,pwd_lis,ksrtc_lis,kseb_lis,dept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
